<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Realjf&#39;s blog</title>
    <link>https://realjf.io/</link>
    <description>Recent content on Realjf&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Nov 2020 14:03:58 +0800</lastBuildDate>
    
	<atom:link href="https://realjf.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>VS Code扩展开发 之 发布扩展 Publishing Vscode Extensions</title>
      <link>https://realjf.io/vscode/publishing-vscode-extensions/</link>
      <pubDate>Tue, 24 Nov 2020 14:03:58 +0800</pubDate>
      
      <guid>https://realjf.io/vscode/publishing-vscode-extensions/</guid>
      <description>一旦你制作了高质量的扩展，你就能发布到vscode 扩展市场，以便让其他人可以找到并下载使用你的扩展， 你可以打包扩展为可安装的VSIX格式并与其他人分享
本节将包括以下内容：
 使用vsce，这个是管理VS Code扩展的CLI工具 打包、发布以及取消发布扩展 注册一个发布者id用于发布扩展  vsce vsce，是Visual Studio Code Extensions的简称，是一个打包，发布和管理vscode扩展的命令行工具
安装 请确保你已经安装了node.js
npm install -g vsce  使用 cd myExtension vsce package # myExtension.vsix generated vsce publish # &amp;lt;publisherID&amp;gt;.myExtension published to VS Code MarketPlace  更多的命令请使用vsce &amp;ndash;help查看
发布扩展  由于安全考虑，vsce不会发布包含用户提供的svg图片的扩展
 发布工具检查如下内容：
 package.json中提供的icon图标可能不是一个svg package.json中提供的徽章可能不是svg，除非他们来自可信的徽章提供商 README.md和CHANGELOG.md中的图片地址需要处理成https路径 README.md中和CHANGELOG.md中的图片可能不是svg除非他们来自可信的徽章提供商  visualstudio代码利用Azure DevOps提供其Marketplace服务。 这意味着扩展的身份验证、托管和管理是通过azuredevops提供的。
vsce只能使用Personal access tokens发布扩展。要发布扩展，至少需要创建一个，
获取个人access token 首先，确保你有Azure DevOps组织
 在下面的示例中，组织的名称是realjf。从组织的主页（例如：https://dev.azure.com/realjf)下一步， 打开“个人图像设置”下拉菜单，选择Personal access tokens：
 在Personal Access Tokens页面，点击New Token创建一个新的Personal Access Token</description>
    </item>
    
    <item>
      <title>VS Code扩展开发 之 语言的语法高亮 Language Extension Syntax Highlight</title>
      <link>https://realjf.io/vscode/language-extension-syntax-highlight/</link>
      <pubDate>Tue, 24 Nov 2020 12:07:13 +0800</pubDate>
      
      <guid>https://realjf.io/vscode/language-extension-syntax-highlight/</guid>
      <description>简介 语法高亮显示确定在VisualStudio代码编辑器中显示的源代码的颜色和样式。 它负责在JavaScript中为if或for等关键字着色，这与字符串、注释和变量名不同
语法高亮有两个组件：
 Tokenization：符号化，将文本拆分为符号列表 Theming：支持主题，使用主题或用户设置将符号映射到特定的颜色和样式  在深入讨论细节之前，一个好的开始是使用scopeinspector工具并探索源文件中存在哪些标记以及它们与哪些主题规则匹配。 要同时查看语义和语法标记，请在TypeScript文件中使用内置主题（例如，Dark+）
符号化 文本的符号化是将文本分成若干段，并用标记类型对每个段进行分类。
VS代码的标记化引擎由TextMate语法驱动。TextMate语法是正则表达式的结构化集合， 以plist（XML）或JSON文件的形式编写。 语法扩展可以通过语法贡献点的贡献。
TextMate符号化引擎在与呈现器相同的进程中运行，标记会随着用户类型的变化而更新。 标记用于语法高亮显示，但也用于将源代码分类为注释、字符串和正则表达式区域。
从版本1.43开始，VS代码还允许扩展通过 语义标记提供者 为程序提供标记化。典型的是， 在项目服务器中实现的符号和语义的源代码一般都可以理解。例如， 可以在整个项目中使用常量高亮显示来呈现常量变量名，而不仅仅是在声明的地方。
基于语义标记的高亮显示被认为是对基于TextMate的语法高亮显示的补充。 语义突出显示在语法突出显示之上。由于语言服务器需要一段时间来加载和分析项目， 语义标记高亮显示可能会在短时间延迟后出现。
本文主要讨论基于TextMate的标记化。语义标记化和主题化在 语义高亮指南中解释
TextMate 语法 VS代码使用TextMate语法作为语法标记化引擎。 它们是为TextMate编辑器而发明的， 由于开源社区创建和维护了大量的语言包，因此被许多其他编辑器和ide采用。
TextMate语法依赖于Oniguruma正则表达式， 通常以plist或JSON的形式编写。您可以在这里找到对TextMate语法的很好的介绍， 并且可以查看现有的TextMate语法，以了解它们是如何工作的
TextMate标记和作用域 标记是同一程序元素的一个或多个字符。示例标记包括运算符（如+和*）、变量名（如myVar）或字符串（如“my string”）。
每个token都与定义token上下文的作用域相关联。作用域是一个点分隔的标识符列表，用于指定当前token的上下文。 例如，JavaScript中的+操作具有作用域关键字.运算符.算术.js。
主题将范围映射到颜色和样式，以提供语法高亮显示。TextMate提供了许多主题所针对的通用范围的列表。 为了尽可能广泛地支持您的语法，请尝试在现有范围上构建，而不是定义新的范围。
作用域嵌套，以便每个token也与父作用域的列表相关联。 下面的示例使用范围检查器 在一个简单的JavaScript函数中显示+运算符的范围层次结构。 最具体的作用域列在顶部，更一般的父作用域列在下面：
父范围信息也用于创建主题。当主题以某个范围为目标时，所有具有该父作用域的标记都将被着色， 除非该主题还为其各自的作用域提供了更具体的着色
添加 基本语法 VS代码支持json TextMate语法。这些都是通过grammars贡献点贡献的。
每个语法贡献都指定：语法应用于的语言的标识符、语法标记的顶级作用域名称以及语法文件的相对路径。 下面的示例显示了虚构的abc语言的语法贡献：
{ &amp;quot;contributes&amp;quot;: { &amp;quot;languages&amp;quot;: [ { &amp;quot;id&amp;quot;: &amp;quot;abc&amp;quot;, &amp;quot;extensions&amp;quot;: [&amp;quot;.abc&amp;quot;] } ], &amp;quot;grammars&amp;quot;: [ { &amp;quot;language&amp;quot;: &amp;quot;abc&amp;quot;, &amp;quot;scopeName&amp;quot;: &amp;quot;source.</description>
    </item>
    
    <item>
      <title>VSCode扩展开发系列三 之 结束 Vscode Extension Wrapping Up</title>
      <link>https://realjf.io/vscode/vscode-extension-wrapping-up/</link>
      <pubDate>Tue, 24 Nov 2020 11:33:17 +0800</pubDate>
      
      <guid>https://realjf.io/vscode/vscode-extension-wrapping-up/</guid>
      <description> 扩展的能力  VS Code APIs Contribution Points  详见扩展的能力
指南和例子  Extension Guide Listing vscode-extension-example  测试和发布  如何在你的扩展中添加集成测试 如何发布你的扩展到vs code市场 如何为你的扩展建立持续集成  </description>
    </item>
    
    <item>
      <title>VSCode扩展开发系列二 之 扩展解析 Vscode Extension Anatomy</title>
      <link>https://realjf.io/vscode/vscode-extension-anatomy/</link>
      <pubDate>Tue, 24 Nov 2020 11:24:01 +0800</pubDate>
      
      <guid>https://realjf.io/vscode/vscode-extension-anatomy/</guid>
      <description>在上一节中我们创建了一个hello world扩展，那么他的工作原理是什么呢？
 注册onCommand激活事件：onCommand:extension.helloWorld，以便在用户运行Hello World命令时，扩展可激活 使用 contributes.commands Contribution Point使命令Hello World在命令调色板中可用，并且绑定一个命令id:extension.helloWorld 使用commands.registerCommand vscode api去绑定一个已经被extension.helloWorld的命令id注册的函数绑定  这里需要理解以下概念
 Activation Event：设置扩展激活的时机。位于 package.json 中。 Contribution Point：设置在 VSCode 中哪些地方添加新功能，也就是这个扩展增强了哪些功能。位于 package.json 中。 Register：在 extension.ts 中给要写的功能用 vscode.commands.register&amp;hellip; 给 Activation Event 或 Contribution Point 中配置的事件绑定方法或者设置监听器。位于入口文件（默认是 extension.ts）的 activate() 函数中。 VS Code API：你可以在扩展代码中调用的javascript api功能集合  扩展文件结构 . ├── .vscode │ ├── launch.json // Config for launching and debugging the extension │ └── tasks.json // Config for build task that compiles TypeScript ├── .</description>
    </item>
    
    <item>
      <title>VSCode扩展开发系列一 之 第一个vscode插件开发 Your First Vscode Extension</title>
      <link>https://realjf.io/vscode/your-first-vscode-extension/</link>
      <pubDate>Tue, 24 Nov 2020 10:18:41 +0800</pubDate>
      
      <guid>https://realjf.io/vscode/your-first-vscode-extension/</guid>
      <description>准备  node.js git  安装yeoman和vscode扩展生成器 npm install -g yo generator-code  用生成器构建一个TypeScript或JavaScript项目，以备开发。运行生成器并为TypeScript项目填写一些字段：
yo code ? What type of extension do you want to create? New Extension (TypeScript) ? What&#39;s the name of your extension? HelloWorld ? What&#39;s the identifier of your extension? helloworld ? What&#39;s the description of your extension? LEAVE BLANK ? Initialize a git repository? Yes ? Bundle the source code with webpack? No ? Which package manager to use?</description>
    </item>
    
    <item>
      <title>vue.js 2 系列之九 理解vue.js Understanding Vuejs 2</title>
      <link>https://realjf.io/vuejs/understanding-vuejs-2/</link>
      <pubDate>Sat, 14 Nov 2020 20:31:27 +0800</pubDate>
      
      <guid>https://realjf.io/vuejs/understanding-vuejs-2/</guid>
      <description>准备 创建项目
vue create nomagic  在项目根目录下添加新文件vue.config.js
module.exports = { runtimeCompiler: true }  在项目根目录下运行
npm install bootstrap@4.0.0  在main.js里添加bootstrap.min.css如下内容
import Vue from &#39;vue&#39; import App from &#39;./App.vue&#39; import &amp;quot;bootstrap/dist/css/bootstrap.min.css&amp;quot;; Vue.config.productionTip = false new Vue({ render: h =&amp;gt; h(App), }).$mount(&#39;#app&#39;)  运行例子
npm run serve  使用DOM API创建应用 在main.js中添加如下内容：
require(&#39;../node_modules/bootstrap/dist/css/bootstrap.min.css&#39;) let counter = 1; let container = document.createElement(&amp;quot;div&amp;quot;); container.classList.add(&amp;quot;text-center&amp;quot;, &amp;quot;p-3&amp;quot;); let msg = document.createElement(&amp;quot;h1&amp;quot;); msg.classList.add(&amp;quot;bg-primary&amp;quot;, &amp;quot;text-white&amp;quot;, &amp;quot;p-3&amp;quot;); msg.textContent = &amp;quot;Button Not Pressed&amp;quot;; let button = document.</description>
    </item>
    
    <item>
      <title>vue.js 2 系列之八 运动商店A Real App 4</title>
      <link>https://realjf.io/vuejs/a-real-app-4/</link>
      <pubDate>Mon, 09 Nov 2020 14:15:41 +0800</pubDate>
      
      <guid>https://realjf.io/vuejs/a-real-app-4/</guid>
      <description>基于之前一篇基础之上进行构建 /vuejs/a-real-app-3/
首先，运行json web服务
npm run json  然后运行运动商店http服务器
npm run serve  添加商品管理功能 在src/store文件夹中的index.js文件中添加如下内容
import Vue from &amp;quot;vue&amp;quot;; import Vuex from &amp;quot;vuex&amp;quot;; import Axios from &amp;quot;axios&amp;quot;; import CartModule from &amp;quot;./cart&amp;quot;; import OrdersModule from &amp;quot;./orders&amp;quot;; import AuthModule from &amp;quot;./auth&amp;quot;; Vue.use(Vuex); const baseUrl = &amp;quot;http://localhost:3500&amp;quot;; const productsUrl = `${baseUrl}/products`; const categoriesUrl = `${baseUrl}/categories`; const testData = []; for(let i = 1; i &amp;lt;= 10; i++){ testData.push({ id: i, name: `Product #${i}`, category: `Category ${i % 3}`, description: `This is Product #${i}`, price: i * 50 }) } export default new Vuex.</description>
    </item>
    
    <item>
      <title>vue.js 2 系列之七 运动商店 A Real App 3</title>
      <link>https://realjf.io/vuejs/a-real-app-3/</link>
      <pubDate>Sat, 07 Nov 2020 14:35:06 +0800</pubDate>
      
      <guid>https://realjf.io/vuejs/a-real-app-3/</guid>
      <description>基于之前一篇基础之上进行构建 /vuejs/a-real-app-2/
准备 在data.js文件中添加如下内容：
var faker = require(&amp;quot;faker&amp;quot;); var data = []; var categories = [&amp;quot;Watersports&amp;quot;, &amp;quot;Soccer&amp;quot;,&amp;quot;Chess&amp;quot;, &amp;quot;Running&amp;quot;]; faker.seed(100); for(let i=1; i&amp;lt;=500; i++){ var category = faker.helpers.randomize(categories); data.push({ id: i, name: faker.commerce.productName(), category: category, description: `${category}: ${faker.lorem.sentence(3)}`, price: faker.commerce.price() }) } module.exports = function() { return { products: data, categories: categories, orders: [], }; };  然后执行如下命令：
npm run json  在另外一个终端执行如下命令：
npm run serve  处理大量数据 改进分页导航 在src/components文件夹的PageControls.vue文件中添加如下内容：</description>
    </item>
    
    <item>
      <title>vue.js 2 系列之六 运动商店 A Real App 2</title>
      <link>https://realjf.io/vuejs/a-real-app-2/</link>
      <pubDate>Sat, 07 Nov 2020 11:49:25 +0800</pubDate>
      
      <guid>https://realjf.io/vuejs/a-real-app-2/</guid>
      <description>下单 基于之前一篇基础之上进行构建 /vuejs/a-real-app/
创建购物车预置 在src/components文件夹下新建ShoppingCart.vue文件，其内容如下：
&amp;lt;template&amp;gt; &amp;lt;h4 class=&amp;quot;bg-primary text-white text-center p-2&amp;quot;&amp;gt; placeholder for Cart &amp;lt;/h4&amp;gt; &amp;lt;/template&amp;gt;  配置url路由 在src/router文件夹中添加index.js文件中添加如下内容：
import Vue from &amp;quot;vue&amp;quot;; import VueRouter from &amp;quot;vue-router&amp;quot;; import Store from &amp;quot;../components/Store&amp;quot;; import ShoppingCart from &amp;quot;../components/ShoppingCart&amp;quot;; Vue.use(VueRouter); export default new VueRouter({ mode: &amp;quot;history&amp;quot;, routes: [ {path:&amp;quot;/&amp;quot;, component: Store}, {path: &amp;quot;/cart&amp;quot;, component: ShoppingCart}, {path: &amp;quot;*&amp;quot;, redirect: &amp;quot;/&amp;quot;} ] })  将上面的路由文件添加到main.js中
import Vue from &#39;vue&#39; import App from &#39;./App.vue&#39; // 引入jquery import $ from &#39;jquery&#39; Vue.</description>
    </item>
    
    <item>
      <title>vue.js 2 系列之五 运动商店 A Real App</title>
      <link>https://realjf.io/vuejs/a-real-app/</link>
      <pubDate>Fri, 06 Nov 2020 16:41:21 +0800</pubDate>
      
      <guid>https://realjf.io/vuejs/a-real-app/</guid>
      <description>准备 首先创建项目
vue create sportsstore --default  安装jquery，bootstrap，popper.js
cd sportsstore npm install jquery npm install bootstrap@4.0.0 npm install popper  在 main.js文件中引入jquery和bootstrap
import Vue from &#39;vue&#39; import App from &#39;./App.vue&#39; // 引入jquery import $ from &#39;jquery&#39; Vue.config.productionTip = false // 添加bootstrap框架 import &amp;quot;bootstrap/dist/css/bootstrap.min.css&amp;quot; new Vue({ render: h =&amp;gt; h(App), }).$mount(&#39;#app&#39;)  配置package.json的eslintConfig里的rules
&amp;quot;rules&amp;quot;: { &amp;quot;no-unused-vars&amp;quot;:&amp;quot;off&amp;quot;, &amp;quot;no-console&amp;quot;:&amp;quot;off&amp;quot;, &amp;quot;no-declare&amp;quot;: &amp;quot;off&amp;quot; },  运行项目
npm run serve  添加附加包 cd sportsstore npm install axios@0.</description>
    </item>
    
    <item>
      <title>vue.js 2 系列之四 javascript入门 Js Primer</title>
      <link>https://realjf.io/vuejs/js-primer/</link>
      <pubDate>Fri, 06 Nov 2020 15:35:03 +0800</pubDate>
      
      <guid>https://realjf.io/vuejs/js-primer/</guid>
      <description>准备 首先创建项目
vue create jsprimer --default  安装jquery，bootstrap，popper.js
cd jsprimer npm install jquery npm install bootstrap@4.0.0 npm install popper  在 main.js文件中引入jquery和bootstrap
import Vue from &#39;vue&#39; import App from &#39;./App.vue&#39; // 引入jquery import $ from &#39;jquery&#39; Vue.config.productionTip = false // 添加bootstrap框架 import &amp;quot;bootstrap/dist/css/bootstrap.min.css&amp;quot; new Vue({ render: h =&amp;gt; h(App), }).$mount(&#39;#app&#39;)  配置package.json的eslintConfig里的rules
&amp;quot;rules&amp;quot;: { &amp;quot;no-unused-vars&amp;quot;:&amp;quot;off&amp;quot;, &amp;quot;no-console&amp;quot;:&amp;quot;off&amp;quot;, &amp;quot;no-declare&amp;quot;: &amp;quot;off&amp;quot; },  运行项目
npm run serve  函数 定义函数，包括缺省值，函数返回值， 在main.js中添加如下代码
func myFunc(name, age = 18) { return &amp;quot;Hello &amp;quot; + name + &amp;quot;, your age is &amp;quot; + age.</description>
    </item>
    
    <item>
      <title>vue.js 2 系列之三 Html 和 Css 入门</title>
      <link>https://realjf.io/vuejs/html-css-primer/</link>
      <pubDate>Fri, 06 Nov 2020 14:41:48 +0800</pubDate>
      
      <guid>https://realjf.io/vuejs/html-css-primer/</guid>
      <description>准备 首先创建项目
vue create htmlcss --default  安装jquery，bootstrap，popper.js
cd htmlcss npm install jquery npm install bootstrap@4.0.0 npm install popper  在 main.js文件中引入jquery和bootstrap
import Vue from &#39;vue&#39; import App from &#39;./App.vue&#39; // 引入jquery import $ from &#39;jquery&#39; Vue.config.productionTip = false // 添加bootstrap框架 import &amp;quot;bootstrap/dist/css/bootstrap.min.css&amp;quot; new Vue({ render: h =&amp;gt; h(App), }).$mount(&#39;#app&#39;)  eslint配置
# 进入node_modules目录的.bin目录下，初始化eslint cd node_modules/.bin/ eslint --init # 设置选项，除选择vue.js外，其他都选择默认选项 # 最后，将node_modules目录.bin目录下的.eslintrc.js文件拷贝到项目根目录下 # window下 copy .eslintrc.js ..\..\ # linux下 cp .</description>
    </item>
    
    <item>
      <title>vue.js 2 系列之二 理解vue.js Understanding Vue.js</title>
      <link>https://realjf.io/vuejs/understanding-vuejs/</link>
      <pubDate>Fri, 06 Nov 2020 14:26:34 +0800</pubDate>
      
      <guid>https://realjf.io/vuejs/understanding-vuejs/</guid>
      <description>理解web应用结构模型 往返交互(round-trip)或者多页应用模型 通过用户点击提交表单等操作，浏览器请求返回新的html文档结构供用户浏览
单体应用模型或单页应用模型 用户通过点击提交表单发送ajax请求更新首次返回的html文档中的部分数据</description>
    </item>
    
    <item>
      <title>vue.js 2 系列之一 第一个vue.js应用 First Vuejs App</title>
      <link>https://realjf.io/vuejs/first-vuejs-app/</link>
      <pubDate>Fri, 06 Nov 2020 10:37:34 +0800</pubDate>
      
      <guid>https://realjf.io/vuejs/first-vuejs-app/</guid>
      <description>准备开发环境  安装最新版node.js 使用npm安装@vue/cli命令行工具包 安装git 安装开发ide，如vscode，sublime text, atom,vim等 安装浏览器，chrome,firefox等   安装vue命令：npm install -g @vue/cli
 创建工程项目 vue create todo --default  项目结构解析 执行tree -L 1后得到如下结构
├── babel.config.js ├── node_modules ├── package.json ├── package-lock.json ├── public | ├── favicon.ico | └── index.html ├── README.md └── src ├── App.vue ├── assets │ └── logo.png ├── components │ └── HelloWorld.vue └── main.js   public/index.html 这是浏览器加载的第一个文件 src/main.js 这个vue.js应用的配置js文件 src/App.vue 这是vue.js组件，包含html文档结构和js代码以及css文档样式 src/assets/logo.png assets文件夹是存放静态资源文件  运行开发工具 cd todo npm run serve # 运行结果如下： App running at: - Local: http://localhost:8080/ - Network: http://192.</description>
    </item>
    
    <item>
      <title>如何使用cmake - How to Use Cmake</title>
      <link>https://realjf.io/devtools/how-to-use-cmake/</link>
      <pubDate>Wed, 04 Nov 2020 09:24:08 +0800</pubDate>
      
      <guid>https://realjf.io/devtools/how-to-use-cmake/</guid>
      <description>准备  cmake   下载地址：https://cmake.org/download/
 安装 具体的安装方法参照官网，这里不做赘述
建议 cmake每次运行会产生大量中间文件，可以通过在项目根目录下创建build文件，然后运行cmake ../执行项目构建
cmake命令行选项 指定构建系统生成器： -G 使用-G可以指定编译器，当前平台支持的编译器名称可以通过帮助手册查询cmake &amp;ndash;help，
# 使用vs2017构建工程 cmake -G &amp;quot;Visual Studio 15 2017&amp;quot; ../ # 使用MinGW cmake -G &amp;quot;MinGW Makefiles&amp;quot; # 使用unix makefiles cmake -G &amp;quot;Unix Makefiles&amp;quot;  CMakeCache.txt文件  当cmake第一次运行一个空的构建的时候，他会创建一个CMakeCache.txt文件， 文件里存放了一些可以用来制定工程的项目，比如：变量、选项等
 对于同一变量，如果cache文件里面有设置，那么CMakeLists文件里就会优先使用Cache文件里面的同名变量。
 CMakeLists里面通过设置了一个Cache里面没有的变量，那么就将这个变量的值写入到Cache里面
  添加变量到cache文件中： -D  注意：-D后面不能有空格，如：cmake -DCMAKE_BUILD_TYPE:STRING=Debug  从Cache文件中删除变量：-U  此选项和-D功能相反，从Cache文件中删除变量，支持使用*和？通配符  cmake命令行模式：-E  cmake提供了很多和平台无关的命令，在任何平台都可以使用：chdir, copy,copy_if_different等 可以使用：cmake -D help进行查询  打印运行的每一行cmake  命令行选项中：&amp;ndash;trace，将打印运行的每一行cmake 命令：&amp;ndash;trace-source=&amp;ldquo;filename&amp;rdquo; 就会打印出有关filename的执行  设置编译参数  add_definitions (-DENABLED)，当在cmake里面添加该定义的时候，如果代码里面定义了#ifdef ENABLED #endif 相关的片段，此时代码里面这一块代码就会生效 //add_definitions(&amp;ldquo;-Wall -ansi -pedantic -g&amp;rdquo;) 该命令现已经被取代，使用：add_compile_definitions(WITH_OPENCV2)  设置默认值命令：option  option命令可以帮助我们设置一个自定义的宏，如：option(MY-MESSAGE &amp;ldquo;this is my message&amp;rdquo; ON) 第一个参数就是我们要设置的默认值的名字 第二个参数是对值的解释，类似于注释 第三个值是这个默认值的值，如果没有声明，cmake默认的是OFF 使用：设置好之后我们在命令行去使用的时候，也可以去给他设定值：cmake -DMY-MESSAGE=on .</description>
    </item>
    
    <item>
      <title>Vagrantfile</title>
      <link>https://realjf.io/devtools/vagrantfile/</link>
      <pubDate>Sun, 11 Oct 2020 04:48:38 +0800</pubDate>
      
      <guid>https://realjf.io/devtools/vagrantfile/</guid>
      <description>配置版本 配置版本是一种机制，通过该机制，Vagrant 1.1+可以 与Vagrant 1.0.x Vagrantfiles保持向后兼容，同时引入了许多新功能和配置选项
现在运行vagrant init，其格式如下：
Vagrant.configure(&amp;quot;2&amp;quot;) do |config| # ... end  其中的2代表配置的版本的号
可以同时使用版本1和版本2的特性，最终它们将合并在一起使用
Vagrant.configure(&amp;quot;1&amp;quot;) do |config| # v1 configs... end Vagrant.configure(&amp;quot;2&amp;quot;) do |config| # v2 configs... end  最小版本 这个可以限制太新或者太旧的版本，但是此版本限制必须放在vagrantfile文件最前面， 并通过vagrant.require_version 指定
Vagrant.require_version &amp;quot;&amp;gt;= 1.3.5&amp;quot;  上述限制将让vagrantfile文件只在 大于等于vagrant 1.3.5版本时加载
也可以指定多版本限制
Vagrant.require_version &amp;quot;&amp;gt;= 1.3.5&amp;quot;, &amp;quot;&amp;lt; 1.4.0&amp;quot;  循环vm定义 (1..3).each do |i| config.vm.define &amp;quot;node-#{i}&amp;quot; do |node| node.vm.provision &amp;quot;shell&amp;quot;, inline: &amp;quot;echo hello from node #{i}&amp;quot; end end  以上的each结构时使用副本进行迭代，所以不会出错，但是如果使用以下结构，将会使所有node的text相同</description>
    </item>
    
    <item>
      <title>安装vagrant Install Vagrant</title>
      <link>https://realjf.io/devtools/install-vagrant/</link>
      <pubDate>Tue, 29 Sep 2020 05:29:26 +0800</pubDate>
      
      <guid>https://realjf.io/devtools/install-vagrant/</guid>
      <description> 准备环境  kali 2020  安装 apt update apt install vagrant # 测试是否安装成功 vagrant --version  </description>
    </item>
    
    <item>
      <title>windows环境下安装Php扩展Mcrypt</title>
      <link>https://realjf.io/php/php-mcrypt-install-in-win/</link>
      <pubDate>Tue, 15 Sep 2020 14:34:59 +0800</pubDate>
      
      <guid>https://realjf.io/php/php-mcrypt-install-in-win/</guid>
      <description>准备  xampp环境 mcrypt扩展下载地址https://windows.php.net/downloads/pecl/releases/mcrypt/  解压安装 解压后，直接复制php_mcrypt.dll到php/ext目录下， 然后在php.ini中添加一行extension=php_mcrypt.dll，重启apache即可</description>
    </item>
    
    <item>
      <title>windows环境下安装Memcached和php-memcached扩展以及安装php-memcache扩展</title>
      <link>https://realjf.io/php/memcached-and-php-extension-install-win/</link>
      <pubDate>Tue, 15 Sep 2020 14:12:53 +0800</pubDate>
      
      <guid>https://realjf.io/php/memcached-and-php-extension-install-win/</guid>
      <description>准备  xampp环境 php-memcached扩展，地址https://github.com/lifenglsf/php_memcached_dll php-memcache扩展，地址http://pecl.php.net/package/memcache/4.0.5.2/windows memcached下载地址https://www.runoob.com/memcached/window-install-memcached.html  memcached安装 首先下载对应版本的memcached，我这里使用的是这个http://static.runoob.com/download/memcached-1.4.5-amd64.zip
安装步骤详见：https://www.runoob.com/memcached/window-install-memcached.html
我这里只写1.4.5版本的安装
首先下载解压后，用管理员权限运行如下命令：
schtasks /create /sc onstart /tn memcached /tr &amp;quot;&#39;e:\memcached\memcached.exe&#39; -m 512&amp;quot; # /tn taskname 指定唯一识别这个计划任务的名称 # /sc schedule 指定计划频率 # /create 创建新计划任务 # /tr taskrun 指定在这个计划运行的程序的路径和文件名 # 如果需要删除，可以运行如下命令 schtasks /delete /tn memcached # 设置开机启动后如何立马运行 schtasks /run /tn memcached # 运行后如何终止正在运行的计划任务 schtasks /end /tn memcached # 查看更多schtasks帮助 schtasks /?  memcached的php扩展 首先phpinfo查看php版本， http://localhost:8080/dashboard/phpinfo.php
然后根据Zend Extension Build和PHP Extension Build可以确定对应的memcached版本， 我这里的信息如下：</description>
    </item>
    
    <item>
      <title>windows下Vscode Php开发环境配置</title>
      <link>https://realjf.io/posts/vscode-win-php-setting/</link>
      <pubDate>Mon, 14 Sep 2020 17:08:59 +0800</pubDate>
      
      <guid>https://realjf.io/posts/vscode-win-php-setting/</guid>
      <description>准备  windows10 系统 vscode xampp  首先下载安装xampp 由于墙的问题，可以使用如下地址：https://sourceforge.net/projects/xampp/
当然如果你能翻墙，可以直接访问xampp官网下载
下载完成后安装，安装完成后，将xampp/php/php.exe加入系统路径, 在terminal中执行php -v验证是否成功
下载xdebug插件 下载地址：https://xdebug.org/download
如果不知道下载什么版本，可以将你的phpinfo信息拷贝到这个网址下查询https://xdebug.org/wizard 复制后点击下面的分析phpinfo按钮
这里下载的是：https://xdebug.org/files/php_xdebug-2.9.6-7.4-vc15-x86_64.dll
将下载好的拷贝到xampp/php/ext文件夹中 修改php.ini文件，在文件末尾追加以下信息 [xdebug] zend_extension=&amp;ldquo;E:\xampp\php\ext\php_xdebug-2.9.6-7.4-vc15-x86_64.dll&amp;rdquo; xdebug.remote_enable = 1 xdebug.remote_autostart = 1 xdebug.remote_port = 9900 // 默认端口9000，根据自己本机改
xdebug.remote_handler = dbgp xdebug.remote_host = 127.0.0.1
vscode下载安装 下载vscode：https://code.visualstudio.com/
下载安装完成后，需要安装一些扩展插件
 bmewburn.vscode-intelephense-client felixfbecker.php-intellisense felixfbecker.php-debug ikappas.composer  按下ctrl+p，然后输入&amp;gt; settings.json，选择preferences: open default settings(JSON), 打开配置文件，配置php执行路径：
&amp;quot;php.validate.executablePath&amp;quot;: &amp;quot;E:\\xampp\\php\\php.exe&amp;quot;  配置好这些后，启动xampp的apache服务器
准备好后开始测试 在xampp/htdocs/目录下新建一个php文件夹，然后在用vscode打开php文件夹，新建文件php_test.php，内容如下：
&amp;lt;?php $a = &#39;hello world&#39;; echo $a; ?&amp;gt;  在 &amp;ldquo;$a = &amp;lsquo;hello world&amp;rsquo;&amp;ldquo;这一行设置断点， 然后，按下f5执行，转到run code的界面，如果是首次运行，需要配置configuration，因为左上角显示的是 No Configuration，</description>
    </item>
    
    <item>
      <title>Oatpp框架简单项目初次启动</title>
      <link>https://realjf.io/cpp/oatpp-project-start/</link>
      <pubDate>Mon, 14 Sep 2020 16:30:24 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/oatpp-project-start/</guid>
      <description>准备  window10系统 已配置好c++开发环境的vscode visual studio 2019&amp;frasl;2017  方法一 开始 # 新建项目目录 mkdir oatpp_example cd oatpp_example mkdir src type null &amp;gt; CMakeLists.txt type null &amp;gt; src/main.cpp  写代码 src/main.cpp的内容如下：
#include &amp;quot;oatpp/web/server/HttpConnectionHandler.hpp&amp;quot; #include &amp;quot;oatpp/network/server/Server.hpp&amp;quot; #include &amp;quot;oatpp/network/server/SimpleTCPConnectionProvider.hpp&amp;quot; class Handler : public oatpp::web::server::HttpRequestHandler { public: /** * Handle incoming request and return outgoing response. */ std::shared_ptr&amp;lt;OutgoingResponse&amp;gt; handle(const std::shared_ptr&amp;lt;IncomingRequest&amp;gt;&amp;amp; request) override { return ResponseFactory::createResponse(Status::CODE_200, &amp;quot;Hello World!&amp;quot;); } }; void run() { /* Create Router for HTTP requests routing */ auto router = oatpp::web::server::HttpRouter::createShared(); /* Route GET - &amp;quot;/hello&amp;quot; requests to Handler */ router-&amp;gt;route(&amp;quot;GET&amp;quot;, &amp;quot;/hello&amp;quot;, std::make_shared&amp;lt;Handler&amp;gt;()); /* Create HTTP connection handler with router */ auto connectionHandler = oatpp::web::server::HttpConnectionHandler::createShared(router); /* Create TCP connection provider */ auto connectionProvider = oatpp::network::server::SimpleTCPConnectionProvider::createShared(8000 /*port*/); /* Create server which takes provided TCP connection and passes them to HTTP connection handler */ oatpp::network::server::Server server(connectionProvider, connectionHandler); /* Priny info about server port */ OATPP_LOGI(&amp;quot;MyApp&amp;quot;, &amp;quot;Server running on port %s&amp;quot;, connectionProvider-&amp;gt;getProperty(&amp;quot;port&amp;quot;).</description>
    </item>
    
    <item>
      <title>Windows下 Vscode Cpp开发环境配置</title>
      <link>https://realjf.io/posts/vscode-win-cpp-setting/</link>
      <pubDate>Mon, 14 Sep 2020 15:59:09 +0800</pubDate>
      
      <guid>https://realjf.io/posts/vscode-win-cpp-setting/</guid>
      <description>前期准备  win10 系统 安装好vscode 安装好git 安装好cmake for windows 安装好mingw64 安装好visual studio 2019&amp;frasl;2017   本次c++开发项目主要依赖于cmake和visual studio作为编译工具
开始配置vscode 首先打开vscode，安装一下插件   ms-vscode.cpptools ms-vscode.cmake-tools formulahendry.code-runner  然后开始c++配置 按住ctrl+p，打开vscode的命令模式, 输入&amp;rdquo;&amp;gt; edit Configurations&amp;rdquo;，然后选择 c/c++ edit Configurations(JSON)，打开 c_cpp_properties.json文件
开始编辑c_cpp_properties.json文件 { &amp;quot;configurations&amp;quot;: [ { &amp;quot;name&amp;quot;: &amp;quot;GCC&amp;quot;, &amp;quot;includePath&amp;quot;: [ &amp;quot;${workspaceFolder}/**&amp;quot;, &amp;quot;C:\\Program Files (x86)\\oatpp\\include\\oatpp-1.1.0\\oatpp&amp;quot; // 这里添加第三方库目录 ], &amp;quot;defines&amp;quot;: [ &amp;quot;_DEBUG&amp;quot;, &amp;quot;UNICODE&amp;quot;, &amp;quot;_UNICODE&amp;quot; ], &amp;quot;windowsSdkVersion&amp;quot;: &amp;quot;10.0.15063.0&amp;quot;, &amp;quot;compilerPath&amp;quot;: &amp;quot;E:\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin\\g++.exe&amp;quot;, // 这里改成你安装mingw64下的g++.exe文件路径 &amp;quot;cStandard&amp;quot;: &amp;quot;c11&amp;quot;, &amp;quot;cppStandard&amp;quot;: &amp;quot;c++17&amp;quot;, &amp;quot;intelliSenseMode&amp;quot;: &amp;quot;gcc-x64&amp;quot; // 这里是模式选择 } ], &amp;quot;version&amp;quot;: 4 }  配置完成后，在vscode的工作目录下有个.</description>
    </item>
    
    <item>
      <title>Go Mod Module Declares Its Path as: xxxx but was required as: xxxx</title>
      <link>https://realjf.io/golang/go-mod-module-declares-error/</link>
      <pubDate>Wed, 09 Sep 2020 09:18:15 +0800</pubDate>
      
      <guid>https://realjf.io/golang/go-mod-module-declares-error/</guid>
      <description> 背景 今天在一个新项目文件下执行了go mod init初始化后，进行go build，报如下错误：
go: example imports github.com/realjf/goframe: github.com/realjf/goframe@v0.0.0-20200908085940-3b9391b761c4: parsing go.mod: module declares its path as: goframe but was required as: github.com/realjf/goframe  意思是，模块声明为goframe，但是却使用github.com/realjf/goframe作为包引入
解决方法 首先确认引入的包的go.mod文件里的module名称是否为github.com/realjf/goframe,
如果是，则进行下一步，如果不是，则需要修改为module github.com/realjf/goframe
然后是在新项目的go.mod文件中新增一行如下内容：
# 格式为：replace (module declares its path as:后边那部分) =&amp;gt; (but was required as:后边那部分) 版本号 replace goframe =&amp;gt; github.com/realjf/goframe v0.0.0 // indirect  之后重新执行go build，可以发现问题解决，并且在go.mod文件中多了一行：
require github.com/realjf/goframe v0.0.0-20200908095551-2f2da0b85d99  </description>
    </item>
    
    <item>
      <title>PHP启动时配置文件显示： Loaded Configuration File 为 none</title>
      <link>https://realjf.io/php/start-with-config-file-none/</link>
      <pubDate>Mon, 07 Sep 2020 18:00:11 +0800</pubDate>
      
      <guid>https://realjf.io/php/start-with-config-file-none/</guid>
      <description>PHP启动时配置文件显示： Loaded Configuration File 为 none 首先查看php 的配置情况 php --ini # 输出如下 Configuration File (php.ini) Path: /data/conf/etc/php.ini Loaded Configuration File: (none) Scan for additional .ini files in: (none) Additional .ini files parsed: (none)  可以看到Loaded Configuration File的配置项为none，如果你直接在teminal中执行php运行代码，可能出现配置一些配置未加载的情况 ，特别是一些扩展未加载情况导致的无法使用扩展
解决方法 如果有strace，可以使用strace跟踪下php的执行情况
strace /usr/local/php/bin/php -i 2&amp;gt; /tmp/ll.log # 然后使用grep查看跟踪中出现加载php.ini的路径 grep &#39;php.ini&#39; /tmp/ll.log # 结果如下： open(&amp;quot;/usr/local/php/bin/php.ini&amp;quot;, O_RDONLY) = -1 ENOENT (No such file or directory) open(&amp;quot;/usr/local/php/etc/php.ini&amp;quot;, O_RDONLY) = -1 ENOENT (No such file or directory)  可以看到首先加载了/usr/local/php/bin/目录下的php.</description>
    </item>
    
    <item>
      <title>平衡二叉树 Avl Tree</title>
      <link>https://realjf.io/algorithm/tree/avl-tree/</link>
      <pubDate>Wed, 22 Jul 2020 10:31:57 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/tree/avl-tree/</guid>
      <description>平衡二叉树定义  左子树上的所有节点的值都比根节点的值小 右子树上的所有节点的值都比根节点的值大 左子树与右子树的高度差最大为1 二叉树中每棵子树都要求是平衡二叉树  平衡二叉树性质  高为h的BT, 其结点的数目在2^(h+1)-1和1/2(3^(h+1)−1)之间, 叶的数目在2^h和3^h之间  平衡因子 平衡因子：左子树的高度减去右子树的高度，即B = B左 - B右。 由平衡二叉树的定义可知，平衡因子的取值只可能为0，1，-1。
 0：左右子树等高。 1：左子树比较高。 -1：右子树比较高。  平衡二叉树失衡与再平衡 当平衡因子的值大于-1或者大于1时，则该树不再平衡，需要进行再平衡，再平衡通过旋转的方式实现。
再平衡可以通过LL、RR、LR、RL旋转方式进行
LL旋转 LL，如下图，我们真实的三个节点为Y &amp;gt; X &amp;gt; Z。然后我们为了方便描述，增加几个虚拟的节点，节点间的大小关系：T1&amp;lt;Z&amp;lt;T2&amp;lt; X &amp;lt;T3&amp;lt;Y&amp;lt;T4
 /////////////////////////////////////////////////// // LL T1&amp;lt;Z&amp;lt;T2&amp;lt; X &amp;lt;T3&amp;lt;Y&amp;lt;T4 // // y x // // / \ / \ // // x T4 向右旋转 (y) z y // // / \ - - - - - - - -&amp;gt; / \ / \ // // z T3 T1 T2 T3 T4 // // / \ // // T1 T2 // ///////////////////////////////////////////////////  对于LL，我们要右旋才能达到再平衡，根据之前描述，我们需要将Y节点顶替T3的位置，问题来了，T3放哪呢？ 根据大小关系 X &amp;lt; T3 &amp;lt; Y。我们可以将T3放到Y的左孩子节点的位置，这样进行旋转后得到的结果如上所示。 我们发现这棵树不但达到了再平衡的目的，节点间的大小关系，依然维持了：T1&amp;lt;Z&amp;lt;T2&amp;lt; X &amp;lt;T3&amp;lt;Y&amp;lt;T4的关系。</description>
    </item>
    
    <item>
      <title>二叉搜索树 Binary Search Tree</title>
      <link>https://realjf.io/algorithm/tree/binary-search-tree/</link>
      <pubDate>Wed, 22 Jul 2020 09:37:10 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/tree/binary-search-tree/</guid>
      <description>二叉搜索树的性质  若任意节点的左子树不空，则左子树上所有节点的值均不大于它的根节点的值 若任意节点的右子树不空，则右子树上所有节点的值均不小于它的根节点的值 任意节点的左右子树分别为二叉搜索树  二叉搜索树的特点  有链表的快速插入与删除操作 也有数组快速查找的优势  二叉搜索树的复杂度  平均每次操作需要O(logn)的时间  在最优的情况下，二叉搜索树为完全二叉树，其平均比较次数为logN,在最差情况下，二叉搜索树退化为单支树，其平均比较次数为N
如果退化成单支树，二叉搜索树的性能就失去了，如何改进呢？这将在平衡二叉树AVL树中进行讲述。
二叉搜索树的实现 #include &amp;lt;iostream&amp;gt; using namespace std; template&amp;lt;class T&amp;gt; struct BSTNode { BSTNode(const T&amp;amp; key = T()) : _left(nullptr), _right(nullptr), _key(key) { } BSTNode&amp;lt;T&amp;gt;* _left; BSTNode&amp;lt;T&amp;gt;* _right; T _key; }; template&amp;lt;class T&amp;gt; class BSTree { typedef BSTNode&amp;lt;T&amp;gt; Node; public: BSTree() : _root(nullptr) { } ~BSTree() { } BSTree(const BSTree&amp;lt;T&amp;gt;&amp;amp; tree) { _root = Copy(tree.</description>
    </item>
    
    <item>
      <title>php websocket简单使用 Simple Websocket</title>
      <link>https://realjf.io/php/simple-websocket/</link>
      <pubDate>Sat, 13 Jun 2020 18:14:12 +0800</pubDate>
      
      <guid>https://realjf.io/php/simple-websocket/</guid>
      <description>环境准备  php 7 linux 系统  服务端 websocket.php 文件 &amp;lt;?php $address = &#39;0.0.0.0&#39;; $port = 8000; // 创建socket $server = socket_create(AF_INET, SOCK_STREAM, SOL_TCP); socket_set_option($server, SOL_SOCKET, SO_REUSEADDR, 1); socket_bind($server, $address, $port); socket_listen($server); $client = socket_accept($server); // 发送websokcet握手 header $request = socket_read($client, 5000); // 读取数据 preg_match(&#39;#Sec-WebSocket-Key: (.*)\r\n#&#39;, $request, $matches); $key = base64_encode(pack( &#39;H*&#39;, sha1($matches[1] . &#39;258EAFA5-E914-47DA-95CA-C5AB0DC85B11&#39;) )); $headers = &amp;quot;HTTP/1.1 101 Switching Protocols\r\n&amp;quot;; $headers .= &amp;quot;Upgrade: websocket\r\n&amp;quot;; $headers .= &amp;quot;Connection: Upgrade\r\n&amp;quot;; $headers .</description>
    </item>
    
    <item>
      <title>linux下的安卓模拟器anbox安装 How to Set Up Anbox in Linux</title>
      <link>https://realjf.io/posts/how-to-set-up-anbox-in-linux/</link>
      <pubDate>Sat, 13 Jun 2020 16:55:14 +0800</pubDate>
      
      <guid>https://realjf.io/posts/how-to-set-up-anbox-in-linux/</guid>
      <description>环境准备  kali linux 2020  开始 # 使用下面的 PPA 来安装它 add-apt-repository ppa:morphis/anbox-support apt update apt install linux-headers-generic anbox-modules-dkms # 在你安装 anbox-modules-dkms 软件包后，你必须手动重新加载内核模块，或需要系统重新启动 modprobe ashmem_linux modprobe binder_linux # 使用 APT-GET 命令 或 APT 命令 来安装 anbox apt install anbox # 否则，需要通过 snap 来进行安装 apt install snapd snap install --classic anbox-install &amp;amp;&amp;amp; anbox-installer snap install --devmode --beta anbox  默认情况下，Anbox 并没有带有 Google Play Store。因此，我们需要手动下载每个应用程序（APK），并使用 Android 调试桥（ADB）安装它
# 对于 Debian/Ubuntu 系统，使用 APT-GET 命令 或 APT 命令 来安装 ADB apt install android-tools-adb  启动anbox container服务 systemctl enable anbox-container-manager systemctl start anbox-container-manager # 期间如果遇到服务启动失败，可以查看对应的错误日志，可能是因为android.</description>
    </item>
    
    <item>
      <title>简单的基于Elasticsearch-php API的封装 Library Elasticsearch Api Client</title>
      <link>https://realjf.io/elasticsearch/library-elasticsearch-api-client/</link>
      <pubDate>Wed, 10 Jun 2020 11:56:47 +0800</pubDate>
      
      <guid>https://realjf.io/elasticsearch/library-elasticsearch-api-client/</guid>
      <description>abstract class libEsBase { protected $__index = &amp;quot;&amp;quot;; protected $__type = &amp;quot;&amp;quot;; const MAX_RESULT_WINDOW = 10000; // from + size &amp;lt;= max_result_window /** * 定义结构 * @return array */ abstract protected function __getMapping(); /** * @var \Elasticsearch\Client */ protected $_es = null; public function __construct() { $this-&amp;gt;_es = &amp;quot;your elasticsearch-php api client&amp;quot;; } /** * @return array */ protected function __runBefore() { if(!$this-&amp;gt;checkEsAlive()){ return [FALSE, &amp;quot;Elasticsearch not alive&amp;quot;]; } list($check, $msg) = $this-&amp;gt;checkIndex(); if(!</description>
    </item>
    
    <item>
      <title>elasticsearch随机获取数据 random Fetch Data</title>
      <link>https://realjf.io/elasticsearch/random-fetch-data/</link>
      <pubDate>Wed, 10 Jun 2020 11:47:39 +0800</pubDate>
      
      <guid>https://realjf.io/elasticsearch/random-fetch-data/</guid>
      <description>搜索的形式随机获取数据
{ &amp;quot;query&amp;quot;: { &amp;quot;bool&amp;quot;: { &amp;quot;must&amp;quot;: [{ &amp;quot;term&amp;quot;: { &amp;quot;game_id&amp;quot;: 132 } }] } }, &amp;quot;from&amp;quot;: 1, &amp;quot;size&amp;quot;: 100, &amp;quot;sort&amp;quot;: { &amp;quot;_script&amp;quot;: { &amp;quot;script&amp;quot;: &amp;quot;Math.random()&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;number&amp;quot;, &amp;quot;order&amp;quot;: &amp;quot;asc&amp;quot; } } }  </description>
    </item>
    
    <item>
      <title>elasticsearch的doc_values和fielddata区别</title>
      <link>https://realjf.io/elasticsearch/docvalues-fielddata/</link>
      <pubDate>Thu, 04 Jun 2020 18:15:14 +0800</pubDate>
      
      <guid>https://realjf.io/elasticsearch/docvalues-fielddata/</guid>
      <description>Elasticsearch 首先分析文档，之后根据结果创建倒排索引。
倒排索引 Elasticsearch 使用一种称为 倒排索引 的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。
doc_values doc_values使聚合更快、更高效且内存使用率高。
在 Elasticsearch 中，doc_values 就是一种列式存储结构，默认情况下每个字段的 doc_values 都是激活的， doc_values 是在索引时创建的。当字段索引时，Elasticsearch 为了能够快速检索，会把字段的值加入倒排索引中，同时它也会存储该字段的 doc_values。
Elasticsearch 中的 doc_values 常被应用到以下场景：
 对一个字段进行排序 对一个字段进行聚合 某些过滤，比如地理位置过滤 某些与字段相关的脚本计算  因为文档值（doc_values）被序列化到磁盘，我们可以依靠操作系统的帮助来快速访问。 当 working set 远小于节点的可用内存，系统会自动将所有的文档值保存在内存中，使得其读写十分高速； 当其远大于可用内存，操作系统会自动把 doc_values 加载到系统的页缓存中，从而避免了 jvm 堆内存溢出异常。
 因此，搜索和聚合是相互紧密缠绕的。搜索使用倒排索引查找文档，聚合操作收集和聚合 doc_values 里的数据。
 doc_values 支持大部分字段类型，但是text 字段类型不支持（因为analyzed）。
{ &amp;quot;mappings&amp;quot;: { &amp;quot;properties&amp;quot;: { &amp;quot;status_code&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot; }, &amp;quot;session_id&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;keyword&amp;quot;, &amp;quot;doc_values&amp;quot;: false } } } }   (1) status_code 字段默认启动 doc_values 属性； (2) session_id 显式设置 doc_values = false，但是仍然可以被查询；   如果确信某字段不需要排序或者聚合，或者从脚本中访问字段值，那么我们可以设置 doc_values = false，这样可以节省磁盘空间。</description>
    </item>
    
    <item>
      <title>汇编语言之引导加载程序 Bootloaders</title>
      <link>https://realjf.io/assembly/bootloaders/</link>
      <pubDate>Sun, 31 May 2020 08:55:50 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/bootloaders/</guid>
      <description>什么是引导加载程序 引导加载程序是一小段软件，可在打开计算机电源后加载操作系统并准备执行。发生这种情况的方式在不同的计算机设计之间会有所不同（早期的计算机需要一个人在每次打开计算机时手动对其进行设置），并且在引导加载过程中通常有多个阶段。
至关重要的是要理解术语“引导程序”只是软件的一种分类（有时是模糊的）。对于处理器来说，引导加载程序只是它盲目执行的另一段代码。引导加载程序有许多种。有些很小，有些很大。 有些遵循非常简单的规则，而另一些则显示精美的屏幕并为用户提供选择的选择。
在与IBM PC兼容的计算机上，要加载的第一个程序是基本输入/输出系统（BIOS）。BIOS执行许多测试和初始化，如果一切正常，则BIOS的启动加载程序开始。其目的是加载另一个引导加载程序！ 它选择一个磁盘（或某些其他存储介质）从中加载辅助引导加载程序。
在某些情况下，此引导加载程序会加载足够的操作系统以开始运行它。在其他情况下，它将从其他位置加载另一个引导加载程序。当在一台计算机上安装多个操作系统时，通常会发生这种情况。 每个OS可能都有自己的特定引导加载程序，而“中央”引导加载程序会根据用户的选择加载特定的引导加载程序之一。
大多数引导加载程序都是用汇编语言（甚至是机器代码）专门编写的，因为它们需要紧凑，无法访问其他语言可能需要的OS例程（例如内存分配），因此需要遵循一些不寻常的要求，并且它们频繁使用低级功能。 但是，某些引导加载程序（尤其是那些具有许多功能并允许用户输入的引导加载程序）非常重。这些通常是用Assembly和C的组合编写的。GRand Unified Bootloader（GRUB）就是这样的一个例子。
一些引导加载程序是高度特定于操作系统的，而其他引导加载程序则不太特定-当然，BIOS引导加载程序不是特定于操作系统的。 MS-DOS引导加载程序（放置在所有 MS-DOS格式的软盘上）仅检查文件IO.SYS和MSDOS.SYS是否存在；否则，仅将其检查。 如果它们不存在，则显示错误“非系统磁盘或磁盘错误”，否则它将加载并开始执行IO.SYS。
可能（通过操作系统）期望最后阶段的引导加载程序以某种方式准备计算机，例如，通过将处理器置于保护模式并对中断控制器进行编程。 尽管可以在操作系统的初始化过程中完成这些操作，但将它们移至引导加载程序可以简化操作系统的设计。 某些操作系统要求其引导加载程序设置一个小的基本GDT（全局描述符表）并进入保护模式，以消除操作系统具有任何16位代码的需要。 但是，操作系统可能很快会用其自己的复杂GDT代替它。
引导区 磁盘的前512个字节称为引导扇区或主引导记录。引导扇区是磁盘上保留的用于引导目的的区域。 如果磁盘的引导扇区包含有效的引导扇区（扇区的最后一个字必须包含签名0xAA55），则BIOS会将磁盘视为可引导磁盘。
引导过程 当打开或重置时，x86处理器开始执行在地址FFFF：0000处找到的指令（在此阶段它以实模式运行）（英特尔软件开发人员手册第3卷第9章与以下信息矛盾：执行从物理地址开始0xFFFFFFF0，等等。 在与IBM PC兼容的处理器中，此地址映射到ROM芯片，该芯片包含计算机的基本输入/输出系统（BIOS）代码。BIOS负责许多测试和初始化。 例如，BIOS可以执行内存测试，初始化中断控制器和系统计时器并测试这些设备是否正常运行。
最终，实际的引导加载开始了。BIOS首先搜索并初始化可用的存储介质（例如软盘驱动器，硬盘，CD驱动器），然后确定要尝试从中引导的存储介质。 它会检查每个设备的可用性（例如，确保软盘驱动器包含磁盘），然后按照某些预定义的顺序检查0xAA55签名（通常可以使用BIOS设置工具配置该顺序）。 它将遇到的第一个可启动设备的第一个扇区加载到RAM中，并启动执行。
理想情况下，这将是另一个引导加载程序，它将继续工作，进行一些准备，然后将控制权传递给其他东西。
尽管BIOS仍与已有20年历史的软件兼容，但随着时间的推移，它们也变得越来越复杂。早期的BIOS无法从CD驱动器引导，但是现在CD甚至DVD引导都是标准的BIOS功能。 也可以从USB存储设备启动，某些系统可以通过网络启动。为了实现这种高级功能，BIOS有时会进入保护模式等，但随后返回实模式以与旧版引导加载程序兼容。 这就产生了一个麻烦的问题：编写引导加载程序以与普遍存在的BIOS配合使用，并且编写BIOS来支持所有这些引导加载程序，从而在很大程度上避免了新的引导加载功能。
技术细节 引导加载程序在程序员必须理解的某些条件下运行，以便制作成功的引导加载程序。以下与PC BIOS启动的引导加载程序有关：
 驱动器的第一个扇区包含其引导加载程序。 一个扇区为512字节-最后两个字节必须为0xAA55（即0x55后跟0xAA），否则BIOS将驱动器视为不可引导。 如果一切正常，则所述第一个扇区将放置在RAM地址0000：7C00上，并且BIOS的角色已经结束，因为它将控制权转移到0000：7C00（即，将JMP传递到该地址）。 DL寄存器将包含正在从中引导的驱动器号，如果您想从驱动器上的其他位置读取更多数据，则很有用。 BIOS留下了大量代码，既可以处理硬件中断（例如按键），又可以为Bootloader和OS提供服务（例如键盘输入，磁盘读取和写入屏幕）。 您必须了解中断向量表（IVT）的用途，并注意不要干扰您所依赖的BIOS部分。大多数操作系统用自己的代码替换BIOS代码，但是引导加载程序只能使用自己的代码以及BIOS提供的内容来使用。 有用的BIOS服务包括int 10h（用于显示文本/图形），int 13h（磁盘功能）和int 16h（键盘输入）。 这意味着引导加载程序需要的任何代码或数据都必须包含在第一个扇区中（请注意不要意外执行数据），或者必须将其从磁盘的另一个扇区手动加载到RAM中的某个位置。 由于操作系统尚未运行，因此大部分RAM将不使用。但是，您必须注意不要干扰上述BIOS中断处理程序和服务所需的RAM。 操作系统代码本身（或下一个引导程序）也需要加载到RAM中。 BIOS将堆栈指针放在引导扇区末尾之外的512个字节中，这意味着堆栈不能超过512个字节。可能有必要将堆栈移动到更大的区域。 如果要在主流操作系统下读取磁盘，则需要遵守一些约定。例如，您可能希望在软盘上包括BIOS参数块，以使该盘在大多数PC操作系统下均可读。  大多数汇编器都会具有ORG 7C00h与之类似的命令或指令，以通知汇编器将从偏移量7C00h开始加载代码。 汇编程序在计算指令和数据地址时会考虑到这一点。如果不考虑这一点，则汇编程序将假定代码已加载到地址0，并且必须在代码中手动对其进行补偿。
通常，引导程序会将内核加载到内存中，然后跳转到内核。然后，内核将能够回收引导加载程序使用的内存（因为它已经执行了其工作）。但是，可以在引导扇区中包含OS代码，并在OS启动后将其保留在驻留位置。
这是为NASM设计的简单引导程序演示：
org 7C00h jmp short Start ;Jump over the data (the &#39;short&#39; keyword makes the jmp instruction smaller) Msg: db &amp;quot;Hello World!</description>
    </item>
    
    <item>
      <title>汇编语言之linux系统调用接口</title>
      <link>https://realjf.io/assembly/interfacing-with-linux/</link>
      <pubDate>Sun, 31 May 2020 08:13:52 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/interfacing-with-linux/</guid>
      <description>syscalls Syscall是用户程序和Linux内核之间的接口。它们用于让内核执行各种系统任务，例如文件访问，进程管理和联网。 在C编程语言中，您通常会调用包装函数，该函数执行所有必需的步骤，甚至使用高级功能（例如标准IO库）。
在Linux上，有几种方法可以进行系统调用。该页面将重点介绍通过使用int $ 0x80或syscall调用软件中断来进行syscall。这是在仅汇编程序中进行系统调用的简单直观的方法
系统调用 为了使用中断进行系统调用，您必须通过将所有必需的信息复制到通用寄存器中来将其传递给内核
每个系统调用都有一个固定的数字（注意：数字在int $ 0x80和系统调用之间有所不同！）。您可以通过将数字写入eax / rax寄存器来指定系统调用。
大多数系统调用都使用参数来执行其任务。通过在进行实际调用之前将它们写入适当的寄存器中来传递这些参数。 每个参数索引都有一个特定的寄存器。请参阅小节中的表，因为int $ 0x80和syscall之间的映射不同。参数按照它们在相应C包装函数的函数签名中出现的顺序传递 您可以在每个Linux API文档中找到syscall函数及其签名，例如参考手册（键入man 2 open以查看打开的syscall的签名）。
一切设置正确后，您可以使用int $ 0x80或syscall调用中断，内核将执行任务
系统调用的返回/错误值被写入eax / rax。
 内核使用自己的堆栈来执行操作。不会以任何方式触摸用户堆栈。
 int 0x80 在Linux x86和Linux x86_64系统上，都可以使用int $ 0x80命令调用中断0x80进行系统调用。通过如下设置通用寄存器来传递参数：
   Syscall # Param 1 Param 2 Param 3 Param 4 Param 5 Param 6     eax ebx ecx edx esi edi ebp       Return value     eax    系统调用号在Linux生成的文件$ build / arch / x86 / include / generated / uapi / asm / unistd_32.</description>
    </item>
    
    <item>
      <title>nasm汇编之宏 Macros</title>
      <link>https://realjf.io/assembly/macros/</link>
      <pubDate>Sun, 31 May 2020 06:13:27 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/macros/</guid>
      <description>编写宏是确保使用汇编语言进行模块化编程的另一种方法。
 宏是由名称分配的一系列指令，可以在程序中的任何位置使用。 在NASM中，宏使用％macro和％endmacro指令定义 宏以％macro指令开头，以％endmacro指令结尾  语法
%macro macro_name number_of_params &amp;lt;macro body&amp;gt; %endmacro  其中，number_of_params指定数字参数，macro_name指定宏的名称。
通过使用宏名称和必要的参数来调用宏。当您需要在程序中多次使用某些指令序列时，可以将这些指令放在宏中并使用它，而不必一直写指令。
例如，程序的一个非常普遍的需求是在屏幕上写一个字符串。要显示字符串，需要以下说明序列
mov edx,len ;message length mov ecx,msg ;message to write mov ebx,1 ;file descriptor (stdout) mov eax,4 ;system call number (sys_write) int 0x80 ;call kernel  在以上显示字符串的示例中，INT 80H函数调用已使用寄存器EAX，EBX，ECX和EDX。 因此，每次需要在屏幕上显示时，都需要将这些寄存器保存在堆栈中，调用INT 80H，然后从堆栈中恢复寄存器的原始值。因此，编写两个用于保存和还原数据的宏可能会很有用
我们已经观察到，某些指令（如IMUL，IDIV，INT等）需要将某些信息存储在某些特定的寄存器中，甚至返回某些特定寄存器中的值。 如果程序已经使用这些寄存器来保存重要数据，则应将这些寄存器中的现有数据保存在堆栈中，并在执行指令后将其恢复。
示例
; A macro with two parameters ; Implements the write system call %macro write_string 2 mov eax, 4 mov ebx, 1 mov ecx, %1 mov edx, %2 int 80h %endmacro section .</description>
    </item>
    
    <item>
      <title>nasm汇编之递归 Recursion</title>
      <link>https://realjf.io/assembly/recursion/</link>
      <pubDate>Sun, 31 May 2020 06:13:15 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/recursion/</guid>
      <description>递归过程是一个可以自我调用的过程。递归有两种：直接和间接。 在直接递归中，该过程调用自身，在间接递归中，第一个过程调用第二个过程，第二个过程依次调用第一个过程。
以下程序显示了如何使用汇编语言实现阶乘n。为了简化程序，我们将计算阶乘3
section .text global _start ;must be declared for using gcc _start: ;tell linker entry point mov bx, 3 ;for calculating factorial 3 call proc_fact add ax, 30h mov [fact], ax mov edx,len ;message length mov ecx,msg ;message to write mov ebx,1 ;file descriptor (stdout) mov eax,4 ;system call number (sys_write) int 0x80 ;call kernel mov edx,1 ;message length mov ecx,fact ;message to write mov ebx,1 ;file descriptor (stdout) mov eax,4 ;system call number (sys_write) int 0x80 ;call kernel mov eax,1 ;system call number (sys_exit) int 0x80 ;call kernel proc_fact: cmp bl, 1 jg do_calculation mov ax, 1 ret do_calculation: dec bl call proc_fact inc bl mul bl ;ax = al * bl ret section .</description>
    </item>
    
    <item>
      <title>nasm汇编之过程 Procedures</title>
      <link>https://realjf.io/assembly/procedures/</link>
      <pubDate>Sun, 31 May 2020 03:23:47 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/procedures/</guid>
      <description>过程或子例程在汇编语言中非常重要，因为汇编语言程序往往会很大。程序由名称标识。 在此名称之后，将描述执行明确定义的作业的过程主体。该过程的结束由return语句指示。
语法
proc_name: procedure body ... ret  通过使用CALL指令从另一个函数调用该过程。 CALL指令应将被调用过程的名称作为参数，如下所示
CALL proc_name  示例
Live Demo section .text global _start ;must be declared for using gcc _start: ;tell linker entry point mov ecx,&#39;4&#39; sub ecx, &#39;0&#39; mov edx, &#39;5&#39; sub edx, &#39;0&#39; call sum ;call sum procedure mov [res], eax mov ecx, msg mov edx, len mov ebx,1 ;file descriptor (stdout) mov eax,4 ;system call number (sys_write) int 0x80 ;call kernel mov ecx, res mov edx, 1 mov ebx, 1 ;file descriptor (stdout) mov eax, 4 ;system call number (sys_write) int 0x80 ;call kernel mov eax,1 ;system call number (sys_exit) int 0x80 ;call kernel sum: mov eax, ecx add eax, edx add eax, &#39;0&#39; ret section .</description>
    </item>
    
    <item>
      <title>nasm汇编之数组 Arrays</title>
      <link>https://realjf.io/assembly/arrays/</link>
      <pubDate>Sun, 31 May 2020 03:23:36 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/arrays/</guid>
      <description>汇编程序的数据定义指令用于为变量分配存储空间。 变量也可以用一些特定的值初始化。初始化值可以以十六进制，十进制或二进制形式指定
我们可以通过以下两种方式之一来定义单词变量“ months”
MONTHS DW 12 MONTHS DW 0CH MONTHS DW 0110B  数据定义指令还可用于定义一维数组。让我们定义一维数字数组
NUMBERS DW 34, 45, 56, 67, 75, 89  上面的定义声明了一个六个字的数组，每个字都用数字34、45、56、67、75、89初始化。这分配了2x6 = 12个字节的连续存储空间。 第一个数字的符号地址为NUMBERS，第二个数字的符号地址为NUMBERS + 2，依此类推
您可以定义一个大小为8的名为清单的数组，并将所有值初始化为零，如下所示：
INVENTORY DW 0 DW 0 DW 0 DW 0 DW 0 DW 0 DW 0 DW 0  可以缩写为
INVENTORY DW 0, 0 , 0 , 0 , 0 , 0 , 0 , 0  TIMES指令还可用于将多个初始化为相同的值。使用TIMES，可以将INVENTORY数组定义为
INVENTORY TIMES 8 DW 0  示例</description>
    </item>
    
    <item>
      <title>nasm汇编之字符串 Strings</title>
      <link>https://realjf.io/assembly/strings/</link>
      <pubDate>Sun, 31 May 2020 03:23:28 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/strings/</guid>
      <description>可变长度的字符串可以根据需要包含任意多个字符。通常，我们通过两种方式之一指定字符串的长度
 显式存储字符串长度 使用前哨角色  我们可以使用表示位置计数器当前值的$位置计数器符号来显式存储字符串长度
msg db &#39;Hello, world!&#39;,0xa ;our dear string len equ $ - msg ;length of our dear string  $指向字符串变量msg的最后一个字符之后的字节。因此，$-msg给出字符串的长度。我们也可以写
msg db &#39;Hello, world!&#39;,0xa ;our dear string len equ 13 ;length of our dear string  另外，您可以存储带有尾部定点字符的字符串来分隔字符串，而不必显式存储字符串长度。 前哨字符应为不出现在字符串中的特殊字符。
例如：
message DB &#39;I am loving it!&#39;, 0  字符串指令 每个字符串指令可能需要一个源操作数，一个目标操作数或两者。对于32位段，字符串指令使用ESI和EDI寄存器分别指向源和目标操作数
但是，对于16位段，SI和DI寄存器分别用于指向源和目标。
有五个用于处理字符串的基本说明
 MOVS 该指令将1字节，字或双字数据从存储器位置移到另一个位置。 LODS 该指令从存储器加载。如果操作数是一个字节，则将其加载到AL寄存器中；如果操作数是一个字，则将其加载到AX寄存器中，并将双字加载到EAX寄存器中 STOS 该指令将数据从寄存器（AL，AX或EAX）存储到存储器。 CMPS 该指令比较存储器中的两个数据项。数据可以是字节大小，字或双字。 SCAS 该指令将寄存器（AL，AX或EAX）的内容与存储器中项目的内容进行比较。  上面的每个指令都有字节，字和双字版本，并且可以通过使用重复前缀来重复字符串指令</description>
    </item>
    
    <item>
      <title>nasm汇编之数值 Numbers</title>
      <link>https://realjf.io/assembly/numbers/</link>
      <pubDate>Sun, 31 May 2020 03:23:19 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/numbers/</guid>
      <description>数值数据通常用二进制表示。算术指令对二进制数据进行操作。当数字显示在屏幕上或通过键盘输入时，它们为ASCII格式
此类转换会产生开销，并且汇编语言编程允许以更有效的方式以二进制形式处理数字。小数可以两种形式表示
 ASCII格式 BCD或者二进制编码的十进制形式  ASCII表示 在ASCII表示中，十进制数字存储为ASCII字符串
有四条指令以ASCII表示形式处理数字
 AAA ASCII Adjust After Addition AAS ASCII Adjust After Subtraction AAM ASCII Adjust After Multiplication AAD ASCII Adjust Before Division  这些指令不使用任何操作数，并假定所需的操作数位于AL寄存器中
示例
section .text global _start ;must be declared for using gcc _start: ;tell linker entry point sub ah, ah mov al, &#39;9&#39; sub al, &#39;3&#39; aas or al, 30h mov [res], ax mov edx,len ;message length mov ecx,msg ;message to write mov ebx,1 ;file descriptor (stdout) mov eax,4 ;system call number (sys_write) int 0x80 ;call kernel mov edx,1 ;message length mov ecx,res ;message to write mov ebx,1 ;file descriptor (stdout) mov eax,4 ;system call number (sys_write) int 0x80 ;call kernel mov eax,1 ;system call number (sys_exit) int 0x80 ;call kernel section .</description>
    </item>
    
    <item>
      <title>nasm汇编之循环 Loops</title>
      <link>https://realjf.io/assembly/loops/</link>
      <pubDate>Sun, 31 May 2020 03:23:13 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/loops/</guid>
      <description>JMP指令可用于实现循环。例如，以下代码段可用于执行循环主体10次
MOV CL, 10 L1: &amp;lt;LOOP-BODY&amp;gt; DEC CL JNZ L1  但是，处理器指令集包括一组用于实现迭代的循环指令。基本的LOOP指令具有以下语法
LOOP label  其中，label是标识目标指令的目标标签，如跳转指令中所述。 LOOP指令假定ECX寄存器包含循环计数。 当执行循环指令时，ECX寄存器递减，并且控制跳至目标标签，直到ECX寄存器的值（即计数器达到零）为止。
示例
Live Demo section .text global _start ;must be declared for using gcc _start: ;tell linker entry point mov ecx,10 mov eax, &#39;1&#39; l1: mov [num], eax mov eax, 4 mov ebx, 1 push ecx mov ecx, num mov edx, 1 int 0x80 mov eax, [num] sub eax, &#39;0&#39; inc eax add eax, &#39;0&#39; pop ecx loop l1 mov eax,1 ;system call number (sys_exit) int 0x80 ;call kernel section .</description>
    </item>
    
    <item>
      <title>nasm汇编之条件判断 Conditions</title>
      <link>https://realjf.io/assembly/conditions/</link>
      <pubDate>Sun, 31 May 2020 03:23:03 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/conditions/</guid>
      <description>汇编语言中的条件执行是通过几个循环和分支指令来完成的。这些指令可以更改程序中的控制流。在两种情况下观察到条件执行
无条件跳转 这是通过JMP指令执行的。条件执行通常涉及将控制权转移到不遵循当前执行指令的指令的地址。 控制权的转移可以是前进，执行新指令集，也可以是后退，重新执行相同的步骤
有条件的跳转 这取决于条件由一组跳转指令j 执行。条件指令通过中断顺序流程来转移控制，而它们通过更改IP中的偏移值来完成
cmp指令 CMP指令比较两个操作数。它通常用于条件执行中。该指令基本上从另一个操作数中减去一个操作数，以比较操作数是否相等。 它不会干扰目标或源操作数。它与条件跳转指令一起用于决策。
语法
CMP destination, source  CMP比较两个数字数据字段。目标操作数可以在寄存器中或在内存中。源操作数可以是常量（立即数）数据，寄存器或内存
示例
CMP DX, 00 ; Compare the DX value with zero JE L7 ; If yes, then jump to label L7 . . L7: ...  CMP通常用于比较计数器值是否已达到需要运行循环的次数。考虑以下典型条件
INC EDX CMP EDX, 10 ; Compares whether the counter has reached 10 JLE LP1 ; If it is less than or equal to 10, then jump to LP1  无条件跳转 这是通过JMP指令执行的。条件执行通常涉及将控制权转移到不遵循当前执行指令的指令的地址。</description>
    </item>
    
    <item>
      <title>nasm汇编之逻辑指令 Logical Instructions</title>
      <link>https://realjf.io/assembly/logical-instructions/</link>
      <pubDate>Sun, 31 May 2020 02:16:58 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/logical-instructions/</guid>
      <description>处理器指令集提供指令AND，OR，XOR，TEST和NOT布尔逻辑，它们根据程序的需要测试，设置和清除位。
   序号 指令 格式     1 AND AND operand1, operand2   2 OR OR operand1, operand2   3 XOR XOR operand1, operand2   4 TEST TEST operand1, operand2   5 NOT NOT operand1    在所有情况下，第一个操作数都可以在寄存器或内存中。第二个操作数可以是寄存器/内存，也可以是立即数（常量）。 但是，内存到内存操作是不可能的。这些指令比较或匹配操作数的位，并设置CF，OF，PF，SF和ZF标志。
and指令 AND指令用于通过执行按位AND运算来支持逻辑表达式。如果两个操作数的匹配位均为1，则按位AND运算将返回1，否则返回0
AND操作可用于清除一个或多个位。例如，假设BL寄存器包含00111010。如果需要将高阶位清除为零，则将其与0FH
AND BL, 0FH ; This sets BL to 0000 1010  如果要检查给定数字是奇数还是偶数，一个简单的测试将是检查数字的最低有效位。如果为1，则数字为奇数，否则为偶数。
假设数字在AL寄存器中，我们可以写
AND AL, 01H ; ANDing with 0000 0001 JZ EVEN_NUMBER  示例</description>
    </item>
    
    <item>
      <title>nasm汇编之算术指令 Arithmetic Instructions</title>
      <link>https://realjf.io/assembly/arithmetic-instructions/</link>
      <pubDate>Sun, 31 May 2020 02:15:46 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/arithmetic-instructions/</guid>
      <description>inc 指令 INC指令用于将操作数加1。它适用于可以在寄存器或内存中的单个操作数
语法
INC destination  操作数目的地可以是8位，16位或32位操作数
示例
INC EBX ; Increments 32-bit register INC DL ; Increments 8-bit register INC [count] ; Increments the count variable  dec指令 DEC指令用于将操作数减1。它对可以在寄存器或内存中的单个操作数起作用
语法
DEC destination  操作数目的地可以是8位，16位或32位操作数。
示例
segment .data count dw 0 value db 15 segment .text inc [count] dec [value] mov ebx, count inc word [ebx] mov esi, value dec byte [esi]  add和sub指令 ADD和SUB指令用于对字节，字和双字大小的二进制数据进行简单的加/减，即分别用于添加或减去8位，16位或32位操作数
语法
ADD/SUB destination, source  ADD / SUB指令可以在</description>
    </item>
    
    <item>
      <title>nasm汇编之常量 Constants</title>
      <link>https://realjf.io/assembly/constants/</link>
      <pubDate>Sun, 31 May 2020 02:09:10 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/constants/</guid>
      <description>NASM提供了多个定义常量的指令。在前面的章节中，我们已经使用过EQU指令。我们将特别讨论三个指令
 EQU %assign %define  EQU指令 EQU指令用于定义常量。 EQU指令的语法如下
CONSTANT_NAME EQU expression  示例
TOTAL_STUDENTS equ 50  EQU语句的操作数可以是表达式
LENGTH equ 20 WIDTH equ 10 AREA equ length * width  示例
Live Demo SYS_EXIT equ 1 SYS_WRITE equ 4 STDIN equ 0 STDOUT equ 1 section .text global _start ;must be declared for using gcc _start: ;tell linker entry point mov eax, SYS_WRITE mov ebx, STDOUT mov ecx, msg1 mov edx, len1 int 0x80 mov eax, SYS_WRITE mov ebx, STDOUT mov ecx, msg2 mov edx, len2 int 0x80 mov eax, SYS_WRITE mov ebx, STDOUT mov ecx, msg3 mov edx, len3 int 0x80 mov eax,SYS_EXIT ;system call number (sys_exit) int 0x80 ;call kernel section .</description>
    </item>
    
    <item>
      <title>nasm汇编之变量 Variables</title>
      <link>https://realjf.io/assembly/variables/</link>
      <pubDate>Sun, 31 May 2020 01:50:22 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/variables/</guid>
      <description>NASM提供了各种定义指令来为变量保留存储空间。 define assembler指令用于分配存储空间。它可以用于保留以及初始化一个或多个字节
为初始化数据分配存储空间 初始化数据的存储分配语句的语法为
[variable-name] define-directive initial-value [,initial-value]...  其中，变量名是每个存储空间的标识符。汇编器为数据段中定义的每个变量名称关联一个偏移值。
五种基本类型指令
   指令 说明 存储空间     DB 定义字节 1 byte   DW 定义字 2 bytes   DD 定义双字 4 bytes   DQ 定义四字 8 bytes   DT 定义10字 10 bytes    示例
choice DB &#39;y&#39; number DW 12345 neg_number DW -12345 big_number DQ 123456789 real_number1 DD 1.234 real_number2 DQ 123.</description>
    </item>
    
    <item>
      <title>nasm汇编之寻址模式 Addressing Modes</title>
      <link>https://realjf.io/assembly/address-modes/</link>
      <pubDate>Sun, 31 May 2020 01:05:08 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/address-modes/</guid>
      <description>大多数汇编语言指令都需要处理操作数。操作数地址提供了要处理的数据存储的位置。一些指令不需要操作数，而另一些指令则可能需要一个，两个或三个操作数
当一条指令需要两个操作数时，第一个操作数通常是目的地，可能是寄存器或存储器地址，第二个操作数是源。 源包含要传递的数据（立即寻址）或数据的地址（在寄存器或存储器中）。通常，操作后源数据保持不变。
寻址的三种基本模式是
 寄存器寻址 立即寻址 内存寻址  寄存器寻址 在这种寻址模式下，寄存器包含操作数。根据指令，寄存器可以是第一操作数，第二操作数或两者。
MOV DX, TAX_RATE ; Register in first operand MOV COUNT, CX ; Register in second operand MOV EAX, EBX ; Both the operands are in registers  由于寄存器之间的数据处理不涉及内存，因此可以最快地处理数据
立即寻址 立即数操作数具有常数值或表达式。当具有两个操作数的指令使用立即寻址时，第一个操作数可以是寄存器或存储器位置，而第二个操作数是立即数。第一个操作数定义数据的长度。
BYTE_VALUE DB 150 ; A byte value is defined WORD_VALUE DW 300 ; A word value is defined ADD BYTE_VALUE, 65 ; An immediate operand 65 is added MOV AX, 45H ; Immediate constant 45H is transferred to AX  直接内存寻址 在内存寻址模式下指定操作数时，通常需要直接访问主存储器，通常是数据段。这种寻址方式导致数据处理速度变慢。 为了找到数据在内存中的确切位置，我们需要段起始地址（通常在DS寄存器中找到）和偏移值。此偏移值也称为有效地址。</description>
    </item>
    
    <item>
      <title>nasm汇编之系统调用 System Calls</title>
      <link>https://realjf.io/assembly/system-calls/</link>
      <pubDate>Sun, 31 May 2020 00:53:19 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/system-calls/</guid>
      <description>系统调用是用户空间和内核空间之间接口的API。我们已经使用了系统调用。 sys_write和sys_exit，分别用于写入屏幕和退出程序
linux 系统调用 您可以在汇编程序中使用Linux系统调用。您需要按照以下步骤在程序中使用Linux系统调用
 将系统调用编号放入EAX寄存器中 将系统调用的参数存放到EBX,ECX等寄存器 调用相关的中断 结果通常在EAX寄存器中返回  有六个寄存器，用于存储所用系统调用的参数。这些是EBX，ECX，EDX，ESI，EDI和EBP。 这些寄存器采用从EBX寄存器开始的连续参数。如果有六个以上的自变量，则第一个自变量的存储位置将存储在EBX寄存器中
以下代码段显示了系统调用sys_exit的使用
mov eax,1 ; system call number (sys_exit) int 0x80 ; call kernel  以下代码段显示了系统调用sys_write的使用
mov edx,4 ; message length mov ecx,msg ; message to write mov ebx,1 ; file descriptor (stdout) mov eax,4 ; system call number (sys_write) int 0x80 ; call kernel  所有系统调用及其编号（在调用int 80h之前放入EAX的值）都列在/usr/include/asm/unistd.h中
下表显示了使用的一些系统调用
   %eax name %ebx %ecx %edx %esx %edi     1 sys_exit int - - - -   2 sys_fork struct pt_regs - - - -   3 sys_read unsigned int char * size_t - -   4 sys_write unsigned int const char * size_t - -    示例 section .</description>
    </item>
    
    <item>
      <title>nasm汇编之寄存器 Register</title>
      <link>https://realjf.io/assembly/register/</link>
      <pubDate>Sun, 31 May 2020 00:52:44 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/register/</guid>
      <description>处理器操作主要涉及处理数据。该数据可以存储在存储器中并从其访问。 然而，从存储器中读取数据并将数据存储到存储器中会减慢处理器的速度，因为这涉及到通过控制总线发送数据请求并进入存储器存储单元并通过同一通道获取数据的复杂过程。
为了加速处理器的运行，处理器包括一些内部存储器存储位置，称为寄存器。
处理器寄存器 IA-32体系结构中有10个32位和6个16位处理器寄存器。寄存器分为三类
 通用寄存器 控制寄存器 段寄存器  通用寄存器进一步分为以下几类
 数据寄存器 指针寄存器 索引寄存器  数据寄存器 四个32位数据寄存器用于算术，逻辑和其他操作。这些32位寄存器可以三种方式使用-
 作为完整的32位数据寄存器：EAX，EBX，ECX，EDX。 下半部分的32位寄存器可用作四个16位数据寄存器：AX，BX，CX和DX。 上述四个16位寄存器的上半部分和下半部分可以用作八个8位数据寄存器：AH，AL，BH，BL，CH，CL，DH和DL。  其中一些数据寄存器在算术运算中有特定用途。
 AX是主要的累加器 ; 它用于输入/输出和大多数算术指令。例如，在乘法运算中，一个操作数根据操作数的大小存储在EAX或AX或AL寄存器中。 BX被称为基址寄存器，因为它可以用于索引寻址。 CX被称为计数寄存器，因为ECX，CX寄存器在迭代操作中存储循环计数。 DX被称为数据寄存器。它也用于输入/输出操作。它还与AX寄存器以及DX一起使用，用于涉及大数值的乘法和除法运算。  指针寄存器 指针寄存器是32位EIP，ESP和EBP寄存器以及相应的16位右部分IP，SP和BP。
指针寄存器分为三类
 指令指针（IP） -16位IP寄存器存储要执行的下一条指令的偏移地址。与CS寄存器关联的IP（作为CS：IP）给出了代码段中当前指令的完整地址。 堆栈指针（SP） -16位SP寄存器提供程序堆栈内的偏移值。与SS寄存器（SS：SP）关联的SP是指程序堆栈中数据或地址的当前位置。 基本指针（BP） -16位BP寄存器主要帮助参考传递给子例程的参数变量。SS寄存器中的地址与BP中的偏移量相结合，以获取参数的位置。BP也可以与DI和SI组合用作特殊寻址的基址寄存器。  索引寄存器 32位索引寄存器ESI和EDI及其最右边的16位部分。SI和DI用于索引寻址，有时用于加法和减法。有两组索引指针-
 源索引（SI） -用作字符串操作的源索引。 目的索引（DI） -用作字符串操作的目标索引。  控制寄存器 将32位指令指针寄存器和32位标志寄存器组合起来视为控制寄存器。
许多指令涉及比较和数学计算，并更改标志的状态，而其他一些条件指令则测试这些状态标志的值，以将控制流带到其他位置。
通用标志位是：
 溢出标志（OF） -指示有符号算术运算后数据的高阶位（最左位）的溢出。 方向标记（DF） -它确定向左或向右移动或比较字符串数据的方向。DF值为0时，字符串操作为从左至右的方向；当DF值为1时，字符串操作为从右至左的方向。 中断标志（IF） -确定是否忽略或处理外部中断（例如键盘输入等）。当值为0时，它禁用外部中断，而当值为1时，它使能中断。 陷阱标志（TF） -允许在单步模式下设置处理器的操作。我们使用的DEBUG程序设置了陷阱标志，因此我们可以一次逐步执行一条指令。 符号标志（SF） -显示算术运算结果的符号。根据算术运算后数据项的符号设置此标志。该符号由最左位的高位指示。正结果将SF的值清除为0，负结果将其设置为1。 零标志（ZF） -指示算术或比较运算的结果。非零结果会将零标志清零，零结果将其清零。 辅助进位标志（AF） -包含经过算术运算后从位3到位4的进位；用于专业算术。当1字节算术运算引起从第3位到第4位的进位时，将设置AF。 奇偶校验标志（PF） -指示从算术运算获得的结果中1位的总数。偶数个1位将奇偶校验标志清为0，奇数个1位将奇偶校验标志清为1。 进位标志（CF） -在算术运算后，它包含一个高位（最左边）的0或1进位。它还存储移位或旋转操作的最后一位的内容。  下表列出了16位标志寄存器中标志位的位置：</description>
    </item>
    
    <item>
      <title>nasm汇编之内存段 Memory Segments</title>
      <link>https://realjf.io/assembly/memory-segments/</link>
      <pubDate>Sun, 31 May 2020 00:33:36 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/memory-segments/</guid>
      <description>汇编程序的三个节.data、.bss、.text。这些部分也代表各种内存段。
如果将section关键字替换为segment，则会得到相同的结果。试试下面的代码
segment .text ;code segment global _start ;must be declared for linker _start: ;tell linker entry point mov edx,len ;message length mov ecx,msg ;message to write mov ebx,1 ;file descriptor (stdout) mov eax,4 ;system call number (sys_write) int 0x80 ;call kernel mov eax,1 ;system call number (sys_exit) int 0x80 ;call kernel segment .data ;data segment msg db &#39;Hello, world!&#39;,0xa ;our dear string len equ $ - msg ;length of our dear string  内存段 分段存储器模型将系统存储器分为独立的分段组，这些分段由位于分段寄存器中的指针引用。每个细分用于包含特定类型的数据。 一个段用于包含指令代码，另一段用于存储数据元素，第三段用于保留程序堆栈。</description>
    </item>
    
    <item>
      <title>nasm汇编之基础语法 Basic Syntax</title>
      <link>https://realjf.io/assembly/basic-syntax/</link>
      <pubDate>Sun, 31 May 2020 00:20:08 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/basic-syntax/</guid>
      <description>一个汇编程序可以被分成三个sections：
 data section bss section text section  data section data 部分用于声明初始化的数据或常量。该数据在运行时不会更改。您可以在本节中声明各种常量值，文件名或缓冲区大小等
section .data  bss section bss部分用于声明变量。声明bss部分的语法是
section .bss  text section text部分用于保留实际代码。此section必须以全局声明_start开头，该声明告诉内核程序从何处开始执行。
section .text global _start _start:  注释 ; this is a comment mov a, b ; move b to a  statements [label] mnemonic [operands] [;comment]  hello world示例 section .text global _start ;must be declared for linker (ld) _start: ;tells linker entry point mov edx,len ;message length mov ecx,msg ;message to write mov ebx,1 ;file descriptor (stdout) mov eax,4 ;system call number (sys_write) int 0x80 ;call kernel mov eax,1 ;system call number (sys_exit) int 0x80 ;call kernel section .</description>
    </item>
    
    <item>
      <title>汇编语言之数学操作 Math Operations List</title>
      <link>https://realjf.io/assembly/math-operations-list/</link>
      <pubDate>Sat, 30 May 2020 22:23:28 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/math-operations-list/</guid>
      <description></description>
    </item>
    
    <item>
      <title>汇编语言之跳转标识 Jump Symbol</title>
      <link>https://realjf.io/assembly/jump-symbol/</link>
      <pubDate>Sat, 30 May 2020 22:00:29 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/jump-symbol/</guid>
      <description></description>
    </item>
    
    <item>
      <title>汇编语言之系统调用寄存器输入 System Call Inputs by Register</title>
      <link>https://realjf.io/assembly/system-call-inputs-by-register/</link>
      <pubDate>Sat, 30 May 2020 21:30:25 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/system-call-inputs-by-register/</guid>
      <description> 示例 </description>
    </item>
    
    <item>
      <title>汇编语言之寄存器 Registers</title>
      <link>https://realjf.io/assembly/registers/</link>
      <pubDate>Sat, 30 May 2020 21:28:19 +0800</pubDate>
      
      <guid>https://realjf.io/assembly/registers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>php扩展开发 php Extension Develop</title>
      <link>https://realjf.io/php/extension-develop/</link>
      <pubDate>Mon, 18 May 2020 16:00:22 +0800</pubDate>
      
      <guid>https://realjf.io/php/extension-develop/</guid>
      <description>下载php源代码 要开发php扩展，需要下载php源码，里面有我们开发扩展需要的工具
下载地址：https://www.php.net/downloads
wget https://www.php.net/distributions/php-7.4.6.tar.xz xz -d php-7.4.6.tar.xz tar xvf php-7.4.6.tar  我们需要的是源码目录下ext目录下的ext_skel或ext_skel.php文件，它是类unix环境下用于自动生成php扩展框架的脚本工具。
开发自己的php扩展 可以通过&amp;ndash;help查看ext_skel.php的完整命令
ext_skel --help  首先，我们需要利用ext_skel.php生成我们需要的框架，只需要提供&amp;ndash;extname的参数即可
# 5.6.23 ./ext_skel --extname=helloworld # 7.4.6 ./ext_skel.php --ext helloworld  运行之后，在ext目录下将多出一个helloworld的目录，即我们生成的扩展框架目录
目录下包含以下文件： - config.m4：这是Unix环境下的Build System配置文件，后面将会通过它生成配置和安装。 - php_helloworld.h：这个文件是扩展模块的头文件。遵循C语言一贯的作风，这个里面可以放置一些自定义的结构体、全局变量等等。 - helloworld.c：这个就是扩展模块的主程序文件了，最终的扩展模块各个函数入口都在这里。当然，你可以将所有程序代码都塞到这里面，也可以遵循模块化思想，将各个功能模块放到不同文件中
build system配置 这里看下config.m4配置的一些内容，打开config.m4，注意，其使用dnl作为注释符
dnl config.m4 for extension helloworld dnl Comments in this file start with the string &#39;dnl&#39;. dnl Remove where necessary. dnl If your extension references something external, use &#39;with&#39;: dnl PHP_ARG_WITH([helloworld], dnl [for helloworld support], dnl [AS_HELP_STRING([--with-helloworld], dnl [Include helloworld support])]) dnl Otherwise use &#39;enable&#39;: PHP_ARG_ENABLE([helloworld], [whether to enable helloworld support], [AS_HELP_STRING([--enable-helloworld], [Enable helloworld support])], [no]) if test &amp;quot;$PHP_HELLOWORLD&amp;quot; !</description>
    </item>
    
    <item>
      <title>php底层运行机制 Underlying Operation Mechanism</title>
      <link>https://realjf.io/php/underlying-operation-mechanism/</link>
      <pubDate>Mon, 18 May 2020 14:08:10 +0800</pubDate>
      
      <guid>https://realjf.io/php/underlying-operation-mechanism/</guid>
      <description>php是多进程模型，不同请求间互不干涉，保证了一个请求挂掉不会对其他请求造成影响。目前php也支持多线程模型。
php同时也是弱类型语言，zend引擎+组件（ext）的模式，降低内部耦合，中间层sapi,隔绝web server和php
php的核心架构 php核心架构如下图，从下到上可以简单分为四层体系：
 zend引擎：是php的内核，它将php代码翻译为可执行opcode的处理并实现相应的处理方法，实现了基本的数据结构、内存分配管理、提供了相应的api方法供外部调用，是一切的核心 Extensions：围绕着zend引擎，extensions通过组件式的方式提供各种基础服务，各种内置函数、标准库等都是通过extensions实现的。 sapi：全称是Server Application Programming Interface服务端应用编程接口，sapi通过一系列钩子函数，使得php可以和外围交互数据，通过sapi成功的将php本身和上层应用解耦隔离，php可以不再考虑如何针对不同应用进行兼容，而应用本身也可以针对自己特点实现不同处理方式。  常见的一些sapi有：apache2handler: 这是以apache作为webserver，采用mod_php模式运行方式也是应用最广泛的一种 cgi：这是webserver和php直接交互的另一种方式，fastcgi+php得到广泛应用，也是异步webserver所唯一支持的方式 cli：命令行调用的应用模式  上层应用：这是我们平时编写的php程序，通过不同的sapi方式得到各种各样的应用模式  php执行流程 php实现了典型动态语言执行过程：将一段代码经过词法解析、语法解析等阶段后，源程序会被翻译成一个个指令（opcodes）， 然后zend虚拟机顺次执行这些指令完成操作。php本身是用c实现的，因此最终调用的也是c的函数。
php的执行核心是翻译出来的一条条指令，即opcode。
opcode是php程序执行的最基本单位。一个opcode由两个参数（op1,op2）、返回值和处理函数组成。php程序最终被翻译成一组opcode处理函数的顺序执行。
zend引擎 zend引擎作为php的内核，有很多经典的设计机制，主要有以下几个：
实现hashTable数据结构： hashTable是zend的核心数据结构。几乎用来实现所有常见功能。
zend hash table实现了典型的hash表散列结构,同时通过附加一个双向链表，提供了正向、反向遍历数组的功能。其结构如下：
在hash table中既有key-&amp;gt;value形式的散列结构，也有双向链表模式，使得它能够非常方便的支持快速查找和线性遍历
 散列结构：Zend的散列结构是典型的hash表模型，通过链表的方式来解决冲突。需要注意的是zend的hash table是一个自增长的数据结构， 当hash表数目满了之后，其本身会动态以2倍的方式扩容并重新元素位置。初始大小均为8。 另外，在进行 key-&amp;gt;value快速查找时候，zend本身还做了一些优化，通过空间换时间的方式加快速度。 比如在每个元素中都会用一个变量 nKeyLength标识key的长度以作快速判定。
 双向链表：Zend hash table通过一个链表结构，实现了元素的线性遍历。 理论上，做遍历使用单向链表就够了，之所以使用双向链表，主要目的是为了快速删除，避免遍历。 Zend hash table是一种复合型的结构，作为数组使用时，即支持常见的关联数组也能够作为顺序索引数字来使用，甚至允许2者的混合。
 PHP关联数组：关联数组是典型的hash_table应用。
 PHP索引数组：索引数组就是我们常见的数组，通过下标访问。例如 arr[0]，Zend HashTable内部进行了归一化处理，对于index类型key同样分配了hash值和nKeyLength(为0)。内部成员变量 nNextFreeElement就是当前分配到的最大id，每次push后自动加一。正是这种归一化处理，PHP才能够实现关联和非关联的混合。由于 push操作的特殊性，索引key在PHP数组中先后顺序并不是通过下标大小来决定，而是由push的先后决定。
  php变量实现原理 PHP在变量申明的时候不需要指定类型。PHP在程序运行期间可能进行变量类型的隐示 转换。 和其他强类型语言一样，程序中也可以进行显示的类型转换。PHP变量可以分为简单类型(int、string、bool)、集合类型(array 、resource 、object)和常量(const)。以上所有的变量在底层都是同一种结构 zval
Zval是zend中另一个非常重要的数据结构，用来标识并实现PHP变量，其数据结构如下
zval结构主要分三部分：</description>
    </item>
    
    <item>
      <title>树的遍历 Tree Walk</title>
      <link>https://realjf.io/algorithm/tree/tree-walk/</link>
      <pubDate>Thu, 14 May 2020 16:14:16 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/tree/tree-walk/</guid>
      <description> 前序遍历 按照根节点、左子树、右子树的顺序输出节点编号。称为树的前序遍历
#define MAX 10000 #define NIL -1 struct Node { int p, l, r;}; struct Node T[MAX]; void preOrder(int u) { if(u == NIL) return; printf(&amp;quot; %d&amp;quot;, u); preOrder(T[u].l); preOrder(T[u].r); }  中序遍历 按照左子树、根节点、右子树的顺序输出节点编号。称为树的中序遍历
void inOrder(int u) { if(u == NIL) return; inOrder(T[u].l); printf(&amp;quot; %d&amp;quot;, u); inOrder(T[u].r); }  后序遍历 按照左子树、右子树、根节点的顺序输出节点编号。称为树的后序遍历
void postOrder(int u) { if(u == NIL) return; postOrder(T[u].l); postOrder(T[u].r); printf(&amp;quot; %d&amp;quot;, u); }  </description>
    </item>
    
    <item>
      <title>mysql Explain 详解</title>
      <link>https://realjf.io/mysql/explain-analysis/</link>
      <pubDate>Thu, 14 May 2020 09:10:02 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/explain-analysis/</guid>
      <description>explain 输出列    列名 JSON 名 说明     id select_id The SELECT identifier   select_type None The SELECT type   table table_name The table for the output row   partitions partitions The matching partitions   type access_type The join type   possible_keys possible_keys The possible indexes to choose   key key The index actually chosen   key_len key_length The length of the chosen key   ref ref The columns compared to the index   rows rows Estimate of rows to be examined   filtered filtered Percentage of rows filtered by table condition   Extra None Additional information    id select 标识</description>
    </item>
    
    <item>
      <title>Binary Search</title>
      <link>https://realjf.io/algorithm/search/binary-search/</link>
      <pubDate>Wed, 13 May 2020 11:00:54 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/search/binary-search/</guid>
      <description>对于已排序的数组A进行二分查找，实现如下：
int binarySearch(int key){ int left = 0; int right = n; int mid; while(left &amp;lt; right){ mid = (left+right)/2; if(key == A[mid]) return 1; if(key &amp;gt; A[mid]) left = mid+1; else if(key &amp;lt; A[mid]) right = mid; } return 0; }  </description>
    </item>
    
    <item>
      <title>免秘钥登录配置 Ssh Login Nopassword</title>
      <link>https://realjf.io/linux/ssh-login-nopassword/</link>
      <pubDate>Mon, 11 May 2020 16:20:44 +0800</pubDate>
      
      <guid>https://realjf.io/linux/ssh-login-nopassword/</guid>
      <description>方法一 在一个节点生成公钥，然后利用ssh-copy-id复制到各节点
ssh-keygen -t rsa -b 4096 -P &#39;&#39; -f ~/.ssh/id_rsa -C &amp;quot;备注&amp;quot; # 复制到各节点 ssh-copy-id node2 ssh-copy-id node3 ssh-copy-id node4 # 其他节点重复上述操作，实现各节点之间可以相互免密登录  方法二 也可以使用shell脚本，需要提前安装好expect
yum install expect -y  autoSSH.sh
#!/bin/bash ## 脚本接收的参数，也就是要互相配置 SSH 免密登录的服务器列表参数 BASE_HOST_LIST=$* ## 密码，默认用户是当前运行脚本的用户，比如 root 用户 ## 这里改成你的用户对应的密码 BASE_PASSWORD=&amp;quot;root&amp;quot; ## shell 函数：模拟 SSH 公钥私钥文件生成的人机交互过程 sshkeygen(){ expect -c &amp;quot; spawn ssh-keygen expect { \&amp;quot;ssh/id_rsa):\&amp;quot; {send \&amp;quot;\r\&amp;quot;;exp_continue} \&amp;quot;passphrase):\&amp;quot; {send \&amp;quot;\r\&amp;quot;;exp_continue} \&amp;quot;again:\&amp;quot; {send \&amp;quot;\r\&amp;quot;;exp_continue} } &amp;quot; } ## shell 函数：模拟配置 SSH 免密登录过程的人机交互过程 sshcopyid(){ expect -c &amp;quot; spawn ssh-copy-id $1 expect { \&amp;quot;(yes/no)?</description>
    </item>
    
    <item>
      <title>Jdk 8 安装</title>
      <link>https://realjf.io/linux/jdk-8u131/</link>
      <pubDate>Mon, 11 May 2020 15:46:10 +0800</pubDate>
      
      <guid>https://realjf.io/linux/jdk-8u131/</guid>
      <description> jdk下载地址： https://www.oracle.com/java/technologies/javase-jdk8-downloads.html
或者：https://www.oracle.com/java/technologies/oracle-java-archive-downloads.html
这里提供百度云下载：链接: https://pan.baidu.com/s/1_fSe_nkdoZ_QhidbQyZ1ig 提取码: ttpw
准备环境  centos7 虚拟机  手动安装 检查系统是否已经安装了jdk，有就卸载默认的jdk rpm -qa | grep jdk ava-1.6.0-openjdk-1.6.0.35-1.13.7.1.el6_6.x86_64 java-1.7.0-openjdk-1.7.0.79-2.5.5.4.el6.x86_64 [root@node1 ~]# rpm -e --nodeps java-1.6.0-openjdk-1.6.0.35-1.13.7.1.el6_6.x86_64 [root@node1 ~]# rpm -e --nodeps java-1.7.0-openjdk-1.7.0.79-2.5.5.4.el6.x86_64  下载安装jdk wget https://download.oracle.com/otn/java/jdk/8u251-b08/3d5a2bb8f8d4428bbe94aed7ec7ae784/jdk-8u251-linux-x64.tar.gz tar zxvf jdk-8u251-linux-x64.tar.gz -C /usr/local # 配置环境变量 vi /etc/profile export JAVA_HOME=/usr/local/jdk1.8.0_251 export PATH=$PATH:$JAVA_HOME/bin # 保存退出 :wq source /etc/profile # 验证 java -version  </description>
    </item>
    
    <item>
      <title>zookeeper集群搭建 Zookeeper cluster Set Up</title>
      <link>https://realjf.io/distributed/zookeeper-set-up/</link>
      <pubDate>Mon, 11 May 2020 11:06:43 +0800</pubDate>
      
      <guid>https://realjf.io/distributed/zookeeper-set-up/</guid>
      <description>准备环境  准备4个centos7虚拟机 下载zookeeper安装包 提前安装好jdk 安装jdk  zookeeper下载地址：http://mirrors.hust.edu.cn/apache/zookeeper/
集群规划  node1： leader或follower node2： leader或follower node3： leader或follower node4： observer   leader：能接收所有的读写请求，也可以处理所有的读写请求，而且整个集群中的所有写数据请求都是由leader进行处理 follower：能接收所有的读写请求，但是读数据请求自己处理，写数据请求转发给leader observer：跟follower的唯一的区别就是没有选举权和被选举权
 下载安装 wget http://mirrors.hust.edu.cn/apache/zookeeper/stable/apache-zookeeper-3.5.7-bin.tar.gz tar zxvf apache-zookeeper-3.5.7-bin.tar.gz # 加入环境变量path中 vim ~/.bash_profile export ZOOKEEPER_HOME=/home/hadoop/apps/zookeeper export PATH=$PATH:$ZOOKEEPER_HOME/bin # 保存退出，然后source使其生效 source ~/.bash_profile  配置zoo.cfg文件 # 进入ZOOKEEPER_HOME/conf目录 # 复制zoo_sample.cfg为zoo.cfg cp zoo_sample.cfg zoo.cfg # 编辑zoo.cfg vi zoo.cfg # 集群各节点的心跳时间间隔，保持默认即可(2s) tickTime=2000 # 此配置表示，允许follower连接并同步到leader的初始化连接时间 # 它以tickTime的倍数来表示 # 当超过设置倍数的tickTime时间，则连接失败 # 保持默认即可(10次心跳的时间，即20s) initLimit=10 # follower与leader通信，从发送请求到接收到响应的等待时间的最大值，保持默认即可，即10s # 如果10s内没有收到响应，本次请求就失败 syncLimit=5 # zookeeper的数据存放的位置，默认是/tmp/zookeeper，一定要改，因为tmp目录会不定时清空 dataDir=/root/hadoop/zkdata # 客户端连接的端口号，保持默认即可 clientPort=2181 # 以下内容手动添加 # server.</description>
    </item>
    
    <item>
      <title>安装flutter开发环境 Set Up flutter</title>
      <link>https://realjf.io/flutter/set-up/</link>
      <pubDate>Sun, 10 May 2020 11:53:15 +0800</pubDate>
      
      <guid>https://realjf.io/flutter/set-up/</guid>
      <description>获取安装flutter sdk wget https://storage.googleapis.com/flutter_infra/releases/stable/linux/flutter_linux_1.17.0-stable.tar.xz tar xf ~/Downloads/flutter_linux_1.17.0-stable.tar.xz  或者直接从github下载也可以
git clone https://github.com/flutter/flutter.git -b stable  添加flutter到你的path环境变量
export PATH=&amp;quot;$PATH:`pwd`/flutter/bin&amp;quot;  最后提前预下载相关依赖包
flutter precache  下载完成后，检查相关环境是否安装成功
flutter doctor  检查过程中可能遇到的问题
[-] Android toolchain - develop for Android devices • Android SDK at /Users/obiwan/Library/Android/sdk ✗ Android SDK is missing command line tools; download from https://goo.gl/XxQghQ • Try re-installing or updating your Android SDK, visit https://flutter.dev/setup/#android-setup for detailed instructions.  这是android sdk未安装，可以直接下载安装，然后通过以下命令更新
flutter doctor --android-licenses  最后，如果你使用android studio或者vscode，需要提前下载相应的插件dart和flutter以及kotlin， 同时，android studio还需要在settings里配置flutter sdk路径，同时需要安装相应的安卓模拟器</description>
    </item>
    
    <item>
      <title>Kafka Go Client</title>
      <link>https://realjf.io/kafka/go-client/</link>
      <pubDate>Wed, 29 Apr 2020 15:37:44 +0800</pubDate>
      
      <guid>https://realjf.io/kafka/go-client/</guid>
      <description>本次实验假定您已经安装好了kafka（单机或者集群），且配置好了远程访问地址，详见配置文件config/server.properties
首先需要下载安装librdkafka wget https://github.com/edenhill/librdkafka/archive/v1.4.0.tar.gz tar zxvf librdkafka-1.4.0.tar.gz cd librdkafka-1.4.0 ./configure make make install  安装完毕，可以开始写go client
在go项目下安装客户端 go get -u gopkg.in/confluentinc/confluent-kafka-go.v1/kafka  consumer示例 import ( &amp;quot;fmt&amp;quot; &amp;quot;gopkg.in/confluentinc/confluent-kafka-go.v1/kafka&amp;quot; ) func main() { c, err := kafka.NewConsumer(&amp;amp;kafka.ConfigMap{ &amp;quot;bootstrap.servers&amp;quot;: &amp;quot;192.168.37.133:9092&amp;quot;, &amp;quot;group.id&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;auto.offset.reset&amp;quot;: &amp;quot;earliest&amp;quot;, }) if err != nil { panic(err) } c.SubscribeTopics([]string{&amp;quot;test&amp;quot;, &amp;quot;^aRegex.*[Tt]est&amp;quot;}, nil) for { msg, err := c.ReadMessage(-1) if err == nil { fmt.Printf(&amp;quot;Message on %s: %s\n&amp;quot;, msg.TopicPartition, string(msg.Value)) } else { fmt.</description>
    </item>
    
    <item>
      <title>Kafka快速开始</title>
      <link>https://realjf.io/kafka/set-up/</link>
      <pubDate>Tue, 28 Apr 2020 17:13:30 +0800</pubDate>
      
      <guid>https://realjf.io/kafka/set-up/</guid>
      <description>下载地址：https://www.apache.org/dyn/closer.cgi?path=/kafka/2.5.0/kafka_2.12-2.5.0.tgz
下载 wget https://www.apache.org/dyn/closer.cgi?path=/kafka/2.5.0/kafka_2.12-2.5.0.tgz tar zxvf kafka_2.12-2.5.0.tgz cd kafka_2.12-2.5.0  开启服务器 # 开启zookeeper bin/zookeeper-server-start.sh config/zookeeper.properties # 开启kafka bin/kafka-server-start.sh config/server.properties  创建一个topic bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test  上面创建了一个叫test的topic
我们现在可以运行list topic命令查看刚才创建的topic
bin/kafka-topics.sh --list --bootstrap-server localhost:9092  发送消息 bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test 这是一条信息 这是另外一条消息  开启一个消费者consumer 接收消息
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 这是一条信息 这是另一条信息  安装一个多broker集群，即kafka集群 # 首先为每个broker创建一个配置 cp config/server.properties config/server-1.properties cp config/server.properties config/server-2.properties # 然后为每个配置文件设置 config/server-1.</description>
    </item>
    
    <item>
      <title>storm安装</title>
      <link>https://realjf.io/storm/set-up/</link>
      <pubDate>Tue, 28 Apr 2020 15:31:08 +0800</pubDate>
      
      <guid>https://realjf.io/storm/set-up/</guid>
      <description>一、需要安装的工具  python、zookeeper、storm（如果是storm0.9以前的版本，则需要安装zeromq、jzmq）  二、开始安装 第一步：安装Python2.7.2 wget http://www.python.org/ftp/python/2.7.2/Python-2.7.2.tgz tar zxvf Python-2.7.2.tgz cd Python-2.7.2 ./configure --prefix=/usr/local/python2.7 make make install vi /etc/ld.so.conf 追加/usr/local/lib/ sudo ldconfig  第二步：安装zookeeper wget http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz tar -zxvf zookeeper-3.3.5.tar.gz cp -R zookeeper-3.3.5 /usr/local/zookeeper vim /etc/profile (设置ZOOKEEPER_HOME和ZOOKEEPER_HOME/bin) export ZOOKEEPER_HOME=&amp;quot;/usr/local/zookeeper&amp;quot; export PATH=$PATH:$ZOOKEEPER_HOME/bin cp /usr/local/zookeeper/conf/zoo_sample.cfg /usr/local/zookeeper/conf/zoo.cfg (用zoo_sample.cfg制作$ZOOKEEPER_HOME/conf/zoo.cfg) mkdir /tmp/zookeeper mkdir /var/log/zookeeper  zookeeper的单机安装已经完成了。
第三步：安装zeromq wget http://download.zeromq.org/zeromq-4.1.0-rc1.tar.gz tar zxf zeromq-2.2.0.tar.gz cd zeromq-2.2.0 ./configure //因为jzmq的安装时依赖于zeromq的，所以./configure的时候不能指定zeromq的安装目录，如果指定了，则jzmq的安装会出错（即不能指定--prefix=...）。 make make install sudo ldconfig (更新LD_LIBRARY_PATH)  zeromq安装完成。 注意：如有有依赖报错，需要安装： jzmq dependencies 依赖包 sudo yum install uuid* sudo yum install libtool sudo yum install libuuid sudo yum install libuuid-devel</description>
    </item>
    
    <item>
      <title>docker error creating overlay mount to invalid argument 解决方法</title>
      <link>https://realjf.io/docker/docker-create-layer-error/</link>
      <pubDate>Tue, 28 Apr 2020 15:29:31 +0800</pubDate>
      
      <guid>https://realjf.io/docker/docker-create-layer-error/</guid>
      <description> 原因 由于docker的不同版本在centos上产生的mount问题，1.2.x没有出现这个问题，当使用yum install时，安装的最新版本(1.3.x)，会导致overlay2的错误。
解决方法 修改docker启动参数storage-driver
vim /etc/sysconfig/docker-storage # 将文件中的DOCKER_STORAGE_OPTIONS=&amp;quot;-s overlay2&amp;quot;修改为DOCKER_STORAGE_OPTIONS=&amp;quot;-s overlay&amp;quot;  然后重新加载daemon
systemctl daemon-reload  重启docker
systemctl restart docker  </description>
    </item>
    
    <item>
      <title>Dockerfile实现修改容器hosts文件内容</title>
      <link>https://realjf.io/docker/docker-modify-hosts/</link>
      <pubDate>Tue, 28 Apr 2020 15:26:44 +0800</pubDate>
      
      <guid>https://realjf.io/docker/docker-modify-hosts/</guid>
      <description>场景 今天突然遇到一个问题，需要向容器的/etc/hosts文件追加自定义的内容，直接的做法的是，进入容器，直接修改/etc/hosts文件，但是，这种做法在容器重新启动后就失效，而且容器启动实例一多，就会带来繁琐的手动操作。
为了能让同一个镜像启动的容器每次启动的时候都能自动更新成我们需要的/etc/hosts文件，现有以下几种方法：
1. 在docker run的时候增加参数&amp;ndash;add-host进行添加（官方给的方法） # 添加单个hosts docker run -it nginx --add-host=localhost:127.0.0.1 # 添加多个hosts docker run -it nginx --add-host=localhost:127.0.0.1 --add-host=example.com:127.0.0.1 # 一个ip对应多个hosts docker run -it nginx --add-host=&amp;quot;localhost example.com&amp;quot;:127.0.0.1  2. 在dockerfile中，使用脚本作为镜像入口，再利用脚本运行修改hosts文件的命令以及真正的应用程序入口 文件说明 - myhosts：需要追加到/etc/hosts中的内容 - run.sh：容器的入口执行脚本 - dockerfile：构建镜像的dockerfile文件
dockerfile示例如下：
FROM centos:6 MAINTAINER chenjiefeng COPY run.sh ~/run.sh COPY myhosts ~/myhosts RUN chmod +x ~/run.sh ENTRYPOINT /bin/sh -c ~/run.sh  run.sh示例如下：
#!/bin/bash # 向hosts文件追加内容 cat ~/myhosts &amp;gt;&amp;gt; /etc/hosts # 其他命令 # 保留终端，防止容器自动退出 /bin/bash  myhosts示例如下：</description>
    </item>
    
    <item>
      <title>Docker容器和宿主机时间不一致问题解决</title>
      <link>https://realjf.io/docker/docker-time-sync/</link>
      <pubDate>Tue, 28 Apr 2020 15:26:29 +0800</pubDate>
      
      <guid>https://realjf.io/docker/docker-time-sync/</guid>
      <description> 1. 在Dockerfile中解决（永久性，推荐） 在Dockerfile文件中加上如下：
ENV TZ=Asia/Shanghai # 添加你需要的时区 RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;amp;&amp;amp; echo $TZ &amp;gt; /etc/timezone  2. 临时性设置 在container的shell交互里输入
TZ=Asia/Shanghai ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;amp;&amp;amp; echo $TZ &amp;gt; /etc/timezone ## 检查时间 date  </description>
    </item>
    
    <item>
      <title>golang Slice类型扩容机制</title>
      <link>https://realjf.io/golang/slice/</link>
      <pubDate>Tue, 28 Apr 2020 15:10:49 +0800</pubDate>
      
      <guid>https://realjf.io/golang/slice/</guid>
      <description> 一个slice是一个数组某个部分的引用。在内存中，他是一个包含3个域的结构体：指向slice中第一个元素的指针，slice的长度，以及slice的容量。长度是下标操作的上界，容量是分割操作的上界
数组的slice并不会实际复制一份数据，他只是创建一个新的数据结构，包含了另外的一个指针，一个长度和一个容量数据。如同分割字符串，分割数组也不涉及复制操作：它只是新建了一个结构来放置一个不同的指针，长度和容量。
由于slice是不同于指针的多字长结构，分割操作并不需要分配内存，甚至没有通常被保存在堆中的slice头部，这种表示方法使slice操作和在c中传递指针、长度对一样廉价。移除间接引用及分配操作可以让slice足够廉价，以避免传递显式索引。
slice的扩容 在对slice进行append等操作时，可能会造成slice的自动扩容。其扩容时的大小增长规则是： - 如果新的大小是当前大小2倍以上，则大小增长为新大小 - 否则循环以下操作：如果当前大小小于1024，按每次2倍增长，否则每次按当前大小1/4增长。直到增长的大小超过或等于新大小。
make和new 有两个数据结构创建函数：new和make，基本区别是new（T）返回一个*T，返回的这个指针可以被隐式地消除索引，而make(T, args)返回一个 普通的T，通常情况下，T内部有一些隐式的指针，一句话，new返回一个指向已清零内存的指针，而make返回一个复杂的结构。
slice与unsafe.Pointer相互转换 有时候可能需要使用一些比较tricky的技巧，比如利用make弄一块内存自己管理，或者用cgo之类的方式得到的内存，转换为Go类型使用。 从slice中得到一块内存地址是很容易的：
s := make([]byte, 200) ptr := unsafe.Pointer(&amp;amp;s[0])  从一个内存指针构造出go语言的slice结构相对麻烦些，比如：
var ptr unsafe.Pointer s := ((*[1&amp;lt;&amp;lt;10]byte)(ptr))[:200]  先将ptr强制类型转换为另外一种指针，一个指向[1&amp;lt;&amp;lt;10]byte数组的指针，这里数组大小其实是假的，然后用slice操作取出这个数组的前200个，于是s就是一个200个元素的slice
或者：
var ptr unsafe.Pointer var s1 = struct { addr uintptr len int cap int }{ptr, length, length} s := *(*[]byte)(unsafe.Pointer(&amp;amp;s1))  或者使用reflect.SliceHeader的方式构造slice，比较推荐这种：
var o []byte sliceHeader := (*reflect.SliceHeader)((unsafe.Pointer(&amp;amp;o))) sliceHeader.Cap = length sliceHeader.Len = length sliceHeader.Data = uintptr(ptr)  </description>
    </item>
    
    <item>
      <title>排序算法之选择排序 Select Sort</title>
      <link>https://realjf.io/algorithm/sort/select-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:03:27 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/select-sort/</guid>
      <description>选择排序算法是每次循环遍历出未排除中最小值的位置，然后与将其与未排序部分第一个元素进行交换
#include &amp;lt;stdio.h&amp;gt; void swap(int* a, int* b) { if(*a &amp;gt; *b){ *a = *a + *b; *b = *a - *b; *a = *a - *b; } } int main(){ int a[10],i,j; for(i=0;i&amp;lt;10;i++){ scanf(&amp;quot;%d&amp;quot;, &amp;amp;a[i]); } for(i=0;i&amp;lt;9;i++){ int min = i; for(j=i+1;j&amp;lt;10;j++){ if(a[j] &amp;lt; a[min]){ min = j; } } swap(&amp;amp;a[min], &amp;amp;a[i]); } return 0; }  </description>
    </item>
    
    <item>
      <title>排序算法之归并排序 Merge Sort</title>
      <link>https://realjf.io/algorithm/sort/merge-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:03:19 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/merge-sort/</guid>
      <description>归并排序的基本思想是： - 将给定的包含n个元素的局部数组“分割”成两个局部数组，每个数组各包含n/2各元素。 - 对两个局部数组分别执行mergeSort排序。 - 通过merge将两个已排序完毕的局部数组整合成一个数组。
#inlcude &amp;lt;iostream&amp;gt; using namespace std; #define MAX 500000 #define SENTINEL 2000000000 int L[MAX/2+2], R[MAX/2+2]; int cnt; void merge(int A[], int n, int left, int mid, int right){ int n1 = mid - left; int n2 = right - mid; for(int i=0; i&amp;lt; n1; i++)L[i] = A[left+i]; for(int i = 0; i&amp;lt; n2;i++) R[i] = A[mid+i]; L[n1] = R[n2] = SENTINEL; int i = 0; j = 0; for(int k = left; k&amp;lt;right;k++){ cnt++; if(L[i]&amp;lt;=R[j]){ A[k] = L[i++]; }else{ A[k] = R[j++]; } } } void mergeSort(int A[], int n, int left, int right){ if(left+1 &amp;lt; right){ int mid = (left + right) / 2; mergeSort(A, n, left, mid); mergeSort(A, n, mid, right); merge(A, n, left, mid, right); } } int main(){ int A[MAX], n, i; cnt = 0; cin &amp;gt;&amp;gt; n; for(i = 0; i&amp;lt;n; i++) cin&amp;gt;&amp;gt;A[i]; mergeSort(A, n, 0, n); for(i=0; i&amp;lt;n; i++){ if(i) cout &amp;lt;&amp;lt; &amp;quot; &amp;quot;; cout &amp;lt;&amp;lt; A[i]; } cout &amp;lt;&amp;lt; endl; cout &amp;lt;&amp;lt; cnt &amp;lt;&amp;lt; endl; return 0; }  </description>
    </item>
    
    <item>
      <title>排序算法之快速排序 Quick Sort</title>
      <link>https://realjf.io/algorithm/sort/quick-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:03:14 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/quick-sort/</guid>
      <description>快速排序的基本思想是： - 以整个数组为对象执行quickSort - quickSort流程如下 - 通过分割将对象局部数组分割为前后两个局部数组 - 对前半部分的局部数组执行quickSort - 对后半部分的局部数组执行quickSort
 分割后前半部分数组都小于等于分割点元素，后半部分都大于分割点元素
 #include &amp;lt;stdio.h&amp;gt; #define MAX 100000 #define SENTINEL 200000000 struct Card{ char suit; int value; }; struct Card L[MAX / 2 + 2], R[MAX/2 + 2]; int partition(struct Card A[], int, n, int p, int r){ int i, j; struct Card t, x; x = A[r]; i = p -1; for(j = p; j &amp;lt; r; j++){ if(A[j].</description>
    </item>
    
    <item>
      <title>排序算法之希尔排序 Shell Sort</title>
      <link>https://realjf.io/algorithm/sort/shell-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:03:09 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/shell-sort/</guid>
      <description>希尔排序充分利用插入排序可以高速处理顺序较整齐的数据的特点，重复进行以间隔为g的插入排序。g是一组数列集合。
void shellSort(int A[], int n) { // 生成数列G={1, 4, 13, 40, 121, 364, 1093, ...} for(int h = 1; ; ){ if(h &amp;gt; n) break; G.push_back(h); h = 3*h + 1; } // 按逆序指定G[i]=g for (int i = G.size() - 1; i &amp;gt;= 0; i--){ insertionSort(A, n, G[i]); } } void insertionSort(int A[], int n, int g) { for(int i = g; i &amp;lt; n; i++){ int v = A[i]; int j = i - g; while(j &amp;gt;= 0 &amp;amp;&amp;amp; A[j] &amp;gt; v){ A[j+g] = A[j]; j -= g; cnt++; } A[j + g] = v; } }  </description>
    </item>
    
    <item>
      <title>排序算法之插入排序 Insert Sort</title>
      <link>https://realjf.io/algorithm/sort/insert-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:03:02 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/insert-sort/</guid>
      <description>插入排序是简单的说，就是遍历整个数组，每次将一个元素插入到已排序的数组中，直到插入最后一个元素即完成整个排序过程。
基本思想  将开头第一个元素视作已排序部分，后续元素视作未排序部分 对未排序部分执行一下操作，直到未排序部分被消除  取出未排序部分开头第一个元素作为待排序元素t 将t与已排序部分进行对比，将比t顺序大的元素往后移动一个，即确定排序位置 将待排序元素t插入空出的排序位置中    #include &amp;lt;stdio.h&amp;gt; int main(){ int a[10],i,j; for(i=0;i&amp;lt;10;i++){scanf(&amp;quot;%d&amp;quot;, &amp;amp;a[i]);} for (i=1;i&amp;lt;10;i++){ int t = a[i]; // 待排序元素 j = i-1; while(j&amp;gt;=0 &amp;amp;&amp;amp; a[j] &amp;gt; t){ a[j+1] = a[j]; // 往后移动一个 j--; } a[j+1] = t; // 插入 } for(i=0; i&amp;lt;10;i++){ printf(&amp;quot;%d &amp;quot;, a[i]); } }  插入排序算法最坏的情况时间复杂度也是O(n^2)</description>
    </item>
    
    <item>
      <title>排序算法之冒泡排序 Bubble Sort</title>
      <link>https://realjf.io/algorithm/sort/bubble-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:00:51 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/bubble-sort/</guid>
      <description>冒泡排序算法很简单，对相邻的元素进行两两比较，顺序相反则进行交换，这样，每一趟会将最小或最大的元素“浮”到顶端，最终达到完全有序。
基本思想： 1.
#include &amp;lt;stdio.h&amp;gt; void swap(int* a, int* b){ if(*a &amp;gt; &amp;amp;b){ *a = *a+*b; *b = *a-*b; *a = *a-*b; } return; } int main(){ int a[10],i,j; for(i=0;i&amp;lt;10;i++){scanf(&amp;quot;%d&amp;quot;, &amp;amp;a[i]);} for (i=0;i&amp;lt;10;i++){ for(j=0; j&amp;lt;i; j++){ swap(&amp;amp;a[i], &amp;amp;a[j]); } } for(i=0; i&amp;lt;10;i++){ printf(&amp;quot;%d&amp;quot;, a[i]); } }  由以上程序可以看出，程序的时间复杂度是O(n^2)</description>
    </item>
    
    <item>
      <title>分布式锁的实现方式和原理</title>
      <link>https://realjf.io/distributed/lock-implement/</link>
      <pubDate>Tue, 28 Apr 2020 14:53:32 +0800</pubDate>
      
      <guid>https://realjf.io/distributed/lock-implement/</guid>
      <description>我们需要的分布式锁应该是怎么样的？  可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。 这把锁要是一把可重入锁（避免死锁） 这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条） 有高可用的获取锁和释放锁功能 获取锁和释放锁的性能要好  实现分布式锁的几种方法 分布式锁是控制分布式系统之间同步访问共享 资源的一种方式。在分布式系统中，常常需要协调他们的动作，如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性，这种情况下，便需要使用到分布式锁。
 基于缓存实现，如Redis实现——使用redis的setnx()、get()、getset()方法，用于分布式锁，解决死锁问题 基于数据库乐观锁实现 基于zookeeper实现   乐观锁通常实现基于数据版本(version)的记录机制实现的，比如有一张红包表（t_bonus），有一个字段(left_count)记录礼物的剩余个数，用户每领取一个奖品，对应的left_count减1，在并发的情况下如何要保证left_count不为负数，乐观锁的实现方式为在红包表上添加一个版本号字段（version），默认为0。
 SETNX key val # 原子性操作，当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。 expire key timeout # 为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。 delete key # 删除key GETSET key value # 将给定 key 的值设为 value ，并返回 key 的旧值 (old value)，当 key 存在但不是字符串类型时，返回一个错误，当key不存在时，返回nil  基于数据库实现 使用数据库乐观锁，包括主键防重，版本号控制。但是这两种方法各有利弊。
 使用主键冲突的策略进行防重，在并发量非常高的情况下对数据库性能会有影响，尤其是应用数据表和主键冲突表在一个库的时候，表现更加明显。其实针对是否会对数据库性能产生影响这个话题，我也和一些专业的DBA同学讨论过，普遍认可的是在MySQL数据库中采用主键冲突防重，在大并发情况下有可能会造成锁表现象，比较好的办法是在程序中生产主键进行防重。
 使用版本号策略 这个策略源于mysql的mvcc机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断sql每次进行判断。
  基于数据库表实现 要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。
当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。
上面这种简单的实现有以下几个问题： - 1、这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。
 2、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。
 3、这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。
 4、这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</description>
    </item>
    
    <item>
      <title>rabbitmq go客户端库实现</title>
      <link>https://realjf.io/rabbitmq/client/</link>
      <pubDate>Tue, 28 Apr 2020 14:49:47 +0800</pubDate>
      
      <guid>https://realjf.io/rabbitmq/client/</guid>
      <description>go rabbitmq client library
go get github.com/streadway/amqp   send.go（消息发送者） package main import ( &amp;quot;log&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;github.com/streadway/amqp&amp;quot; ) func failOnError(err error, msg string){ if err != nil { log.Fatalf(&amp;quot;%s: %s&amp;quot;, msg, err) panic(fmt.Sprintf(&amp;quot;%s: %s&amp;quot;, msg, err)) } } func main(){ conn, err := amqp.Dial(&amp;quot;amqp://guest:guest@localhost:5672/&amp;quot;) failOnError(err, &amp;quot;Failed to connect to RabbitMQ&amp;quot;) defer conn.Close() ch, err := conn.Channel() failOnError(err, &amp;quot;Failed to open a channel&amp;quot;) defer ch.Close() q, err := ch.QueueDeclare( &amp;quot;hello&amp;quot;, false, false, false, false, nil, ) failOnError(err, &amp;quot;Failed to declare a queue&amp;quot;) body := &amp;quot;hello&amp;quot; // 发布消息 err = ch.</description>
    </item>
    
    <item>
      <title>安装rabbitmq</title>
      <link>https://realjf.io/rabbitmq/set-up/</link>
      <pubDate>Tue, 28 Apr 2020 14:49:04 +0800</pubDate>
      
      <guid>https://realjf.io/rabbitmq/set-up/</guid>
      <description>Erlang下载地址：http://www.erlang.org/downloads
 rabbitmq官网下载地址：http://www.rabbitmq.com/download.html
  CentOS7.x安装  下载rabbitmq  wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.4/rabbitmq-server-3.7.4-1.el7.noarch.rpm  安装erlang
yum install erlang   需要先安装yum EPEL源
yum install epel-release -y # 或 rpm -vih http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm # 或 wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm rpm -vih epel-release-7-2.noarch.rpm # 更新数据 yum clean all &amp;amp;&amp;amp; yum makecache     erlang下载地址http://erlang.org/download/ 源码安装：
wget http://erlang.org/download/otp_src_20.2.tar.gz # 解压 tar -xzvf otp_src_20.2.tar.gz # 安装依赖包 yum install -y gcc gcc-c++ unixODBC-devel openssl-devel ncurses-devel # 设定安装位置 .</description>
    </item>
    
    <item>
      <title>mysql 事务 Transaction</title>
      <link>https://realjf.io/mysql/transaction/</link>
      <pubDate>Tue, 28 Apr 2020 14:42:50 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/transaction/</guid>
      <description>mysql存储引擎与事务：  1.myisam：不支持事务，用于只读程序提高性能 2. innodb：支持acid事务、行级锁、并发 3. berkeley db：支持事务。  一个事务是一个连续的一组数据库操作，就好像一个单一的工作单元进行。 如果在事务的任何操作失败，则整个事务将失败。
事务的特性： 事务有以下四个标准属性的缩写acid，通常被称为：
 原子性：确保工作单元内的所有操作都完成，否则事务将被终止在故障点，和以前的操作将回滚到以前的状态。 一致性：确保数据库正确地改变状态后，成功提交的事务。 隔离性：使事务操作彼此独立的和透明的。 持久性：确保提交的事务的结果或效果的系统出现故障的情况下仍然存在。  在MySQL中，事务开始使用COMMIT或ROLLBACK语句开始工作和结束。开始和结束语句的SQL命令之间形成了大量的事务。
COMMIT &amp;amp; ROLLBACK: 这两个关键字提交和回滚主要用于MySQL的事务。
当一个成功的事务完成后，发出COMMIT命令应使所有参与表的更改才会生效。
如果发生故障时，应发出一个ROLLBACK命令返回的事务中引用的每一个表到以前的状态。
可以控制的事务行为称为AUTOCOMMIT设置会话变量。如果AUTOCOMMIT设置为1（默认值），然后每一个SQL语句（在事务与否）被认为是一个完整的事务，并承诺在默认情况下，当它完成。 AUTOCOMMIT设置为0时，发出SET AUTOCOMMIT =0命令，在随后的一系列语句的作用就像一个事务，直到一个明确的COMMIT语句时，没有活动的提交。
可以通过使用mysql_query()函数在PHP中执行这些SQL命令。
事务 ACID Atomicity（原子性）、Consistency（稳定性）、Isolation（隔离性）、Durability（可靠性） 1、事务的原子性 一组事务，要么成功；要么撤回。
2、稳定性 有非法数据（外键约束之类），事务撤回。
3、隔离性 事务独立运行。 一个事务处理后的结果，影响了其他事务，那么其他事务会撤回。 事务的100%隔离，需要牺牲速度。
4、可靠性 软、硬件崩溃后，InnoDB数据表驱动会利用日志文件重构修改。 可靠性和高速度不可兼得， innodb_flush_log_at_trx_commit选项 决定什么时候吧事务保存到日志里。
开启事务 START TRANSACTION 或 BEGIN
提交事务（关闭事务） COMMIT
放弃事务（关闭事务） ROLLBACK
折返点 SAVEPOINT adqoo_1 ROLLBACK TO SAVEPOINT adqoo_1 发生在折返点 adqoo_1 之前的事务被提交，之后的被忽略
事务的终止
设置“自动提交”模式 SET AUTOCOMMIT = 0 每条SQL都是同一个事务的不同命令，之间由 COMMIT 或 ROLLBACK隔开 掉线后，没有 COMMIT 的事务都被放弃 事务锁定模式</description>
    </item>
    
    <item>
      <title>数据库范式 Database Normal Form</title>
      <link>https://realjf.io/mysql/database-normal-form/</link>
      <pubDate>Tue, 28 Apr 2020 14:39:03 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/database-normal-form/</guid>
      <description>第一范式：关系模式中，每个属性不可再分。属性原子性 第二范式：非主属性完全依赖于主属性，即消除非主属性对主属性的部分函数依赖关系。 第三范式：非主属性对主属性不存在传递函数依赖关系。 BNCF范式：在第三范式的基础上，消除主属性之间的部分函数依赖  第一范式（1NF）：在关系模式R中的每一个具体关系r中，如果每个属性值都是不可再分的最小数据单位，则称R是第一范式的关系。 例：如职工号，姓名，电话号码组成一个表（一个人可能有多个电话号码） 规范成为1NF有三种方法： 一是重复存储职工号和姓名。这样，关键字只能是电话号码。 二是职工号为关键字，电话号码分为单位电话和住宅电话两个属性 三是职工号为关键字，但强制每条记录只能有一个电话号码。
以上三个方法，第一种方法最不可取，按实际情况选取后两种情况。
第二范式（2NF）：如果关系模式R（U，F）中的所有非主属性都完全依赖于任意候选关键字，则称关系R 是属于第二范式的。 例：选课关系 sc（sid，cid，grade，credit）其中sid为学号， cid为课程号，grade为成绩，credit为学分。 由以上条件，关键字为组合关键字（sid，cid） 在应用中使用以上关系模式有以下问题： a.数据冗余，假设同一门课由40个学生选修，学分就重复40次。 b.更新异常，若调整了某课程的学分，相应的元组credit值都要更新，有可能会出现同一门课学分不同。 c.插入异常，如计划开新课，由于没人选修，没有学号关键字，只能等有人选修才能把课程和学分存入。 d.删除异常，若学生已经结业，从当前数据库删除选修记录。某些门课程新生尚未选修，则此门课程及学分记录无法保存。 原因：非关键字属性credit仅函数依赖于cid，也就是credit部分依赖组合关键字（sid，cid）而不是完全依赖。 解决方法：分成两个关系模式sc（sid，cid，grade），c（cid，credit）。新关系包括两个关系模式，它们之间通过sc中的外关键字cid相联系，需要时再进行自然联接，恢复了原来的关系
第三范式（3NF）：如果关系模式R（U，F）中的所有非主属性对任何候选关键字都不存在传递依赖，则称关系R是属于第三范式的。 例：如s（sid，sname，did，dname，location） 各属性分别代表学号，姓名，所在系，系名称，系地址。 关键字sid决定各个属性。由于是单个关键字，没有部分依赖的问题，肯定是2NF。但这关系肯定有大量的冗余，有关学生所在的几个属性did，dname，location将重复存储，插入，删除和修改时也将产生类似以上例的情况。 原因：关系中存在传递依赖造成的。即sid -&amp;gt; did。 而did -&amp;gt;sid却不存在，did -&amp;gt; location, 因此关键字sid对location函数决定是通过传递依赖did-&amp;gt;location 实现的。也就是说，sid不直接决定非主属性location。 解决目地：每个关系模式中不能留有传递依赖。 解决方法：分为两个关系 s（sid，sname，did），d（dno，dname，location） 注意：关系s中必须有外关键字did。否则两个关系之间失去联系。
BCNF：如果关系模式R（U，F）的所有属性（包括主属性和非主属性）都不传递依赖于R的任何候选关键字，那么称关系R是属于BCNF的。或是关系模式R中，每个决定因素都包含关键字（而不是被关键字所包含）。 例：配件管理关系模式 wpe（wid，pid，eid，qnt）分别表仓库号，配件号，职工号，数量。有以下条件: a.一个仓库有多个职工。 b.一个职工仅在一个仓库工作。 c.每个仓库里一种型号的配件由专人负责，但一个人可以管理几种配件。 d.同一种型号的配件可以分放在几个仓库中。 分析： 1. pid不能确定qnt，由组合属性（wid，pid）来决定，存在函数依赖（wid，pid）-&amp;gt; qnt。 2. 每个仓库里的一种配件由专人负责，而一个人可以管理几种配件，所以有（wid，pid）-&amp;gt; eid。 3. 一个职工仅在一个仓库工作，有eid -&amp;gt; wid。 4. 每个仓库里的一种配件由专人负责，而一个职工仅在一个仓库工作，有（eid，pid）-&amp;gt; qnt。 找一下候选关键字。因为（wid，pid）-&amp;gt; qnt，（wid，pid）-&amp;gt; eid，因此（wid，pid）可以决定整个元组，是一个候选关键字。根据eid -&amp;gt; wid，（eid，pid）-&amp;gt; qnt，故（eid，pid）也能决定整个元组，为另一个候选关键字。属性eid，eid，pid 均为主属性，只有一个非主属性qnt。它对任何一个候选关键字都是完全函数依赖的，并且是直接依赖，所以该关系模式是3NF。</description>
    </item>
    
    <item>
      <title>Mysql优化技巧</title>
      <link>https://realjf.io/mysql/optimize-mysql/</link>
      <pubDate>Tue, 28 Apr 2020 14:35:15 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/optimize-mysql/</guid>
      <description>索引失效情况：  1. 如果条件中有or，即使其中有条件带有索引也不会使用，换言之，要想使用or，又想让索引生效，只能将or条件中的每个列都必须使用索引。 2. 对于多列索引，不是使用的第一部分，则不会使用索引 3. like查询是以%开头的情况 4. 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不使用索引。 5. 如果mysql估计使用全表扫描要比使用索引快，则不使用索引。 6. 在列上进行运算 7. 使用NOT IN 和 &amp;lt;&amp;gt;操作 8. 只要列中包含有NULL值将不会 被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的，所以我们在数据库设计时不要让字段的默认值为NULL 9. mysql查询只使用一个索引，因此如果where子句已经使用了索引，那么order by中的列不会使用索引的。因此数据库默认排序可以复合要求的情况下不要使用排序操作，尽量不要包含多列排序，如果需要最好给这些列创建复合索引。  sql语句小技巧 1. 在使用group by 分组查询时，默认分组后，还会进行排序，可能会降低速度 在group by后面加上order by null 就可以防止排序
2. 有些情况下，可以使用连接来替代子查询，因为使用join，mysql不需要在内存中创建临时表。 select * from dept,emp where dept.deptno=emp.deptno select * from dept left join emp on dept.deptno=emp.deptno[左外连接]
3. 避免使用 select * 从数据库中读取越多数据，查询就越慢
4. 当只要一行数据时使用limit 1 使用limit 1数据库引擎会在找到一条数据后停止搜索，而不是继续往后查寻下一条符合记录的数据。
5. 使用explain你的select查询 使用explain关键字可以让你直到mysql是如何处理你的sql语句的，这可以帮你分析你的查询语句或表结构的性能瓶颈。
6. 永远为每张表设置一个id字段为主键 7. 使用enum而不是varchar类型 enum类型非常快和紧凑，实际上，其保存的是tinyint类型，但其外表上显示为字符串。</description>
    </item>
    
    <item>
      <title>远程登录Mysql配置</title>
      <link>https://realjf.io/mysql/remote-login-mysql/</link>
      <pubDate>Tue, 28 Apr 2020 14:33:41 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/remote-login-mysql/</guid>
      <description>原文地址:http://blog.chinaunix.net/uid-25806228-id-371815.html
Mysql默认关闭远程登录权限，如下操作允许用户在任意地点登录：  进入mysql，  GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;&#39; WITH GRANT OPTION;  IDENTIFIED BY后跟的是密码，可设为空。 FLUSH privileges;  更新Mysql为了安全性，在默认情况下用户只允许在本地登录，可是在有此情况下，还是需要使用用户进行远程连接，因此为了使其可以远程需要进行如下操作：
一、允许root用户在任何地方进行远程登录，并具有所有库任何操作权限，具体操作如下： 在本机先使用root用户登录mysql： mysql -u root -p&amp;rdquo;youpassword&amp;rdquo; 进行授权操作：
mysql&amp;gt;GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;youpassword&#39; WITH GRANT OPTION;  重载授权表：
FLUSH PRIVILEGES;  退出mysql数据库： exit
二、允许root用户在一个特定的IP进行远程登录，并具有所有库任何操作权限，具体操作如下： 在本机先使用root用户登录mysql：
mysql -u root -p&amp;quot;youpassword&amp;quot;  进行授权操作：
GRANT ALL PRIVILEGES ON *.* TO root@&amp;quot;172.16.16.152&amp;quot; IDENTIFIED BY &amp;quot;youpassword&amp;quot; WITH GRANT OPTION;  重载授权表：</description>
    </item>
    
    <item>
      <title>MySQL 5.7 源码安装</title>
      <link>https://realjf.io/mysql/set-up-mysql-57/</link>
      <pubDate>Tue, 28 Apr 2020 14:31:48 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/set-up-mysql-57/</guid>
      <description>源码安装 源码下载地址:http://cdn.mysql.com/Downloads/MySQL-5.7/mysql-5.7.15.tar.gz
先检查已有的mysql
rpm -qa | grep mysql rpm -e mysql-libs-5.1.73-3.el6_5.x86_64 --nodeps  1. 安装依赖的包 由于从mysql5.5开始弃用了常规的configure编译方法，所以需要下载cmake编译器、boost库、ncurses库和gnu分析器生成器bison这4种工具。
yum -y install make gcc-c++ ncurses-devel  安装cmake
wget https://cmake.org/files/v3.6/cmake-3.6.2.tar.gz tar zxvf cmake-3.6.2.tar.gz cd cmake-3.6.2 ./configure make &amp;amp;&amp;amp; make install  安装bison
wget -c http://git.typecodes.com/libs/ccpp/bison-3.0.tar.gz tar zxvf bison-3.0.tar.gz &amp;amp;&amp;amp; cd bison-3.0/ &amp;amp;&amp;amp; ./configure make &amp;amp;&amp;amp; make install  安装boost
wget http://nchc.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz tar zxvf boost_1_59_0.tar.gz cd boost_1_59_0 ./bootstrap.sh ./b2 stage threading=multi link=shared ./b2 install threading=multi link=shared  或者</description>
    </item>
    
    <item>
      <title>安装 Sphinx</title>
      <link>https://realjf.io/sphinx/set-up-sphinx/</link>
      <pubDate>Tue, 28 Apr 2020 14:26:34 +0800</pubDate>
      
      <guid>https://realjf.io/sphinx/set-up-sphinx/</guid>
      <description>简介 sphinx是由俄罗斯人开发的一个全文检索引擎。旨在为其他应用提供高速、低空间占用、告诫过相关度的全文搜索功能。
特性: - 高速的建立索引（在现代cpu上，峰值性能可达到10MB/秒）; - 高性能的搜索（在2~4GB的文本数据上，平均每次检索响应时间小于0.1秒） - 可处理海量数据（目前已知可以处理超过100GB的文本数据，在单一CPU系统上可处理100M文档） - 提供了优秀的相关度算法，基于短语相似度和统计的复合Ranking方法。 - 支持分布式搜索 - 支持短语搜索 - 提供文档摘要生成 - 可作为mysql的存储引擎提供搜索服务 - 支持布尔、短语、词语相似度等多种检索模式 - 文档支持多个全文检索字段（最大不超过32个） - 文档支持多个额外的属性信息 - 支持断词
官网地址：http://sphinxsearch.com/
下载地址：http://sphinxsearch.com/downloads/current/
二进制地址：http://sphinxsearch.com/files/sphinx-3.0.2-2592786-linux-amd64.tar.gz
源码包地址：http://sphinxsearch.com/files/sphinx-2.2.11-release.tar.gz
中文文档地址：http://www.sphinxsearch.org/archives/category/php
sphinx在mysql上的应用有两种方式：  采用api调用，如php、java等的api函数或方法查询。优点是可不必对mysql重新编译，服务端进程“低耦合”，且程序灵活度高、方便调用。 使用插件方式 sphinxSE把sphinx编译成一个mysql插件并使用特定的sql语句进行检索。 通过安装相关编程语言的扩展插件  准备  mysql mysql-devel 编译软件gcc gcc-c++ autoconf automake sphinx ```
安装工具 yum install -y make gcc libtool gcc-c++ g++ autoconf imake automake mysql-devel libxml2-devel expat-devel
  #### sphinx安装  下载 wget http://sphinxsearch.</description>
    </item>
    
    <item>
      <title>sphinx的 total 和 total_found的区别</title>
      <link>https://realjf.io/sphinx/total_found/</link>
      <pubDate>Tue, 28 Apr 2020 14:26:04 +0800</pubDate>
      
      <guid>https://realjf.io/sphinx/total_found/</guid>
      <description>sphinx.conf文件里面有一个配制最大匹配数的参数max_matches ,默认值是1000假如一次搜索里应该查询到2000个匹配,但是在sphinx结果集中只会返回1000个匹配，因为受到max_matches=1000的限制,这时候,结果集里, total=1000,total_found=2000,假设一页显示20条,那么如果用total_found做为分页的总数来设定,在第51页之后的数据都将显示为空白,因为操过了1000条记录.
于是,我修改了sphinx.conf里的max_matches=2000,结果发现,改成2000之后还是没有取到2000条记录,在第51页之后都是空白数据,为什么?
这时候我又去网上查了资料,发现,$s-&amp;gt;SetLimits($start, $limit)的第三个参数,默认为1000,这个参数也是用来设定返回的最大匹配数的,所以这就是这为什么配制文件里改成2000后还是只取到1000条记录的原因&amp;hellip;
还有一点,就是setLimits的第三个参数的值不能超过max_matches的值,否则将取不到记录
所以,total_found返回的是所有的匹配数,不受max_matches和setLimits的第三个参数的限制,而total返回的匹配数最大不超过max_matches和setLimits里的最小值
比如我们经常看到的,淘宝搜索返回的页面最多只返回100页的数据,这时候,total和total_found就能很好的起到作用</description>
    </item>
    
    <item>
      <title>C&#43;&#43;之内存模型 Memory Model</title>
      <link>https://realjf.io/cpp/memory-model/</link>
      <pubDate>Mon, 27 Apr 2020 16:44:23 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/memory-model/</guid>
      <description>C++使用三种不同方案（C++11是四种）来存储数据：
 自动存储持续性 在函数定义中声明的变量（包括函数参数）的持续性为自动的。他们在程序开始执行其所属的函数或代码块时被创建，在执行完函数或代码块时，他们使用的内存将被释放。 静态存储持续性 在函数定义外定义的变量和使用关键字static定义的变量存储的持续性都为静态，他们在程序整个运行过程中都存在。 线程储存持续性（C++11）多核处理器很常见，如果变量是使用关键字thread_local声明的，则其生命周期与所属的线程一样长。 动态存储持续性 用new运算符分配的内存将一直存在，知道使用delete运算符将其释放或程序结束位置。这种内存的存储持续性为动态，有时被称为自由存储或堆   作用域描述了名称在文件的多大范围可见 链接性描述了名称如何在不同单元间共享。链接性为外部的名称可在文件间共享，链接性为内存的名称只能由一个文件中的函数共享。自动变量的名称没有链接性，因为它们不能共享。
 自动存储持续性 在默认情况下，在函数中声明的函数参数和变量的存储持续性为自动，作用域为局部，没有链接性。
自动变量和栈 由于自动变量的数目随函数的开始和结束而增减，因此程序常留出一段内存对自动变量进行管理，通常将其视为栈。
栈是后进先出的，这种设计简化了参数传递。函数调用将其参数的值放在栈顶，然后重新设置栈顶指针，被调用的函数根据其形参描述来确定每个参数的地址。
静态持续变量 c++为静态存储持续性变量提供了3种链接性： - 外部链接性（可在其他文件中访问）、 - 内部链接性（只能在当前文件中访问） - 无连接性（只能在当前函数或代码中访问）
这三种链接性都在整个程序执行期间存在。
编译器将分配固定的内存块来存储所有的静态变量。主要是.data段里
 如果没有显示地初始化静态变量，编译器将把它设置为0.
    存储描述 持续性 作用域 链接性 如何声明     自动 自动 代码块 无 在代码块中   寄存器 自动 代码块 无 在代码块中，使用关键字register   静态，无链接性 静态 代码块 无 在代码块中，使用关键字static   静态，外部链接性 静态 文件 外部 不在任何函数内   静态，内部链接性 静态 文件 内部 不在任何函数内，使用关键字static    静态持续性、外部链接性 外部变量的存储持续性为静态，作用域为整个文件。外部变量也称全局变量。</description>
    </item>
    
    <item>
      <title>TCP协议流量控制与拥塞控制详解</title>
      <link>https://realjf.io/network/tcp-protocol/</link>
      <pubDate>Thu, 23 Apr 2020 17:31:45 +0800</pubDate>
      
      <guid>https://realjf.io/network/tcp-protocol/</guid>
      <description>TCP的主要特点  面向连接的运输层协议 可靠交付服务 提供全双工通信 面向字节流  连续ARQ协议  连续ARQ协议规定：发送方维持一个发送窗口，每收到一个确认，就把发送窗口向前滑动一个分组的位置。 接收方采用累积确认的方式，在收到几个分组后，对按序到达的最后一个分组发送确认。   MSS最大报文段长度
 滑动窗口协议 以字节为单位的滑动窗口。每个tcp活动连接的两端都维护一个发送窗口结构和接收窗口结构。tcp以字节为单位维护其窗口结构。 随着时间推移，当接收到返回的数据ack，滑动窗口也随之右移。
每个tcp报文段都包含ack号和窗口通告信息，tcp发送端可以据此调节窗口结构。
流量控制 所谓流量控制，就是让发送方的发送速率不要太快，要让接收方来得及接收，利用滑动窗口机制可以很方便在tcp连接上实现对发送方的流量控制。
图例说明下 TCP报文段发送机制  第一种机制是TCP维持一个tcp报文段发送出去 第二种机制是由发送方的应用进程指明要求发送报文段 第三种机制是发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段发送出去。  拥塞控制 拥塞控制原理 所谓拥塞控制就是防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制索要做的都有一个前提， 就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。
流量控制往往是指点对点通信量的控制。
拥塞控制方法 拥塞控制是一个动态的问题，从大的方面看，可以分为开环控制和闭环控制两种方法。
开环控制 就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。
闭环控制 闭环控制基于反馈环路，主要有以下几种措施：
 监测网络系统以便检测到拥塞在何时、何处发生。 把拥塞发生的信息传送到可采取行动的地方 调整网络系统的运行以解决出现的问题  拥塞控制的算法 tcp进行拥塞控制的算法有四种，即慢开始(slow-start)、拥塞避免(congestion avoidance)、快重传(fast retransmit)和快恢复(fast recovery)
慢开始和拥塞避免  发送方让自己的发送窗口等于拥塞窗口 判断网络出现拥塞的依据就是出现了超时
 慢开始算法思路：当主机开始发送数据时，由于并不清楚网络的负荷情况，所以如果立即把大量数据字节注入到网络，那么就有可能引起网络发生拥塞。 经验证明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。
RFC5681规定初始拥塞窗口cwnd设置为不超过2至4个SMSS（最大报文段）的数值，具体如下：
 若SMSS&amp;gt;2190字节，则设置初始拥塞窗口cwnd=2xSMSS字节，且不得超过2个报文段。 若SMSS&amp;gt;1095且SMSS&amp;lt;=2190字节，则设置初始拥塞窗口cwnd=3xSMSS字节，且不得超过3个报文段。 若SMSS&amp;lt;=1095字节，则设置初始拥塞窗口cwnd=4xSMSS字节，且不得超过4个报文段。  慢开始规定：在每收到一个对新的报文段的确认后，可以把拥塞窗口增加最多一个SMSS的数值。即
拥塞窗口cwnd每次的增加量 = min(N,SMSS)
这里使用报文段的个数作为窗口大小的单位，来阐述拥塞控制原理
 因此，使用慢开始算法后，每经过一个传输轮次，拥塞窗口cwnd就加倍。</description>
    </item>
    
    <item>
      <title>Tcp 连接的建立与终止</title>
      <link>https://realjf.io/network/tcp/</link>
      <pubDate>Thu, 23 Apr 2020 16:10:57 +0800</pubDate>
      
      <guid>https://realjf.io/network/tcp/</guid>
      <description>tcp连接的建立和终止依赖于connect、accept、close等函数。同时tcp也可以说是全双工的方式进行通信。
TCP连接的建立：三次握手 准备条件 服务器通过调用socket、bind和listen三个函数完成准备监听工作，称为被动打开。
第一次 客户端通过调用connect发起连接建立请求，客户端通过tcp发送一个SYN（同步）数据包， 数据包中携带的是建立连接发送数据的初始序列号。通常SYN数据包不携带数据
第二次 服务器收到客户端的SYN数据包后，需要对这个数据包回应一个ACK数据包（其确认序列号=初始序列号+1），且自己也需要发送建立连接的 同步SYN数据包，服务器在一个数据包中发送SYN和ACK信息，并携带自己的初始序列号
第三次 客户端确认收到服务端发送的ACK后，需要回应服务端发送的SYN并发送一个ACK数据包（其确认序列号=初始序列号+1）给服务端。 服务端收到后，连接建立。
TCP连接的终止： 四次挥手 第一次 某个进程首先调用close，称为主动关闭，主动端发送一个FIN数据包，同样携带一个初始序列号，表示数据发送完毕。
第二次 接收这个FIN数据包的称为被动端，它的接收也作为一个文件结束符传递给接收端应用程序，并发送一个ACK数据包给主动端，且携带一个确认序列号
第三次 过了某个时间，被动端的应用程序处理了这个文件结束符，调用了close关闭这端的套接字，所以也发送一个FIN数据包并携带一个初始序列号过去。
第四次 主动端收到关闭请求，也需要回应一个ACK数据包并携带一个确认序列号过去，表示结束。
TCP 状态转换图 TIME_WAIT状态 TIME_WAIT状态，在主动关闭端最后发送确认关闭ACK数据包后，需要等待一段时间才能关闭。这个停留时间是最长数据包生命周期（maximum segment lifetime）的两倍，称为2MSL。
任何TCP实现都必须为MSL选择一个值，RFC1122建议是2分钟。不过伯克利套接字实现改用30秒，这意味着持续时间可能在一分钟到4分钟之间。
TIME_WAIT存在的理由：
 可靠实现tcp全双工连接的终止 允许老的重复数据包在网络中消失（每个数据包都有一个跳数ttl限制，通常是255）  第一个理由 因为假设最后一个ACK数据包可能丢失，这样被动端在没有收到FIN的ACK确认关闭数据包时，会启用超时重传，重新发送FIN数据包， 因此，主动端必须维持状态以等待重传的那个FIN数据包，并允许它重新发送确认ACK数据包。
第二个理由 假设某个套接字（这里指ip和端口的组合）刚关闭，过一段时间这个套接字上又建立了另一个连接，如果这个时候那个丢失的数据包出现， 则可能被这个新连接误认为是发给它的数据，造成错误。tcp为了防止这种问题出现，就必须让这个套接字上之前关闭的连接等待一段时间， 以等待这个丢失的数据包消失，而这个时间就是2MSL，这个时间足以让这个丢失的数据包在网络中消失。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;常用关键字用法解析 const static volatile extern mutable</title>
      <link>https://realjf.io/cpp/keyword/</link>
      <pubDate>Wed, 22 Apr 2020 18:09:41 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/keyword/</guid>
      <description>static 修饰局部变量  静态局部变量只作用于其定义的函数期间，函数结束，其所占用的内存空间也被回收。 在静态存储区分配空间，只初始化一次  修饰全局变量  也称静态全局变量，其作用域在定义它的文件里，不能作用于其他文件。 静态全局变量在静态存储区分配空间，在程序开始运行时完成初始化，也是唯一的一次初始化  修饰函数  静态函数只在声明它的文件中可见，不能被其他文件使用。  修饰类成员  对于静态类成员，它属于类，而不属于某个对象实例，多个对象之间共享静态类成员 静态类成员存储于静态存储区，生命周期为整个程序执行期 静态类成员需要初始化，且在类外初始化，默认初始化为0  初始化方法：&amp;lt;数据类型&amp;gt; &amp;lt;类名&amp;gt;::&amp;lt;静态类成员&amp;gt;=&amp;lt;值&amp;gt;
修饰类成员函数  同样静态类成员函数属于整个类，而非某个实例对象，也没有this指针，需要通过类名进行访问。 不能将静态类成员函数定义为虚函数 &amp;gt; 虚函数依赖vptr和vtable，vptr通过类的构造函数生成，且只能用this指针访问，这也就是为什么静态成员函数不能是虚函数的原因 由于静态成员函数没有this指针，所以就差不多等同于nonmember函数，结果就产生了一个意想不到的好处：成为一个callback函数，使得我们得以将C++和C-based X Window系统结合，同时也成功的应用于线程函数身上 为了防止父类的影响，可以在子类定义一个与父类相同的静态变量，以屏蔽父类的影响。  const 规则：const离谁近，谁就不能被修改，只读的意思，且需要初始化。
修饰基本数据类型  修饰一般常量时，可以在类型说明符前也可以在其后，只要在使用时不改变常量即可。 const修饰指针变量*及引用变量&amp;amp; &amp;gt; 如果const位于星号*的左侧，则const就是用来修饰指针所指向的变量，即指针指向为常量 &amp;gt; 如果const位于星号的右侧，const就是修饰指针本身，即指针本身是常量  作为函数参数的修饰符 用相应的变量初始化const常量，则在函数体中，按照const所修饰的部分进行常量化，保护了原对象的属性不被修改
void say(const char* str){...}  作为函数返回值的修饰符 声明了返回值后，对返回值起到保护作用，即使得其返回值不为“左值”，只能作为右值使用。
const int add(int a, int b){...}  const修饰类成员 修饰的类成员的初始化只能在类的构造函数的初始化表中进行
const修饰类成员函数 作用是修饰的成员函数不能修改类的任何成员变量
int funcA() const {}  const修饰类对象，定义常量对象 常量对象只能调用常量函数，别的成员函数都不能调用。</description>
    </item>
    
    <item>
      <title>zab协议 （Zookeeper Zab Protocol）</title>
      <link>https://realjf.io/distributed/zookeeper-zab-protocol/</link>
      <pubDate>Wed, 22 Apr 2020 09:18:44 +0800</pubDate>
      
      <guid>https://realjf.io/distributed/zookeeper-zab-protocol/</guid>
      <description>ZAB协议，（ZooKeeper Atomic Broadcast, ZooKeeper原子消息广播协议） ZAB协议不像Paxos算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播协议
ZAB协议的核心 所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，而余下的其他服务器则成为follower服务器， leader服务器负责将一个客户端事务请求转换成一个事务Proposal，并将该Proposal分发给集群中所有的follower服务器，之后leader服务器需要 等待所有follower服务器的反馈，一旦超过半数的follower服务器进行了正确的反馈后，那么leader就会再次向所有的follower服务器分发commit消息， 要求其将前一个Proposal进行提交。
ZAB协议内容 ZAB协议包括两种基本模式：崩溃恢复和消息广播。
当整个服务框架在启动过程中，或是当leader服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB协议就会进入恢复模式并选举产生新的leader服务器。 当选举产生新的leader服务器后，同时集群中已经有过半机器与该leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式，其中，所谓的状态同步是指数据同步， 用来保证集群中存在过半的机器能够和leader服务器的数据状态保持一致。
当集群中已经有过半的follower服务器完成了和leader服务器的状态同步，那么整个服务器框架就可以进入消息广播模式了。当一台同样遵循ZAB协议的服务器启动后加入到集群中， 如果此时集群中已经存在一个leader服务器在负责进行消息广播，那么新加入的服务器就会自觉的进入数据恢复模式：找到leader所在的服务器，并与其进行数据同步， 然后一起参与到消息广播流程中。
ZooKeeper设计成只允许唯一的一个leader服务器来进行事务请求的处理。leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议， 而如果集群中的其他机器接收到客户端的事务请求，那么这些非leader服务器会首先将这个事务请求转发给leader服务器。
当leader服务器出现崩溃退出或机器重启，亦或集群中已经不存在过半的服务器与该leader服务器保持正常通信时，那么在重新开始新一轮的原子广播事务操作之前， 所有进程首先会使用崩溃恢复协议来使彼此达到一个一致的状态，于是整个ZAB流程就会从消息广播模式进入到崩溃恢复模式。
数据同步 在ZAB协议的事务编号ZXID设计中，ZXID是一个64位的数字，其中低32位可以看作是一个简单的单调递增的计数器，针对客户端的每一个事务请求，leader服务器在产生 一个新的事务Proposal的时候，都会对该计数器进行加1操作，而高32位则代表了leader周期epoch的编号，每当选举产生一个新的leader服务器，就会从这个leader 服务器上取出其本地日志中最大事务Proposal的ZXID，并从该ZXID中解析出对应的epoch值，然后再对其进行加1操作，之后就会以此编号作为新的epoch，并 将低32位置0来开始生成新的ZXID。ZAB协议中的这一通过epoch编号来区分leader周期变化的策略，能够有效避免不同的leader服务器错误地使用相同的ZXID编号 提出不一样的事务Proposal的异常情况，这对于识别在leader崩溃恢复前后生成的Proposal非常有帮助。
基于这样的策略，当一个包含了上一个leader周期中尚未提交过的事务Proposal的服务器启动时，其肯定无法成为leader，因为当前集群中一定包含一个Quorum集合， 该集合中的机器一定包含了更高epoch的事务Proposal，因此这台机器的事务Proposal肯定不是最高，也就无法成为leader了。
ZAB与Paxos算法的联系与区别 联系  两者都存在一个类似leader进程的角色，由其负责协调多个follower进程的运行 leader进程都会等待超过半数的follower做出正确的反馈后，才会将一个提案进行提交 在ZAB协议中，每个Proposal中都包含了一个epoch值，用来代表当前leader周期，在Paxos算法中，同样存在这样一个标识，只是名字是Ballot。
区别 Paxos算法一个新选举产生的主进程会进行两个阶段的工作，第一阶段称为读阶段，与所有其他进程通信收集上一个主进程提出的提案，并将它们提交。 第二个阶段称为写阶段，主进程开始提出自己的提案。
  ZAB协议在Paxos算法上额外添加了一个同步阶段。在同步阶段之前，ZAB有个类似Paxos算法的读阶段，称为发现阶段。同步阶段之后，也有一个类似的写阶段。</description>
    </item>
    
    <item>
      <title>分布式一致性协议 2PC和3PC Paxos（Distributed Consistency Protocol）</title>
      <link>https://realjf.io/distributed/distributed-consistency-protocol/</link>
      <pubDate>Tue, 21 Apr 2020 10:05:32 +0800</pubDate>
      
      <guid>https://realjf.io/distributed/distributed-consistency-protocol/</guid>
      <description>分布式一致性协议在实践过程中产生了许多优秀的协议和算法，其中就包括两阶段提交、三阶段提交协议和Paxos算法。
2PC：两阶段提交 两阶段提交，主要由协调者和参与者组成，协调者负责协调所有参与者是否提交最后结果，并保证各参与者之间的结果一致（提交或者回滚）。
阶段一：提交事务请求阶段  协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并等待各参与者的回应 各参与者节点执行事务操作，并将undo和redo信息记录事务日志中 如果参与者执行了事务操作，那么就反馈给协调者yes响应，表示事务可以执行，否则返回no，表示事务不可以执行。  阶段二：执行事务提交阶段 阶段二主要是对各参与者反馈的情况决定是否继续进行事务提交操作，或者回滚。 主要包括两种情况：
第一种：执行事务提交 假如协调者从所有的参与者获得的反馈都是yes，那么就执行事务提交。
 发送提交请求，协调者向所有参与者节点发送commit请求 事务提交，参与者接收到commit请求后，会正式执行事务提交，并在完成后释放整个事务执行期间占用的资源 反馈事务提交结果，提交完成后，向协调者发送ack信息 完成事务，协调者接收到所有参与者的ack信息后，完成事务。  第二种：中断事务 假如任何一个参与者向协调者反馈了no，或者在等待超时之后，协调者仍然没有接收到所有参与者的反馈，那么就中断事务。
 发送回滚请求，协调者向所有参与者节点发送rollback请求 事务回滚，参与者接收到rollback请求后，利用第一阶段中记录的undo信息来执行事务回滚，并在完成回滚后释放在整个事务期间占用的资源 反馈事务回滚结果，参与者在完成事务回滚之后，向协调者发送ack信息 中断事务，协调者接收到所有的参与者反馈的ack信息后，完成事务中断  两阶段提交优缺点  优点：原理简单，实现方便 缺点：同步阻塞，单点问题、脑裂、容错机制简单  3PC：三阶段提交 三阶段提交可说是2PC的改进版，其将二阶段提交协议的提交事务请求过程一分为二，形成了CanCommit、PreCommit和do Commit三个阶段组成的事务处理协议。
阶段一：CanCommit  事务询问，协调者向所有的参与者发送一个包含事务内容的canCommit请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。 各参与者向协调者反馈事务询问的响应，参与者在接收到来自协调者的canCommit请求后，正常情况是，如果其自身认为可以顺利执行事务，那么会反馈yes，并进入预备状态，否则反馈no  阶段二：PreCommit 阶段二，协调者会根据各参与者的反馈情况来决定是否可以进行事务的PreCommit操作，正常情况，包括两种：
第一种：执行事务预提交 假如协调者从所有的参与者获得的反馈都是yes，那么就会执行事务预提交。
 发送预提交请求，协调者向所有参与者节点发送preCommit请求，并进入prepared阶段。 事务预提交，参与者接收到preCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。 各参与者向协调者反馈事务执行的响应，如果参与者成功执行了事务操作，那么就反馈给协调者ack响应，同时等待最终指令：提交（commit）或终止（abort）  第二种：中断事务 如果协调者收到任何一个参与者反馈了no，或者等待超时之后，仍然无法接收到所有参与者的反馈，那么就中断事务。
 发送中断请求，协调者向所有参与者节点发送abort请求 中断事务，无论是收到来自协调者的abort，或者是等待协调者请求过程中出现超时，参与者都会中断事务。  阶段三：doCommit 这个阶段是真正执行事务提交，存在两种可能
第一种：执行提交  发送提交请求，假设协调者处于正常状态，并且收到了所有参与者的ack信息，那么它就从预提交状态转换到提交状态，并向所有参与者发送doCommit请求 事务提交，参与者接收到doCommit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的资源。 反馈事务提交结果，参与者在完成事务提交之后，向协调者发送ack信息 完成事务，协调者接收到所有参与者的反馈ack信息后，完成事务。  第二种：中断事务 在这个阶段，假设协调者正常，并且有任意一个参与者反馈了no，或者等待超时之后，协调者无法接收到所有参与者的响应，那么就中断事务。
 发送中断请求，协调者向所有参与者节点发送abort请求 事务回滚，参与者接收到abort请求后，会利用其在阶段二中记录的undo信息来执行回滚，并在完成回滚之后释放事务执行期间占用的资源。 反馈事务回滚结果，事务完成回滚之后，向协调者发送ack信息 中断事务，协调者接收到所有参与者反馈的的ack信息后，中断事务  注意：一旦进入阶段三，可能有两种故障</description>
    </item>
    
    <item>
      <title>五种I/O模式 （Io Pattern）</title>
      <link>https://realjf.io/cpp/io-pattern/</link>
      <pubDate>Fri, 17 Apr 2020 15:22:29 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/io-pattern/</guid>
      <description>常见的五种I/O模式 I/O模式有这五种，分别是：
 阻塞I/O （linux下默认都采用阻塞I/O） 非阻塞I/O （可以通过fcntl或者open设置使用O_NONBLOCK参数，将文件描述符设置为非阻塞） I/O多路复用 信号驱动I/O 异步I/O  其中前面四种被称为同步IO
用户空间与内核空间 首先理解，当进程运行在内核空间时就处于内核态，而进程运行在用户空间时则处于用户态。 在内核态下，进程运行在内核地址空间中，此时的 CPU 可以执行任何指令。运行的代码也不受任何的限制，可以自由地访问任何有效地址，也可以直接进行端口的访问。 在用户态下，进程运行在用户地址空间中，被执行的代码要受到 CPU 的诸多检查，它们只能访问映射其地址空间的页表项中规定的在用户态下可访问页面的虚拟地址，且只能对任务状态段(TSS)中 I/O 许可位图(I/O Permission Bitmap)中规定的可访问端口进行直接访问。
所以，区分内核空间和用户空间本质上是要提高操作系统的稳定性及可用性
进程切换过程 从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： - 保存上下文，包括程序计数器和其他寄存器 - 更新PCB信息(进程管理与控制信息) - 把进程pcb加入等待挂起等队列 - 选择另一个进程执行，并更新其pcb - 更新内存管理的数据结构 - 恢复上下文
阻塞IO 同步阻塞IO，用户进程发起一个IO请求，内核查看数据是否就绪，如果没有，就等待数据就绪，而用户进程处于阻塞状态， 且交出cpu控制权，但数据就绪后，内核将数据拷贝到用户进程空间，并通知用户进程，用户进程解除阻塞状态，进入就绪状态，等待下一次运行。
非阻塞I/O 非阻塞IO，用户进程发起IO请求后，内核检查相应状态，无论就绪与否都返回结果给用户进程，用户进程无需等待就可以根据相应结果进行处理， 当然用户进程可以循环发起IO请求操作，这相当于一直占用CPU。
I/O多路复用 多路IO复用是目前比较多的用于环节C10K问题的方案，采用select、poll、epoll等方式，其中epoll是linux特有的。 相比较非阻塞IO，多路复用的效率明显要高，且是在内核中进行的。
下面分别简要说下select、poll和epoll的区别
select select 函数监听的文件描述符有三类，writefds、readfds和exceptfds，调用后select会阻塞进程，直到有描述符就绪，或者超时， 函数返回后，通过遍历fdset，查找相应就绪的描述符进行处理。
select目前支持几乎所有的平台，在linux上一般限制最大监视文件描述符大小为1024。
 select最大限制是单进程fd最大支持1024个，64为系统默认为2048 对文件描述符采用轮询，效率低 需要维护一个用于存放大量fd的数据结构  poll poll本质上与select类似，管理多个文件描述符，也是进行轮询，根据描述符的状态进行处理。 但它没有最大数限制，poll也有个致命缺陷，包含大量文件描述符的数组被整个在内核与用户空间之间多次复制， 开销随着文件描述符数量激增
epoll epoll是linux2.6开始提供的功能，是对poll的改进，epoll没有文件描述符限制，使用一个文件描述符管理多个描述符， 将用户关心的事件描述符映射到内核中，期间只复制一次。
epoll使用epoll_ctl注册文件描述符，并监听自己感兴趣的事件，使用epoll_wait可以收到事件通知。
epoll的两种触发模式  EPOLLLT （水平触发）当epoll_wait监听的事件发生时，将此事件通知用户进程，用户进程可以不立即处理该事件。下次调用epoll_wait时，会再次响应并通知此事件 EPOLLET （边缘触发）当epoll_wait监听的事件发生时，将此事件通知用户进程，用户进程必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应通知此事件。  epoll的优点  没有最大并发数限制 效率提升，内核态监听事件，只复制一次事件映射集，不是轮询机制，而是使用事件通知机制，只有活跃的文件描述符才占用开销。  epoll的工作流程 信号驱动I/O 信号驱动IO,用户进程首先需要安装SIGIO信号处理函数，然后内核等待IO请求，用户进程继续执行， 直到内核发出SIGIO信号，表示数据准备好，并拷贝到用户进程空间，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;多态与虚函数 （Polymorphism）</title>
      <link>https://realjf.io/cpp/polymorphism/</link>
      <pubDate>Fri, 17 Apr 2020 14:04:30 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/polymorphism/</guid>
      <description>什么是多态？ C++的多态即针对同一事物对不同场景表现多种形态，称为c++的多态性
多态分为静态多态和动态多态 - 静态多态又分为函数重载和泛型编程 - 动态多态则通过虚函数实现
多态的作用  提供了接口与具体实现之间的另一层隔离， 改善了代码的组织结构和可读性以及可扩展性  静态多态 直接上代码
int Add(int a, int b) { return a + b; } double Add(float a, float b) { return a + b; } // 调用的时候 int main() { Add(1, 2); // 调用的是第一个Add Add(1.5, 2.5); // 调用的是第二个Add return 0; }  可以看到，静态多态是在编译期间可以确定的，根据具体的了类型调用不同的函数
动态多态 首先要理解，这里的动态是指在程序运行期间，所以动态多态只能在程序运行的时候确定。
而要实现动态多态，这里需要用到关键字virtual，声明一个函数为虚函数
具体代码：
class Animal { public: virtual void Say() = 0; } class Cow : public Animal { public: void Say() { cout &amp;lt;&amp;lt; &amp;quot;哞哞&amp;quot; &amp;lt;&amp;lt; endl; } } class Sheep : public Animal { public: void Say() { cout &amp;lt;&amp;lt; &amp;quot;咩咩&amp;quot; &amp;lt;&amp;lt; endl; } } // 开始使用 int main() { Animal* cow = (Animal*)new Cow(); Animal* sheep = (Animal*)new Sheep(); cow-&amp;gt;Say(); sheep-&amp;gt;Say(); }  有上述代码可以看出，多态是基类中包含虚函数，而子类对其进行重写的，并且通过基类对象的指针或引用调用虚函数形成多态。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;智能指针详解（Smart Pointer）</title>
      <link>https://realjf.io/cpp/smart-pointer/</link>
      <pubDate>Fri, 17 Apr 2020 11:21:57 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/smart-pointer/</guid>
      <description> 智能指针 智能指针在C++11版本之后提供，包含在头文件中，包括三种： - shared_ptr - unique_ptr - weak_ptr
智能指针的作用 由于C++没有垃圾回收机制，一切内存堆操作都是程序员自己管理，但对于程序员来说管理堆不胜麻烦，稍有不慎忘记释放就会造成内存泄露最终导致内存溢出等问题。 而智能指针则能有效避免此类问题发生。
智能指针通过对普通指针进行类封装，使其表现的跟普通指针类似的行为。
shared_ptr指针 shared_ptr 使用引用计数，每一个shared_ptr的拷贝都指向相同的内存地址，每使用一次，内部的引用计数加1， 每析构一次，内部的引用计数减1，减到0时，自动删除所指向的堆内存。shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。
 初始化。std::shared_ptr n，也可以make_shared函数初始化。不能直接赋值一个指针，因为它是类。 拷贝和赋值，拷贝引用计数加1，赋值引用计数减1，当计数为0时，自动释放内存。 get函数获取原始指针 不要用一个原始指针初始化多个shared_ptr，否则会造成二次释放同一内存。 避免循环引用，循环引用会导致内存泄漏。  unique_ptr指针 unique_ptr 唯一拥有其所指对象，统一时刻只能有一个unique_ptr指向给定对象（通过禁止拷贝语义，只有移动语义实现）。 相比原始指针，unique_ptr的RAII特性，使得其在出现异常时，能自动释放指向对象占用资源。unique_ptr生命周期从创建到作用域结束， 离开作用域时，若其指向对象，则将其所指向对象销毁。
unique_ptr在生命周期内，可以改变智能指针所指对象，通过release释放所有权，通过reset函数指定新对象，通过移动语义转移所有权。
weak_ptr指针  weak_ptr作为一个辅助智能指针，配合shared_ptr可以对资源使用情况进行观测。 weak_ptr可以从一个shared_ptr或另一个weak_ptr对象中构造，以获得资源观测权，它不会使原对象引用计数增加，  智能指针的原理 智能指针：实际指行为类似于指针的类对象，是利用了一种叫做RAII（资源获取即初始化）的技术对普通的指针进行封装, 它的一种通用实现方法是采用引用计数的方法。
 1.智能指针将一个计数器与类指向的对象相关联，引用计数跟踪共有多少个类对象共享同一指针。 2.每次创建类的新对象时，初始化指针并将引用计数置为1； 3.当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数； 4.对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数；这是因为左侧的指针指向了右侧指针所指向的对象，因此右指针所指向的对象的引用计数+1； 5.调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）。 6.实现智能指针有两种经典策略：一是引入辅助类，二是使用句柄类。这里主要讲一下引入辅助类的方法  </description>
    </item>
    
    <item>
      <title>死锁 Deadlock</title>
      <link>https://realjf.io/posts/deadlock/</link>
      <pubDate>Thu, 16 Apr 2020 15:28:20 +0800</pubDate>
      
      <guid>https://realjf.io/posts/deadlock/</guid>
      <description> 什么是死锁？ 简单说，是指两个或两个以上的线程在执行过程中，彼此持有对方需要的资源和处于等待对方释放资源的现象， 如果没有外力作用，这种状态将一直持续下去。
如何避免？ 避免死锁的一般建议是：对竞争资源按顺序采用互斥加锁
当然，如果能在编程时就注意这方便的问题，将可以用更好的方式，比如：
 避免嵌套锁 避免在持有锁时调用用户提供的代码 使用固定顺序获取锁 使用锁的层次结构  </description>
    </item>
    
    <item>
      <title>memcache数据提前过期（丢失）Memcache Data Lost</title>
      <link>https://realjf.io/mc/memcache-data-lost/</link>
      <pubDate>Wed, 15 Apr 2020 10:51:20 +0800</pubDate>
      
      <guid>https://realjf.io/mc/memcache-data-lost/</guid>
      <description>背景 今天遇到一个比较奇葩的问题，使用脚本测试接口防洪攻击时，mc的封禁数据还未到过期时间就出现数据“丢失”的情况， 一直以为是代码问题，后来偶然想到memcache在达到内存超过50%以上时，就可能采用LRU算法回收部分内存，考虑到防洪封禁数据 比较多，所以做了本地测试
了解下memcache的一些状态信息 php通过getStat函数获取memcache状态信息。
 pid mc进程号 uptime 服务器已运行秒数 version 版本 time 当前时间 libevent libevent版本 pointer_size 当前os的指针大小(64位系统一般为64) rusage_user 进程的累计用户时间 rusage_system 进程的累计系统时间 curr_connections 服务器当前打开的连接数 total_connections 从服务器启动后累计打开的总连接数 connection_structures 服务器分配的连接结构数 reserved_fds cmd_get get命令总请求次数 cmd_set set命令总请求次数 cmd_flush flush命令请求次数 cmd_touch touch命令请求次数 get_hits get命令总命中次数 get_misses get命令总未命中次数 delete_misses delete_hits incr_misses incr_hits decr_misses decr_hits cas_misses cas_hits cas_badval 使用擦拭次数 touch_hits touch_misses auth_cmds 认证命令处理次数 auth_errors 认证失败次数 bytes_read 总读取字节数（请求字节数） byte_written 总发送字节数（结果字节数） limit_maxbytes 分配给memcache的内存大小（字节） accepting_conns 服务器是否大打过最大连接数 listen_disabled_num 失效的监听数 threads 当前线程数 conn_yields 连接操作主动放弃数目 hash_power_level hash_bytes hash_is_expanding malloc_fails bytes 当前存储内容所占总字节数 curr_items 当前存储的items数量 total_items 从启动后存储的items总数量 expired_unfetched evicted_unfetched evictions 为获取空闲内存而删除的items数，LRU算法释放（分配给memcache的空间用满后需要删除旧的items来得到空间分配给新的items） reclaimed 已过期的数据条目来存储新数据的数目 crawler_reclaimed lrutail_reflocked  解决方法是，增大MC使用内存</description>
    </item>
    
    <item>
      <title>大文件分片上传 之 基于webuploader组件（Chunk Upload File）</title>
      <link>https://realjf.io/php/chunk-upload-file/</link>
      <pubDate>Mon, 13 Apr 2020 14:00:07 +0800</pubDate>
      
      <guid>https://realjf.io/php/chunk-upload-file/</guid>
      <description>针对大文件（上百兆或者好几个G的大文件上传，总是比较麻烦的，这里将介绍一个比较方便的解决方案
准备  百度的webuploader组件 lnmp或lamp开发环境  本次使用的是百度分享的分片js组件webuploader
同时后端使用php接收分片文件，并进行最后的组装。
第一步，首先下载webuploader插件 下载地址：https://github.com/fex-team/webuploader/releases
解压后文件结构如下：
├── Uploader.swf // SWF文件，当使用Flash运行时需要引入。 ├── webuploader.js // 完全版本。 ├── webuploader.min.js // min版本 ├── webuploader.custom.js ├── webuploader.nolog.js ├── webuploader.flashonly.js // 只有Flash实现的版本。 ├── webuploader.flashonly.min.js // min版本 ├── webuploader.html5only.js // 只有Html5实现的版本。 ├── webuploader.html5only.min.js // min版本 ├── webuploader.withoutimage.js // 去除图片处理的版本，包括HTML5和FLASH. └── webuploader.withoutimage.min.js // min版本 下载  第二步，创建一个html页面，引入一下文件 &amp;lt;link href=&amp;quot;/resource/webuploader/webuploader.css&amp;quot; rel=&amp;quot;stylesheet&amp;quot; /&amp;gt; &amp;lt;script src=&amp;quot;/resource/webuploader/webuploader.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;  页面内容如下：
&amp;lt;div id=&amp;quot;uploader&amp;quot; class=&amp;quot;wu-example&amp;quot;&amp;gt; &amp;lt;div id=&amp;quot;uploader&amp;quot; class=&amp;quot;wu-example&amp;quot;&amp;gt; &amp;lt;!--用来存放文件信息--&amp;gt; &amp;lt;div class=&amp;quot;filename&amp;quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;quot;state&amp;quot;&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;quot;progress&amp;quot;&amp;gt; &amp;lt;div id=&amp;quot;progress_bar&amp;quot; class=&amp;quot;progress-bar progress-bar-info progress-striped active&amp;quot; role=&amp;quot;progressbar&amp;quot; style=&amp;quot;width: 0%&amp;quot;&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class=&amp;quot;btns&amp;quot;&amp;gt; &amp;lt;div id=&amp;quot;picker&amp;quot;&amp;gt;选择文件&amp;lt;/div&amp;gt; &amp;lt;button id=&amp;quot;ctlBtn&amp;quot; class=&amp;quot;btn btn-default&amp;quot;&amp;gt;开始上传&amp;lt;/button&amp;gt; &amp;lt;button id=&amp;quot;pause&amp;quot; class=&amp;quot;btn btn-danger&amp;quot;&amp;gt;暂停上传&amp;lt;/button&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt;  第三步，js逻辑如下 &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt; $(function () { var GUID = WebUploader.</description>
    </item>
    
    <item>
      <title>C&#43;&#43; 的Struct和Class 的区别</title>
      <link>https://realjf.io/cpp/struct-and-class-inherit/</link>
      <pubDate>Sat, 22 Feb 2020 22:14:22 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/struct-and-class-inherit/</guid>
      <description> 关于c++的class和struct的不同可以简单归纳为以下几点： 内部成员变量及成员函数的默认防控属性不同 struct默认防控属性是public，而class默认的防控属性是Private
继承关系中的默认防控属性的区别 在继承关系中，struct默认是public，而class是private
在继承中的基类和子类之间的继承方式
   继承方式 基类的public成员 基类的protected成员 基类中的private成员     public继承 仍为public成员 仍为protected成员 不可见   protected继承 变为protected成员 变为protected成员 不可见   private继承 变为private成员 变为private成员 不可见    模板中使用 class关键字可以用于定义模板参数，但是struct不行
template&amp;lt;template T, class Y&amp;gt; int Func(const T&amp;amp; t, const Y&amp;amp; y) { ... }  使用花括号{}赋值问题  struct如果没有定义构造函数，可以使用花括号对struct成员进行赋值。 struct中如果定义了一个构造函数，则不能使用花括号进行赋值  </description>
    </item>
    
    <item>
      <title>debian 系统启动进入Busybox Initramfs界面</title>
      <link>https://realjf.io/linux/error/boot-into-busybox-initramfs/</link>
      <pubDate>Thu, 20 Feb 2020 22:07:19 +0800</pubDate>
      
      <guid>https://realjf.io/linux/error/boot-into-busybox-initramfs/</guid>
      <description>首先说下背景  系统环境： debian 9  问题描述1 今天使用vmware workstation的时候，提示操作失败，且提示为文件系统只读。 奇怪？怎么突然进入可读了，猜想可能文件系统哪里损坏导致进入只读保护模式。
所以重新启动，之后进入了busybox界面的Initramfs界面，输入help可以查看相应命令。 我使用exit直接退出看能否重新进入，发现还是提示错误，无法进入
 busybox可以提供一个比较完善的shell工具集以及运行环境，同时可以引导程序进入系统。
 解决 在多次尝试重启无果后，重新查看错误提示，提到了/dev/mapper/realjf&amp;ndash;vg-root的文件系统， 可能是文件系统损坏了，所以开始检查修复文件系统：fsck /dev/mapper/realjf&amp;ndash;vg-root， 然后系统开始检查文件系统损坏情况，并尝试进行修复，多次输入&amp;rsquo;y&amp;rsquo;后，提示文件系统修复完成， 然后重新输入exit看是否能重新进入系统，发现已经可以进入系统了。
问题描述2 Gave up waiting for root device. Common problems: - Boot args (cat /proc/cmdline) - Check rootdelay=(did the system wait for the right device ?) - Missing modules (cat /proc/modules; ls /dev) ALERT! /dev/mapper/realjf--vg-root does not exist. Dropping to a shell! BusyBox v.1.23.2 (Debian xxx. xxx) built-in shell (ash) Enter &#39;help&#39; for list of built-in commands.</description>
    </item>
    
    <item>
      <title>Channel 底层实现原理</title>
      <link>https://realjf.io/golang/channel-implement/</link>
      <pubDate>Mon, 20 Jan 2020 09:08:15 +0800</pubDate>
      
      <guid>https://realjf.io/golang/channel-implement/</guid>
      <description>channel是golang的一大特色，golang的goroutine之间的通信也建议通过channel机制实现。 那么我们有必要探讨下，channel的底层实现机制，以便我们更好的应用channel。
 本次探讨版本为go v1.13
 channel的实现原理 go中实现channel的文件包含在/runtime/chan.go中
type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel.</description>
    </item>
    
    <item>
      <title>linux系统资源设置 之 Ulimit 命令</title>
      <link>https://realjf.io/linux/command/ulimit/</link>
      <pubDate>Tue, 10 Dec 2019 14:14:25 +0800</pubDate>
      
      <guid>https://realjf.io/linux/command/ulimit/</guid>
      <description>根据linux 开发手册， ulimit 设置和获取用户的资源限制
ulimit 参数说明
   选项 说明     -t 最大 cpu 占用时间 (单位是秒)   -f 进程创建文件大小的最大值 (单位是blocks)   -d 进程最大的数据段的大小，以kbytes为单位   -s 线程栈的大小，以kbytes为单位   -c 最大的core文件的大小，以blocks为单位   -m 最大内存大小，以kbytes为单位   -u 用户最大的可用的进程数   -n 可以打开的最大文件描述符数量   -l 最大可加锁内存大小，以kbytes为单位   -v 进程最大可用的虚拟内存，以kbytes为单位   -x    -i    -q    -e    -r    -N    -p 管道缓冲区的大小，以kbytes为单位   -a 显示所有资源限制的设定   -S 设定资源的弹性限制    </description>
    </item>
    
    <item>
      <title>如何写go语言的基准测试？</title>
      <link>https://realjf.io/golang/how-to-write-benchmarks-in-go/</link>
      <pubDate>Mon, 25 Nov 2019 15:08:36 +0800</pubDate>
      
      <guid>https://realjf.io/golang/how-to-write-benchmarks-in-go/</guid>
      <description>简介 Go标准库中test包包含一个基准测试工具，可用于检查Go代码的性能。 接下来将介绍如何使用测试包编写一个简单的基准测试。
一个基准测试示例 我们以斐波那契数列计算来做测试
func Fib(n int) int { if n &amp;lt; 2 { return n } return Fib(n-1) + Fib(n-2) }  创建一个名为*_test.go的测试文件，我们将对计算第20个斐波那契数列值进行性能测试。
func BenchmarkFib20(b *testing.B) { for n := 0; n &amp;lt; b.N; n++ { Fib(20) } }  编写基准测试与编写测试非常相似，因为它们共享测试包中的基础结构。一些关键区别是
 基准测试功能以Benchmark而不是Test开头 基准功能由测试包运行多次。 b.N的值每次都会增加，直到基准运行者对基准的稳定性感到满意为止。 每个基准测试必须执行b.N次测试代码。 BenchmarkFib20中的for循环将出现在每个基准测试函数中。  运行基准测试 我们可以使用go test -bench=. 调用基准测试
go test -bench=. # 运行结果如下 goos: linux goarch: amd64 pkg: test/benchmark BenchmarkFib-4 30000 44684 ns/op PASS ok test/benchmark 1.</description>
    </item>
    
    <item>
      <title>Cmake 使用基本教程</title>
      <link>https://realjf.io/devtools/cmake-tutorial/</link>
      <pubDate>Sat, 23 Nov 2019 14:14:43 +0800</pubDate>
      
      <guid>https://realjf.io/devtools/cmake-tutorial/</guid>
      <description>首先创建一个项目
mkdir Tutorial cd Tutorial touch tutorial.cxx  tutorial.cxx内容如下：
 第一步：从最基础开始 最简单的应用是在项目根目录下创建一个CMakeLists.txt文件，内容如下：
# 设置cmake最小要求版本 cmake_minimum_required(VERSION 3.10) # 设置项目名称 project(Tutorial) # 添加可执行文件 add_executable(Tutorial tutorial.cxx)  CMake支持大写，小写和大小写混合命令，上述示例使用小写方式。
添加版本号和配置头文件 第一个功能cmake_minimum_required是为我们的可执行文件和项目提供版本号。 虽然我们可以仅在源代码中执行此操作，但是使用CMakeLists.txt可提供更大的灵活性
cmake_minimum_required(VERSION 3.10) # 设置项目版本号 project(Tutorial VERSION 1.0)  配置头文件以将版本号传递给源代码
configure_file(TutorialConfig.h.in TutorialConfig.h)  由于已配置的文件将被写入二进制树，因此我们必须将该目录添加到路径列表中以搜索包含文件。 将以下行添加到CMakeLists.txt文件的末尾
target_include_directories(Tutorial PUBLIC &amp;quot;${PROJECT_BINARY_DIR}&amp;quot; )  在源目录中使用以下内容创建TutorialConfig.h.in
// 配置选项和设置项目配置 #define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@ #define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@  当CMake配置此头文件时，@Tutorial_VERSION_MAJOR@和@Tutorial_VERSION_MINOR@的值将被替换。 接下来，修改tutorial.cxx以包括配置的头文件TutorialConfig.h
最后，通过更新tutorial.cxx来打印出版本号
if (argc &amp;lt; 2) { // report version std::cout &amp;lt;&amp;lt; argv[0] &amp;lt;&amp;lt; &amp;quot; Version &amp;quot; &amp;lt;&amp;lt; Tutorial_VERSION_MAJOR &amp;lt;&amp;lt; &amp;quot;.</description>
    </item>
    
    <item>
      <title>unix环境高级编程 之 apue.h环境安装配置 </title>
      <link>https://realjf.io/unix/how-to-setup-apue-env/</link>
      <pubDate>Sat, 23 Nov 2019 09:20:03 +0800</pubDate>
      
      <guid>https://realjf.io/unix/how-to-setup-apue-env/</guid>
      <description> 官网http://www.apuebook.com/apue3e.html
准备 apt-get install libbsd-dev  如果不执行上面步骤可能会出现如下问题：
barrier.c:(.text+0x6e): undefined reference to `heapsort’ collect2: ld make[1]: *** [barrier] make[1]: Leaving directory `/home/albert/Documents/progs/apue.3e/threads’ make: *** [all]  1. 下载解压 wget http://www.apuebook.com/src.3e.tar.gz tar zxvf src.3e.tar.gz cd apue.3e make  2. 复制相关头文件到/usr/include等 cp ./include/apue.h /usr/include cp ./lib/libapue.a /usr/local/lib  3. 搭建成功，测试 gcc 1-3.c -o 1-3 -lapue # 编译连接后 ./1-3 /lib # 查看是否正常执行程序  </description>
    </item>
    
    <item>
      <title>unix网络编程 之 myerr.h文件</title>
      <link>https://realjf.io/files/myerr/</link>
      <pubDate>Sat, 23 Nov 2019 08:51:45 +0800</pubDate>
      
      <guid>https://realjf.io/files/myerr/</guid>
      <description>unix网络编程 之 myerr.h文件 myerr.h
// myerr.h #include &amp;lt;errno.h&amp;gt;/* for definition of errno */ #include &amp;lt;stdarg.h&amp;gt;/* ISO C variable aruments */ static void err_doit(int, int, const char *, va_list); /* * Nonfatal error related to a system call. * Print a message and return. */ void err_ret(const char *fmt, ...) { va_list ap; va_start(ap, fmt); err_doit(1, errno, fmt, ap); va_end(ap); } /* * Fatal error related to a system call. * Print a message and terminate.</description>
    </item>
    
    <item>
      <title>unix网络编程 之 ourhdr.h文件</title>
      <link>https://realjf.io/files/ourhdr-h/</link>
      <pubDate>Sat, 23 Nov 2019 08:51:24 +0800</pubDate>
      
      <guid>https://realjf.io/files/ourhdr-h/</guid>
      <description>unix网络编程 之 ourhdr.h文件 ourhdr.h
// ourhdr.h #ifndef __ourhdr_h #define __ourhdr_h #include &amp;lt;errno.h&amp;gt; /*for definition of errno */ #include &amp;lt;stdarg.h&amp;gt; /*ANSI C header file */ #include &amp;lt;sys/types.h&amp;gt; /* required for some of our prototypes */ #include &amp;lt;stdio.h&amp;gt; /* for convenience */ #include &amp;lt;stdlib.h&amp;gt; /* for convenience */ #include &amp;lt;string.h&amp;gt; /* for convenience */ #include &amp;lt;unistd.h&amp;gt; /* for convenience */ #define MAXLINE 4096 /* max line length */ #define FILE_MODE (S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH) /* default file access permissions for new files */ #define DIR_MODE (FILE_MODE | S_IXUSR | S_IXGRP | S_IXOTH) /* default permissions for new directoris */ typedef void Sigfunc(int); /* for signal handlers */ /* 4.</description>
    </item>
    
    <item>
      <title>unix网络编程 之 unp.h头文件安装配置</title>
      <link>https://realjf.io/unix/how-to-setup-unp-env/</link>
      <pubDate>Sat, 23 Nov 2019 08:17:24 +0800</pubDate>
      
      <guid>https://realjf.io/unix/how-to-setup-unp-env/</guid>
      <description>unix网络编程环境之unp.h安装配置 官网http://www.unpbook.com/src.html
1. 下载安装 wget http://www.unpbook.com/unpv13e.tar.gz tar zxvf unpv13e.tar.gz cd unpv13e ./configure cd lib make cd ../libfree make  上面make遇到报错，如下
gcc -I../lib -g -O2 -D_REENTRANT -Wall -c -o in_cksum.o in_cksum.c gcc -I../lib -g -O2 -D_REENTRANT -Wall -c -o inet_ntop.o inet_ntop.c inet_ntop.c: In function ‘inet_ntop’: inet_ntop.c:60:9: error: argument ‘size’ doesn’t match prototype size_t size; ^~~~ In file included from inet_ntop.c:27: /usr/include/arpa/inet.h:64:20: error: prototype declaration extern const char *inet_ntop (int __af, const void *__restrict __cp, ^~~~~~~~~ make: *** [&amp;lt;builtin&amp;gt;: inet_ntop.</description>
    </item>
    
    <item>
      <title>Golang 并发编程 之 sync.Mutex 或 channel（通道）</title>
      <link>https://realjf.io/posts/golang-concurrency-mutexorchannel/</link>
      <pubDate>Thu, 21 Nov 2019 18:01:02 +0800</pubDate>
      
      <guid>https://realjf.io/posts/golang-concurrency-mutexorchannel/</guid>
      <description>并发控制中sync.Mutex 与 channel 的使用？ go的创建者建议“通过通信共享内存，不通过共享内存进行通信”。
也就是说，Go确实在sync包中提供了传统的锁定机制。大多数锁定问题可以使用通道锁定或传统锁定来解决
使用锁机制和通道的优劣分析 Go新手常见的错误是仅仅因为可能和/或很有趣而过度使用通道和goroutine。如果最适合您的问题，请不要害怕使用sync.Mutex。 Go务实的做法是让您使用能够最好地解决问题的工具，而不用强迫您使用一种代码风格.
通常
   channel mutex     相互传递数据，分发工作单元，传递异步结果 缓存，状态    wait-group 另一个重要的同步机制是sync.WaitGroup。 这允许多个协作goroutine在再次独立运行之前共同等待同一个阈值事件。
通常在两种情况下很有用。
 在“清理”时，可以使用sync.WaitGroup来确保所有goroutine（包括主要的goroutine）都在完全终止之前等待 更常见的情况是循环算法，其中涉及一组goroutine，这些goroutine全部独立工作一段时间，然后全部等待障碍，然后再次独立进行。此模式可能会重复很多次。障碍事件可能会交换数据。此策略是批量同步并行（BSP）的基础  结语 怎么使用取决于你的应用场景，通道通信，互斥锁和等待组是互补的，可以组合使用。</description>
    </item>
    
    <item>
      <title>Golang 并发编程 之 runtime.LockOSThread</title>
      <link>https://realjf.io/posts/golang-concurrency-lockosthread/</link>
      <pubDate>Thu, 21 Nov 2019 17:10:37 +0800</pubDate>
      
      <guid>https://realjf.io/posts/golang-concurrency-lockosthread/</guid>
      <description>背景介绍 一些库（尤其是图形框架和库（例如Cocoa，OpenGL和libSDL））使用线程局部状态，并且可能要求仅从特定OS线程（通常是“主”线程）调用函数。 Go为此提供了runtime.LockOSThread函数，接下来通过示例说明如何正确使用它。
package dl import ( &amp;quot;fmt&amp;quot; &amp;quot;runtime&amp;quot; ) // 安排main.main在主线程上运行 func init() { runtime.LockOSThread() } // 在主线程main.main中调用Main循环 func Main() { for f := range mainfunc { // 取出工作队列中的函数进行调用 f() } } var mainfunc = make(chan func()) func do(f func()) { done := make(chan bool, 1) // 将整个函数加入到工作队列中 mainfunc &amp;lt;- func() { f() fmt.Println(&amp;quot;add queue&amp;quot;) done &amp;lt;- true } &amp;lt;-done } func Beep() { do(func() { // 无论什么时候都运行在主线程 fmt.</description>
    </item>
    
    <item>
      <title>Golang 并发编程 之 超时处理</title>
      <link>https://realjf.io/posts/golang-concurrency-timeout/</link>
      <pubDate>Thu, 21 Nov 2019 17:10:13 +0800</pubDate>
      
      <guid>https://realjf.io/posts/golang-concurrency-timeout/</guid>
      <description>并发编程中的超时处理 在并发编程中，要放弃运行时间太长的同步调用，请使用带有time.After的select语句，如下：
import ( &amp;quot;errors&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;time&amp;quot; ) func main() { var timeoutNanoseconds time.Duration = 5 * time.Second c := make(chan error, 1) go func() { time.Sleep(20 * time.Second) c &amp;lt;- errors.New(&amp;quot;error&amp;quot;) } () select { case err := &amp;lt;-c: // use err and reply fmt.Println(err) case &amp;lt;-time.After(timeoutNanoseconds): // call timed out fmt.Println(&amp;quot;timeout...&amp;quot;) } }  以上代码在超时5秒后退出</description>
    </item>
    
    <item>
      <title>Golang 并发编程 之 数据竞态检测</title>
      <link>https://realjf.io/posts/golang-data-race-detector/</link>
      <pubDate>Thu, 21 Nov 2019 16:41:31 +0800</pubDate>
      
      <guid>https://realjf.io/posts/golang-data-race-detector/</guid>
      <description>什么是数据争用或竞态 数据争用是并发系统中最常见且最难调试的错误类型之一。当两个goroutine并发访问同一变量并且至少其中之一是写操作时，就会发生数据争用。
下面让我们来实际模拟一下数据争用问题。
以下示例可能导致内存崩溃和损坏的数据争用
func main() { c := make(chan bool) m := make(map[string]string) go func() { m[&amp;quot;1&amp;quot;] = &amp;quot;a&amp;quot; c &amp;lt;- true }() m[&amp;quot;2&amp;quot;] = &amp;quot;b&amp;quot; &amp;lt;-c for k, v := range m { fmt.Println(k, v) } }  运行go run -race main.go进行竞争检测，得到的结果如下：
#================== WARNING: DATA RACE Write at 0x00c00008e150 by goroutine 6: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:202 +0x0 main.main.func1() /root/go_project/src/test/race.go:9 +0x5d Previous write at 0x00c00008e150 by main goroutine: runtime.mapassign_faststr() /usr/local/go/src/runtime/map_faststr.go:202 +0x0 main.</description>
    </item>
    
    <item>
      <title>Protobuf  数据类型</title>
      <link>https://realjf.io/posts/protobuf-data-type/</link>
      <pubDate>Mon, 28 Oct 2019 15:31:06 +0800</pubDate>
      
      <guid>https://realjf.io/posts/protobuf-data-type/</guid>
      <description>基础类型    .proto类型 java类型 c++类型 备注     double double double    float float float    int32 int int32 使用可变长编码方式。编码负数时不够高效，如果你的字段可能包含负数，请使用sint32   int64 long int64 使用可变长编码方式。编码负数时不够高效，如果你的字段可能包含负数，请使用sint64   uint32 int[1] uint32 总是4个字节，如果数值总是比228大的话，这个类型会比uint32高效   uint64 long[1] uint64 总是8个字节，如果数值总是比256大的话，这个类型会比uint64高效   sint32 int int32 使用可变编码方式，有符号的整型值，编码时比通常的int32高效   sint64 long int64 使用可变长编码方式，有符号的整型值，编码时比通常的int64高效   fixed32 int[1] uint32 总是4个字节。如果数值总是比总是比228大的话，这个类型会比uint32高效。   fixed64 long[1] unit64 总是8个字节。如果数值总是比256大的话，这个类型会比uint64高效   sfixed32 int int32 总是4个字节   sfixed64 long int64 总是8个字节   bool boolean bool    string String string 一个字符串必须是utf-8编码或者7-bit ascii编码的文本   bytes ByteString string 可能包含任意顺序的字节数据    特殊字段    英文 中文 备注     enum 枚举(数字从零开始) 作用是为字段指定某”预定义值序列” enum Type {MAN = 0;WOMAN = 1; OTHER= 3;}   message 消息体 message User{}   repeated 数组/集合 repeated User users = 1   import 导入定义 import &amp;ldquo;protos/other_protos.</description>
    </item>
    
    <item>
      <title>Golang Micro 微服务框架使用</title>
      <link>https://realjf.io/posts/golang-micro-usage/</link>
      <pubDate>Tue, 22 Oct 2019 09:50:59 +0800</pubDate>
      
      <guid>https://realjf.io/posts/golang-micro-usage/</guid>
      <description>准备  搭建好golang开发环境 安装git等相关工具  开始 一、安装protobuf protobuf用于生成微服务代码
go get github.com/micro/protoc-gen-micro # 同时需要安装protoc和protoc-go-gen go get -d -u github.com/golang/protobuf/protoc-gen-go go install github.com/golang/protobuf/protoc-gen-go   如果需要别的语言的代码生成器，请参阅https://github.com/protocolbuffers/protobuf
关于protobuf的使用，请参阅https://developers.google.com/protocol-buffers/
 二、服务发现 服务发现用于将服务名称解析为地址，服务发现可以使用etcd、zookeeper、consul等组件
安装etcd etcd下载地址https://github.com/etcd-io/etcd/releases
三、写一个服务 以下为一个简单的rpc服务例子
创建服务proto 微服务的关键要求之一是严格定义接口。
Micro使用protobuf来实现这一目标。 在这里，我们使用Hello方法定义了Greeter处理程序。 它需要一个字符串参数同时使用一个HelloRequest和HelloResponse。
syntax = &amp;quot;proto3&amp;quot;; service Greeter { rpc Hello(HelloRequest) returns (HelloResponse) {} } message HelloRequest { string name = 1; } message HelloResponse { string greeting = 2; }  生成proto protoc --proto_path=$GOPATH/src:. --micro_out=.</description>
    </item>
    
    <item>
      <title>Golang语言标准库之 sync/atomic原子操作</title>
      <link>https://realjf.io/posts/sync-atomic/</link>
      <pubDate>Thu, 17 Oct 2019 17:37:02 +0800</pubDate>
      
      <guid>https://realjf.io/posts/sync-atomic/</guid>
      <description>原子操作，顾名思义是不可分割的，他可以是一个步骤，也可以是多个步骤，其执行过程不会被线程调度机制打断的操作。
 原子性不可能由软件单独保证，需要硬件的支持，因此和架构有关。在x86架构平台下，cpu提供了在指令执行期间对总线加锁的手段。
CPU芯片上有一条引线#HLOCK pin，如果汇编语言的程序中在一条指令前面加上前缀&amp;rdquo;LOCK&amp;rdquo;，经过汇编以后的机器代码就使CPU在执行这条指令的时候把#HLOCK pin的电位拉低，
持续到这条指令结束时放开，从而把总线锁住，这样同一总线上别的CPU就暂时不能通过总线访问内存了，保证了这条指令在多处理器环境中的原子性。
 sync/atomic包的文件结构以及数据结构可以参考这里
sync/atomic包提供了6中操作数据类型
 int32 uint32 int64 uint64 uintptr unsafe.Pointer  分别为这每种数据类型提供了五种操作
 add 增减 load 载入 store 存储 compareandswap 比较并交换 swap 交换  下面以int32为例，具体使用上面五种操作实现原子操作 AddInt32操作 var val int32 val = 10 atomic.AddInt32(&amp;amp;val, 10) // 对于无符号32位即uint32，则需要使用二进制补码进行操作 var val2 uint32 val2 = 10 atomic.AddUint32(&amp;amp;val2, ^uint32(10 - 1)) // 等价于 val2 - 10  CompareAndSwapInt32 对比并交换是指先判断addr指向的值是否与参数old一致，如果一致就用new值替换addr的值，最后返回成功，具体例子如下
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;sync&amp;quot; &amp;quot;sync/atomic&amp;quot; ) func main() { var val int32 wg := sync.</description>
    </item>
    
    <item>
      <title>Mysql 5.7.27源码安装教程</title>
      <link>https://realjf.io/posts/mysql-5.7-installation/</link>
      <pubDate>Tue, 15 Oct 2019 09:11:41 +0800</pubDate>
      
      <guid>https://realjf.io/posts/mysql-5.7-installation/</guid>
      <description>准备  debian 9操作系统 mysql下载地址：https://downloads.mysql.com/archives/get/file/mysql-5.7.27.tar.gz boost下载地址：http://nchc.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz  下载安装 1. 下载安装boost wget http://nchc.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz tar zxvf boost_1_59_0.tar.gz mv boost_1_59_0 /usr/local/boost  2. 下载安装mysql # 安装依赖包 apt-get install libncurses-dev # 创建mysql用户组和用户 groupadd mysql useradd mysql -s /sbin/nologin -M -g mysql # 下载mysql wget https://downloads.mysql.com/archives/get/file/mysql-5.7.27.tar.gz tar zxvf mysql-5.7.27.tar.gz cd mysql-5.7.27 # 创建必要的文件夹 mkdir /usr/local/mysql mkdir /usr/local/mysql/data # 数据库文件 mkdir /usr/local/mysql/tmp # sock文件 mkdir /usr/local/mysql/logs # 错误日志文件 mkdir /usr/local/mysql/binlog # binlog日志文件 # 编译mysql cmake .</description>
    </item>
    
    <item>
      <title>Mysql Community Server Installation(mysql 8.0.17 社区版本安装教程)</title>
      <link>https://realjf.io/posts/mysql-community-server-installation/</link>
      <pubDate>Mon, 14 Oct 2019 17:50:16 +0800</pubDate>
      
      <guid>https://realjf.io/posts/mysql-community-server-installation/</guid>
      <description>一、下载安装 下载地址：https://downloads.mysql.com/archives/community/
# 下载 wget https://downloads.mysql.com/archives/get/file/mysql-8.0.17-linux-glibc2.12-x86_64.tar.xz xz -d mysql-8.0.17-linux-glibc2.12-x86_64.tar.xz tar xvf mysql-8.0.17-linux-glibc2.12-x86_64.tar # 移动到你需要安装的目录下 mv mysql-8.0.17-linux-glibc2.12-x86_64 /usr/local/mysql  二、配置 1. 在mysql根目录下创建一个新的data目录，用于存放数据 cd /usr/local/mysql mkdir data  2. 创建mysql用户组和mysql用户 groupadd mysql useradd -g mysql mysql  3. 改变mysql目录权限 chown -R mysql.mysql /usr/local/mysql/  4. 初始化数据库 # 创建mysql_install_db安装文件 mkdir mysql_install_db chmod 777 ./mysql_install_db # 初始化数据库 bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data # 记录好自己的临时密码  5. mysql配置 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld  修改my.cnf文件
vim /etc/my.</description>
    </item>
    
    <item>
      <title>Django后端 &#43; Vue前端 构建Web开发框架</title>
      <link>https://realjf.io/posts/django-vue-web/</link>
      <pubDate>Mon, 14 Oct 2019 15:17:48 +0800</pubDate>
      
      <guid>https://realjf.io/posts/django-vue-web/</guid>
      <description>一、准备  Django &amp;gt;= 1.11 python &amp;gt;= 3.6 mysql &amp;gt;= 5.7 node &amp;gt;= 10.15 vue-cli &amp;gt;= 2.0   本次实验项目基于debian 9系统进行构建，以下涉及到的一些安装命令请根据自己具体环境自行替换
 二、安装 1. 安装node wget https://nodejs.org/dist/v10.16.3/node-v10.16.3-linux-x64.tar.xz xz -d node-v10.16.3-linux-x64.tar.xz tar xvf node-v10.16.3-linux-x64.tar # 然后将文件夹移动到你需要的地方，设置环境变量PATH即可 mv node-v10.16.3-linux-x64 /usr/local/node-v10.16.3 # 这里使用软链进行设置l ln -sf /usr/local/node-v10.16.3/bin/node /usr/local/bin/ ln -sf /usr/local/node-v10.16.3/bin/npm /usr/local/bin/ # 设置好后进行测试 node --version npm --version  2. 安装python3，pip # 打开下载地址 https://www.python.org/downloads/source/ # 选择适合自己的包下载 wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tar.xz xz -d Python-3.7.4.tar.xz tar xvf Python-3.</description>
    </item>
    
    <item>
      <title>Makefile 基本语法和规则</title>
      <link>https://realjf.io/devtools/makefile-rule/</link>
      <pubDate>Mon, 30 Sep 2019 21:57:15 +0800</pubDate>
      
      <guid>https://realjf.io/devtools/makefile-rule/</guid>
      <description> 基本语法 target1 target2 target3: prerequisite1 prerequisite2 command1 command2 command3  冒号的左边可以出现一个或多个工作目标，而冒号的右边可以出现零个或多个必要条件。 如果冒号的右边没有指定必要条件，那么只有在工作目标所代表的文件不存在时才会进行更新的动作。
每个命令必须以跳格符开头，这个语法用来要求make将紧跟在跳格符之后的内容传给subshell来执行。
make会将#号视为注释字符，从井号开始到该行结束之间的所有文字都会被make忽略。你可以使用反斜线，来延续过长的文本行。
规则 </description>
    </item>
    
    <item>
      <title>Nginx服务的基本配置</title>
      <link>https://realjf.io/posts/nginx-base-setting/</link>
      <pubDate>Mon, 30 Sep 2019 14:56:20 +0800</pubDate>
      
      <guid>https://realjf.io/posts/nginx-base-setting/</guid>
      <description>按照用户使用时的预期功能分成了4个功能
 用于调试、定位问题的配置项 正常运行的必备配置项 优化性能的配置项 事件类配置项  用于调试进程和定位问题的配置项 1. 是否以守护进程方式运行nginx 语法： daemon on|off;
默认：daemon on;
守护进程是脱离终端并且在后台运行的进程。它脱离终端是为了避免进程执行过程中的信息在任何终端中显示，这样一来，进程也不会被任何终端所产生的信息所打断。 因此，默认都是以这种方式运行的。
2. 是否以master/worker方式运行 语法： master_process on|off;
默认： master_process on;
一个master进程管理多个worker进程的方式运行的，几乎所有的产品环境下，nginx都是以这种方式工作。
3. error日志的配置 语法：error_log /path/file level;
默认：error_log logs/error.log error;
error日志是定位nginx问题的最佳工具，我们可以根据自己的需求妥善设置error日志的路径和级别。
/path/file参数可以是一个具体的文件，最好将它放到一个磁盘足够大的位置； 也可以是/dev/null，这样就不会输出任何日志了，这也是关闭error日志的唯一手段； 也可以是stderr，这样日志会输出到标准错误文件中。
level是日志的输出级别，取值范围是debug、info、notice、warn、error、crit、alert、emerg。 当设置一个级别，大于或等于该级别的日志都会被输出到/path/file文件中。小鱼该级别的日志则不会输出。
4. 是否处理几个特殊的调试点 语法：debug_points [stop|abort]
这个配置项也是用来帮助用户跟踪调试nginx的。他接受两个参数：stop和abort。 nginx在一些关键的错误逻辑中设置了调试点。如果设置了debug_points为stop，那么nginx的代码执行到这些调试点时就会发出sigstop信号用以调试。 如果设置为abort，则会生成一个coredump文件，可以使用gdb来查看nginx当时的各种信息。
通常不会使用这个配置项。
5. 仅对指定的客户端输出debug级别的日志 语法：debug_connection [IP|CIDR]
这个配置项实际上属于事件类配置，因此，他必须放在events{&amp;hellip;}中才有效，他的值可以是ip地址或cidr地址，如：
events{ debug_connection 10.224.66.14; debug_connection 10.224.57.0/24; }  这样，仅仅来自以上ip地址的请求才会输出debug级别的日志，其他请求仍然沿用error_log中配置的日志级别。
这个配置对修复bug很有用，特别是定位高并发请求下才会发生的问题。
 在debug_connection前，需要确保在执行configure时已经加入了&amp;ndash;with-debug参数，否则不会生效。
 6. 限制coredump核心转储文件的大小 语法：worker_rlimit_core size;</description>
    </item>
    
    <item>
      <title>Linux 内核参数优化</title>
      <link>https://realjf.io/posts/linux-kernel-optimize/</link>
      <pubDate>Mon, 30 Sep 2019 13:50:42 +0800</pubDate>
      
      <guid>https://realjf.io/posts/linux-kernel-optimize/</guid>
      <description>由于默认的linux内核参数考虑的是最通用的场景，这种场景下并不适合高并发访问的web服务器的定义，所以需要修改如下参数， 使得nginx可以拥有更高的性能。
根据不同的业务特点，nginx作为静态web内容服务器、反向代理服务器或者提供图片缩略图功能（实时亚索图片）的服务器时， 其内核参数调整是不同的。
这里只针对最通用，使nginx支持更多并发请求的tcp网络参数做简单说明。
需要修改/etc/sysctl.conf来更改内核参数。
fs.file-max = 999999 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_fin_timeout = 30 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.ip_local_port_range = 1024 61000 net.ipv4.tcp_rmem = 4096 32768 262142 net.ipv4.tcp_wmem = 4096 32768 262142 net.core.netdev_max_backlog = 8096 net.core.rmem_default = 262144 net.core.wmem_default = 262144 net.rmem_max = 2097152 net.wmem_max = 2097152 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn.backlog = 1024  参数说明
 file-max: 这个参数表示进程可以同时打开的最大句柄数，这个参数直接限制最大并发连接数，需要根据实际情况配置 tcp_tw_reuse: 这个参数设置为1，表示允许将TIME_WAIT状态的socket重新用于新的tcp连接，这对于服务器来说很有意义，因为服务器上总会有大量TIME-WAIT状态的连接 tcp_keepalive_time: 这个参数表示当keepalive启用时，tcp发送keepalive消息的频度。默认是2小时，若将其设置的小一些，可以更快地清理无效的连接 tcp_fin_timeout: 这个参数表示当服务器主动关闭连接时，socket保持在FIN-WAIT-2状态的最大时间。 tcp_max_tw_buckets: 这个参数表示操作系统允许TIME-WAIT套接字数量的最大值，如果超过这个数字，TIME-WAIT套接字将立刻被清除并打印警告信息。这个参数默认为180000，过多的TIME-WAIT套接字会使web服务器变慢。 tcp_max_syn_backlog: 这个参数表示TCP三次握手建立阶段接收syn请求队列的最大长度，默认为1024，将其设置得大一些可以使出现nginx繁忙来不及accept新连接的情况时，linux不至于丢失客户端发起的连接请求。 ip_local_port_range: 这个参数定义了在udp和tcp连接中本地（不包括连接的远端）端口的取值范围。 net.</description>
    </item>
    
    <item>
      <title>Scan Qrcode</title>
      <link>https://realjf.io/posts/scan-qrcode/</link>
      <pubDate>Wed, 04 Sep 2019 09:28:23 +0800</pubDate>
      
      <guid>https://realjf.io/posts/scan-qrcode/</guid>
      <description>网页调用微信JSSDK实现扫一扫功能 设置公众号js接口安全域 在公众号后台的，公众号设置，功能设置里
配置ip白名单 在公众号后台基本配置里
页面引入微信sdkjs代码 http://res.wx.qq.com/open/js/jweixin-1.2.0.js
页面js代码 // 点击扫一扫按钮事件 $(&amp;quot;#btn-scan&amp;quot;).on(&amp;quot;click&amp;quot;, function () { //微信扫一扫 设置 var _queryString = window.location.search; $.ajax({ type: &amp;quot;post&amp;quot;, url: &amp;quot;/mobile/user/scanSign&amp;quot;, data: {query: _queryString}, success: function (data) { var result = data.result; wx.config({ debug: false, // 调试接口用 appId: result.appId, //公众号的唯一标识 timestamp: &amp;quot;&amp;quot; + result.timestamp, //生成签名的时间戳 nonceStr: result.nonceStr, //生成签名的随机串 signature: result.signature, //签名 jsApiList: [&#39;scanQRCode&#39;] //需要使用的JS接口列表(我只需要调用扫一扫的接口，如有多个接口用逗号分隔) }); } }); }); //微信扫一扫处理代码 wx.ready(function () { $(&amp;quot;body&amp;quot;).off(&amp;quot;click&amp;quot;, &amp;quot;.j-btn_chat&amp;quot;).on(&amp;quot;click&amp;quot;, &amp;quot;.j-btn_chat&amp;quot;, function (e) { wx.</description>
    </item>
    
    <item>
      <title>Ruby 环境安装</title>
      <link>https://realjf.io/posts/ruby-installation/</link>
      <pubDate>Fri, 30 Aug 2019 12:42:08 +0800</pubDate>
      
      <guid>https://realjf.io/posts/ruby-installation/</guid>
      <description> centos7 下进行安装ruby 准备 下载ruby ruby下载地址：http://www.ruby-lang.org/en/downloads/
这里以2.6.4版本为例
wget https://cache.ruby-lang.org/pub/ruby/2.6/ruby-2.6.4.tar.gz  解压配置安装 tar zxvf ruby-2.6.4.tar.gz -C /usr/local/ cd /usr/local/ruby-2.6.4/ ./configure make &amp;amp;&amp;amp; make install  添加到环境变量中 ln -s /usr/local/ruby-2.6.4/ruby /usr/bin/ruby  验证 ruby -v  </description>
    </item>
    
    <item>
      <title>Srs Obs FFmpeg Vlc搭建rtmp直播服务，并实现推流拉流</title>
      <link>https://realjf.io/posts/srs-obs-ffmpeg-vlc/</link>
      <pubDate>Wed, 10 Jul 2019 16:06:30 +0800</pubDate>
      
      <guid>https://realjf.io/posts/srs-obs-ffmpeg-vlc/</guid>
      <description>rtmp srs直播服务器搭建 准备  srs 提供直播流服务器 obs 提供推流服务 ffmpeg 强大的软件，可作为推流端使用 vlc 用于播放rtmp直播  1. 首先搭建rtmp srs服务器 git clone https://github.com/ossrs/srs cd srs/trunk # 构建srs ./configure &amp;amp;&amp;amp; make # 开启服务 ./objs/srs -c conf/srs.conf # 停止服务 ./objs/srs stop # 重启服务 ./objs/srs restart  2. 安装obs apt-get install obs-studio  关于obs推流设置https://obsproject.com/wiki/OBS-Studio-Quickstart
3. 安装vlc apt-get install vlc  在推流设置完成后，测试推流效果步骤如下： 1. 打开VLC，选择open media-&amp;gt;network 2. 在网络协议中输入推流地址，点击play即可
4. 安装ffmpeg git clone https://git.ffmpeg.org/ffmpeg.git ffmpeg cd ffmpeg # 编译ffmpeg .</description>
    </item>
    
    <item>
      <title>Sublimetext debian安装与常用插件配置</title>
      <link>https://realjf.io/devtools/sublimetext/</link>
      <pubDate>Fri, 05 Jul 2019 10:27:14 +0800</pubDate>
      
      <guid>https://realjf.io/devtools/sublimetext/</guid>
      <description>sublime text官网http://www.sublimetext.com
 安装 install the GPG key wget -qO - https://download.sublimetext.com/sublimehq-pub.gpg | sudo apt-key add -  确保apt工作在http源 apt-get install apt-transport-https  选择安装渠道 稳定版本
echo &amp;quot;deb https://download.sublimetext.com/ apt/stable/&amp;quot; | sudo tee /etc/apt/sources.list.d/sublime-text.list  开发版本
echo &amp;quot;deb https://download.sublimetext.com/ apt/dev/&amp;quot; | sudo tee /etc/apt/sources.list.d/sublime-text.list  更新源并安装 apt-get update apt-get install sublime-text  安装常用插件 1. 安装Package Control 请参考网址Install Package Control
2. 常用插件 ConvertToUTF8 功能：能将除UTF8编码之外的其他编码文件在 Sublime Text 中转换成UTF8编码，在打开文件的时候一开始会显示乱码，然后一刹那就自动显示出正常的字体，当然，在保存文件之后原文件的编码格式不会改变
BracketHighlighter 功能：高亮显示匹配的括号、引号和标签。
Emmet 功能：前端开发必备，HTML、CSS代码快速编写神器</description>
    </item>
    
    <item>
      <title>分布式系统 之 容错性</title>
      <link>https://realjf.io/posts/fault-tolerance/</link>
      <pubDate>Thu, 28 Mar 2019 21:44:20 +0800</pubDate>
      
      <guid>https://realjf.io/posts/fault-tolerance/</guid>
      <description>容错性 基本概念 容错与系统可靠性息息相关，可靠系统满足以下特性：
 可用性 可靠性 安全性 可维护性  故障分类 故障通常分为三类
 暂时故障 间歇故障 持久故障  分布式系统中的典型故障模式可分为以下几种：
 崩溃性故障 遗漏性故障 定时性故障 响应性故障 任意性故障  任意性故障是最严重的故障，也称拜占庭故障。
分布式提交 在分布式系统中，事务往往包含多个参与者的活动，单个参与者的活动是能够保证原子性的， 而保证多个参与者之间原子性则需要通过两阶段提交或者三阶段提交算法实现。
两阶段提交 两阶段提交协议（2PC）的过程涉及协调者和参与者。协调者可以看做事务的发起者，同时也是事务的一个参与者。 对于一个分布式事务来说，一个事务是涉及多个参与者的。
第一阶段(准备阶段)
 协调者节点向所有参与者节点询问是否可以执行提交操作，并开始等待各参与者节点的响应。 参与者节点执行所有事务操作，并将undo信息和redo信息写入日志（若成功其实这里每个参与者已经执行了事务操作） 个参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个同意消息，如果参与者节点事务操作实际执行失败，则返回一个终止操作  第二阶段（提交阶段）
如果协调者收到了参与这的失败消息或者超时，直接给每个参与者发送回滚消息，否则，发送提交消息； 参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。
 当协调者节点从所有参与者节点处获得的相应消息都为同意时：  协调者节点向所有参与者节点发送正式提交请求 参与者节点正式完成操作，并释放在整个事务期间内占用的资源 参与者节点向协调者节点发送完成消息  如果任一参与者节点在第一阶段返回的消息为终止，或者协调者节点在第一阶段的询问在超时之前无法获取所有参与者节点的响应消息时：  协调者节点向所有参与者节点发送回滚操作请求 参与者节点利用之前写入的undo信息执行回滚，并释放在整个事务期间内占用的资源 参与者节点向协调者节点发送回滚完成消息 协调者节点收到所有参与者节点反馈的回滚完成消息后，取消事务 协调者节点收到所有参与者节点返回的完成消息后，完成事务。    缺点
 同步阻塞问题。执行过程中，所有参与者节点都是事务阻塞型的。 单点故障问题。由于协调者的重要性，一旦协调者发生故障，参与者会一直阻塞下去。 数据不一致。在阶段二中，当协调者向参与者发送commit请求后，发生了局域网异常，或者在发送commit请求过程中协调者发生故障， 这会导致只有一部分参与者接收到了commit请求。而在这部分参与者接收到commit请求之后就会执行commit操作。但是其他部分未接收到commit请求的机器无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象。 两阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了，那么， 即使协调者通过选举产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否已被提交。  为了解决两阶段提交的种种问题，提出了三阶段提交。
三阶段提交 三阶段提交是两阶段提交的改进版，有 两个改动点：</description>
    </item>
    
    <item>
      <title>linux Cgroups</title>
      <link>https://realjf.io/posts/cgroups/</link>
      <pubDate>Thu, 21 Mar 2019 05:14:39 +0800</pubDate>
      
      <guid>https://realjf.io/posts/cgroups/</guid>
      <description>Namespace技术为docker容器做了重要的隔离，但是docker容器每个隔离空间之间怎么保持独立而不互相竞争资源呢？这就是cgroups要做的事情了
Linux Cgroups(control groups)提供了对一组进程及其子进程的资源限制、控制和统计的能力，包括cpu、内存、存储和网络等。
cgroups组件  cgroup subsystem hierarchy  cgroup cgroup是对进程分组管理的一种机制，一个cgroup包含一组进程，并可以在这个cgroup上增加linux subsystem的各种配置参数，将一组进程和一组subsystem的系统参数关联起来。
subsystem 是一组资源控制的模块，包括 - blkio 设置对块设备输入输出的访问控制 - cpu 设置cgroup 中进程的cpu被调度的策略 - cpuacct 可以统计cgroup中进程的cpu占用 - cpuset 在多核机器上设置cgroup中进程可以使用的cpu和内存 - devices 控制cgroup中进程对设备的访问 - freezer 用于挂起和恢复cgroup中的进程 - memory 用于控制cgroup中进程的内存占用 - net_cls 用于将cgroup中进程产生的网络包分类，以便linux的tc可以根据分类区分来自某个cgroup的包并做限流和监控 - ns 使cgroup中的进程在新的namespace中fork新进程时，创建出一个新的cgroup，这个cgroup包含新的namespace中的进程
每个subsystem会关联到定义了相应限制的cgroup上，并对这个cgroup中的进行做相应的限制和控制。这些subsystem是逐步合并到内核中的。
 如何看内核当前支持哪些subsystem呢？使用apt-get install cgroup-bin，然后通过lssubsys -a查看
 hierarchy 把一组cgroup串成一个树状结构，一个这样的树便是一个hierarchy，通过这种树状结构，cgroups可以形成继承关系。
三个组件的关系  系统在创建了新的hierarchy之后，系统中所有的进程都会加入这个hierarchy的cgroup根节点，这个cgroup根节点是hierarchy默认创建的 一个subsystem只能附加到一个hierarchy上面 一个hierarchy可以附加多个subsystem 一个进程可以作为多个cgroup的成员，但是这些cgroup必须在不同的hierarchy中。 一个进程fork出子进程时，子进程是和父进程在同一个cgroup中的，也可以根据需要将其移动到其他cgroup中。  kernel加载Cgroups kernel通过虚拟树状文件系统配置cgroups，通过层级的目录虚拟出cgroup树。
1. 首先，要创建并挂载一个hierarchy mkdir cgroup-test mount -t cgroup -o none,name=cgroup-test cgroup-test .</description>
    </item>
    
    <item>
      <title>golang性能分析利器之Pprof</title>
      <link>https://realjf.io/posts/pprof/</link>
      <pubDate>Tue, 19 Mar 2019 15:14:16 +0800</pubDate>
      
      <guid>https://realjf.io/posts/pprof/</guid>
      <description>简介 pprof是golang程序一个性能分析的工具，可以查看堆栈、cpu信息等
pprof有2个包：net/http/pprof以及runtime/pprof
二者之间的关系：net/http/pprof包只是使用runtime/pprof包来进行封装了一下，并在http端口上暴露出来
性能分析利器 pprof go本身提供的工具链有： - runtime/pprof：采集程序的运行数据进行分析 - net/http/pprof：采集HTTP Server的运行时数据进行分析
pprof以profile.proto读取分析样本的集合，并生成报告以可视化并帮助分析数据
 profile.proto是一个Protocol Buffer v3的描述文件，它描述了一组callstack和symbolization信息，作用是表示统计分析的一组采样的调用栈，是很常见的stacktrace配置文件格式
 使用方式  Report generation：报告生成 Interactive terminal use：交互式终端使用 Web interface：Web界面  1. web服务器方式 假如你的go呈现的是用http包启动的web服务器，当想要看web服务器的状态时，选择【net/http/pprof】，使用方法如下：
&amp;quot;net/http&amp;quot; _ &amp;quot;net/http/pprof&amp;quot;  查看结果：通过访问：http://domain:port/debug/pprof查看当前web服务的状态
2. 服务进程 如果你go程序是一个服务进程，同样可以选择【net/http/pprof】包，然后开启另外一个goroutine来开启端口监听
// 远程获取pprof数据 go func() { log.Println(http.ListenAndServe(&amp;quot;localhost:8080&amp;quot;, nil)) }  3. 应用程序 如果你的go程序只是一个应用程序，那就直接使用runtime/pprof包，具体用法是用pprof.StartCPUProfile和pprof.StopCPUProfile。
var cpuprofile = flag.String(&amp;quot;cpuprofile&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;write cpu profile to file&amp;quot;) func main() { flag.Parse() if *cpuprofile != &amp;quot;&amp;quot; { f, err := os.</description>
    </item>
    
    <item>
      <title>Ceph 集群搭建一 之 集群搭建</title>
      <link>https://realjf.io/posts/setup-ceph-cluster-3/</link>
      <pubDate>Tue, 19 Mar 2019 14:57:12 +0800</pubDate>
      
      <guid>https://realjf.io/posts/setup-ceph-cluster-3/</guid>
      <description>第一次练习时，我们创建一个 Ceph 存储集群，它有一个 Monitor 和两个 OSD 守护进程。一旦集群达到 active + clean 状态，再扩展它：增加第三个 OSD 、增加元数据服务器和两个 Ceph Monitors。为获得最佳体验，先在管理节点上创建一个目录，用于保存 ceph-deploy 生成的配置文件和密钥对。
 如果你是用另一普通用户登录的，不要用 sudo 或在 root 身份运行 ceph-deploy ，因为它不会在远程主机上调用所需的 sudo 命令。
 mkdir my-cluster cd my-cluster   禁用 requiretty 在某些发行版（如 CentOS ）上，执行 ceph-deploy 命令时，如果你的 Ceph 节点默认设置了 requiretty 那就会遇到报错。可以这样禁用此功能：执行 sudo visudo ，找到 Defaults requiretty 选项，把它改为 Defaults:ceph !requiretty ，这样 ceph-deploy 就能用 ceph 用户登录并使用 sudo 了。
 创建集群 如果在某些地方碰到麻烦，想从头再来，可以用下列命令配置：
ceph-deploy purgedata {ceph-node} [{ceph-node}] ceph-deploy forgetkeys  用下列命令可以连ceph安装包一起清除：</description>
    </item>
    
    <item>
      <title>Ceph 集群搭建二 之 预检</title>
      <link>https://realjf.io/posts/setup-ceph-cluster-2/</link>
      <pubDate>Tue, 19 Mar 2019 14:57:09 +0800</pubDate>
      
      <guid>https://realjf.io/posts/setup-ceph-cluster-2/</guid>
      <description>集群部署如下： 预检 安装ceph部署工具 在 Red Hat （rhel6、rhel7）、CentOS （el6、el7）和 Fedora 19-20 （f19 - f20） 上执行下列步骤：
用subscription-manager注册你的目标机器，确认你的订阅，并启用安装依赖包的extras软件仓库。例如： sudo subscription-manager repos --enable=el-7-server-extras-rpms  在centos上执行以下命令 sudo yum install -y yum-utils &amp;amp;&amp;amp; sudo yum-config-manager --add-repo https://dl.fedoraproject.org/pub/epel/7/x86_64/ &amp;amp;&amp;amp; sudo yum install --nogpgcheck -y epel-release &amp;amp;&amp;amp; sudo rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 &amp;amp;&amp;amp; sudo rm /etc/yum.repos.d/dl.fedoraproject.org*  把软件包源加入软件仓库。用文本编辑器创建一个 YUM (Yellowdog Updater, Modified) 库文件，其路径为 /etc/yum.repos.d/ceph.repo sudo vim /etc/yum.repos.d/ceph.repo  把如下内容粘帖进去，用 Ceph 的最新主稳定版名字替换 {ceph-stable-release} （如 firefly，hammer, infernalis ），用你的Linux发行版名字替换 {distro} （如 el6 为 CentOS 6 、 el7 为 CentOS 7 、 rhel6 为 Red Hat 6.</description>
    </item>
    
    <item>
      <title>Ceph 集群搭建一 之 准备</title>
      <link>https://realjf.io/posts/setup-ceph-cluster-1/</link>
      <pubDate>Tue, 19 Mar 2019 14:57:05 +0800</pubDate>
      
      <guid>https://realjf.io/posts/setup-ceph-cluster-1/</guid>
      <description>1. 配置ceph yum源 vim /etc/yum.repos.d/ceph.repo [ceph-noarch] name=Cephnoarch packages baseurl=http://ceph.com/rpm-{ceph-release}/{distro}/noarch enabled=1 gpgcheck=1 type=rpm-md gpgkey=https://ceph.com/git/?p=ceph.git;a=blob_plain;f=keys/release.asc  ceph release http://docs.ceph.com/docs/master/releases/
2. 更新源并且安装hosts文件 yum update &amp;amp;&amp;amp; yum install ceph-deploy -y  3. 配置各节点hosts文件 cat /etc/hosts
192.168.1.2 node1 192.168.1.3 node2 192.168.1.4 node3  4. 配置各节点ssh无密码登录，通过ssh方式连接各节点服务器，以安装部署集群。输入ssh-keygen命令，在命令行输入以下内容： ssh-keygen  5. 拷贝key到各节点 ssh-copy-id node1 ssh-copy-id node2 ssh-copy-id node3  6. 在执行ceph-deploy的过程中会发生一些配置文件，建议创建一个目录 mkdir my-cluster cd my-cluster  7. 创建集群，部署新的monitor节点 ceph-deploy new {initial-monitor-node(s)} #例如 ceph-deploy new node1  8. 配置ceph.</description>
    </item>
    
    <item>
      <title>Golang GC 实现原理</title>
      <link>https://realjf.io/posts/how-golang-garbage-collection-works/</link>
      <pubDate>Tue, 19 Mar 2019 14:49:57 +0800</pubDate>
      
      <guid>https://realjf.io/posts/how-golang-garbage-collection-works/</guid>
      <description>当前的1.9版本的GC停顿时间已经可以做到极短. 停顿时间的减少意味着&amp;rdquo;最大响应时间&amp;rdquo;的缩短, 这也让go更适合编写网络服务程序. 这篇文章将通过分析golang的源代码来讲解go中的三色GC的实现原理.
基础概念 内存结构 go在程序启动时会分配一块虚拟内存地址是连续的内存，结构如下：
这一块内存分为了3个区域, 在X64上大小分别是512M, 16G和512G, 它们的作用如下:
arena arena区域就是我们通常说的heap, go从heap分配的内存都在这个区域中.
bitmap bitmap区域用于表示arena区域中哪些地址保存了对象, 并且对象中哪些地址包含了指针. bitmap区域中一个byte(8 bit)对应了arena区域中的四个指针大小的内存, 也就是2 bit对应一个指针大小的内存. 所以bitmap区域的大小是 512GB / 指针大小(8 byte) / 4 = 16GB.
bitmap区域中的一个byte对应arena区域的四个指针大小的内存的结构如下, 每一个指针大小的内存都会有两个bit分别表示是否应该继续扫描和是否包含指针:
bitmap中的byte和arena的对应关系从末尾开始, 也就是随着内存分配会向两边扩展:
spans spans区域用于表示arena区中的某一页(Page)属于哪个span, 什么是span将在下面介绍. spans区域中一个指针(8 byte)对应了arena区域中的一页(在go中一页=8KB). 所以spans的大小是 512GB / 页大小(8KB) * 指针大小(8 byte) = 512MB.
spans区域的一个指针对应arena区域的一页的结构如下, 和bitmap不一样的是对应关系会从开头开始:
什么时候从heap分配对象 go对自动确定哪些对象应该放在栈上，哪些对象应该放在堆上。 简单说，当一个对象的内容可能在生成该对象的函数结束后被访问，那么这个对象就会分配到堆上
在堆上分配的对象的情况包括：
 返回对象的指针 传递了对象的指针到其他函数 在闭包中是用来对象并且需要修改对象 使用new  在C语言中函数返回在栈上的对象的指针是非常危险的事情, 但在go中却是安全的, 因为这个对象会自动在堆上分配. go决定是否使用堆分配对象的过程也叫&amp;rdquo;逃逸分析&amp;rdquo;.
GC Bitmap GC在标记时需要知道哪些地方包含了指针, 例如上面提到的bitmap区域涵盖了arena区域中的指针信息. 除此之外, GC还需要知道栈空间上哪些地方包含了指针, 因为栈空间不属于arena区域, 栈空间的指针信息将会在函数信息里面.</description>
    </item>
    
    <item>
      <title>Goroutine 运行原理</title>
      <link>https://realjf.io/posts/goroutine-principle/</link>
      <pubDate>Tue, 19 Mar 2019 14:45:21 +0800</pubDate>
      
      <guid>https://realjf.io/posts/goroutine-principle/</guid>
      <description>Golang最大的特色可以说是协程(goroutine)了, 协程让本来很复杂的异步编程变得简单, 让程序员不再需要面对回调地狱, 虽然现在引入了协程的语言越来越多, 但go中的协程仍然是实现的是最彻底的.
核心概念 要理解协程的实现，需要理解三个重要概念，P、G和M。
G（goroutine） G是goroutine的简写，goroutine可以解释为受管理的轻量级线程，goroutine使用go关键字创建。
main函数是一个主线程，也是一个goroutine。
 goroutine的新建、休眠、回复、停止都受到go运行时的管理 goroutine执行异步操作时会进入休眠状态，待操作完成后在恢复，无需占用系统线程。 goroutine新建或恢复时会添加到运行队列，等待M取出并运行。  M（machine） M是machine的简写，表示系统线程
M可以运行两种代码：
 go代码，即goroutine，M运行go代码需要一个P 原生代码，例如阻塞的syscall，M运行原生代码不需要P
 M运行时，会从G可运行队列中取出一个然后运行，如果G运行完毕或者进入休眠状态，则从可运行队列中取下一个G运行，周而复始。
 有时候G需要调用一些无法避免阻塞的原生代码，这时M会释放持有的P并进入阻塞状态。其他M会取得这个P并继续运行队列中的G。
  go需要保证有足够的M可以运行G，不让CPU闲着，也需要保证M的数量不过多。
P（process） P是process的简写，代表M运行G所需要的资源。
 虽然P的数量默认等于cpu的核心数，但可以通过环境变量 GOMAXPROC 修改，在实际运行时P跟cpu核心并无任何关联。
 P也可以理解为控制go代码的并行度的机制
 如果P的数量等于1，代表当前最多只能有一个线程M执行go代码。 如果P的数量等于2，代表当前最多只能有两个线程M执行go代码。  执行原生代码的线程数不受P控制。
因为同一时间只有一个线程M可以拥有P，P中的数据都是锁自由的，读写这些数据的效率会非常的高。
数据结构 G的状态  空闲中(_Gidle)：表示G刚刚新建，仍未初始化 待运行(_Grunnable)：表示G在运行队列中，等待M取出并运行 运行中(_Grunning)：表示M正在运行这个G，这时候M会拥有一个P 系统调用中(_Gsyscall)：表示M正在运行这个G发起的系统调用，这时候M并不拥有P 等待中(_Gwaiting)：表示G在等待某些条件完成，这时候G不在运行也不在运行队列中（可能在channel的等待队列中） 已终止(_Gdead)：表示G未被使用，可能已执行完毕（并在freelist中等待下次复用） 栈复制中(_Gcopystack)：表示G正在获取一个新的栈空间并把原来的内容复制过去（用于防止GC扫描）  M的状态 M并没有像G和P一样的状态标记，但可以认为一个M有以下的状态：
 自旋中(spinning)：M正在从运行队列获取G，这时候M会拥有一个P 执行go代码中：M正在执行go代码，这时候M会拥有一个P 执行原生代码中：M正在执行原生代码或者阻塞的syscall，这时M并不拥有P 休眠中：M发现没有待运行的G时会进入休眠，并添加到空闲M链表中，这时M并不拥有P  自旋中这个状态非常重要，是否需要唤醒或者创建新的M取决于当前自旋中的M的数量。
P的状态  空闲中(_Pidle)：当M发现无待运行的G时会进入休眠，这时M拥有的P会变成空闲并加到空闲P链表中 运行中(_Prunning)：当M拥有了一个P后，这个P的状态就会变为运行中，M运行G会使用这个P中的资源。 系统调用中(_Psyscall)：当go调用原生代码，原生代码又反过来调用go代码时，使用的P会变成此状态 GC停止中(_Pgcstop)：当gc停止整个世界(STW)时，P会变为此状态。 已终止(_Pdead)：当P的数量在运行时改变，且数量减少时多余的P会变为此状态。  本地可运行队列G 在go中有多个运行队列可以保存待运行(_Grunnable)的G，他们分别是各个P中的本地运行队列和全局运行队列。</description>
    </item>
    
    <item>
      <title>什么是docker？</title>
      <link>https://realjf.io/posts/what-docker-is/</link>
      <pubDate>Tue, 19 Mar 2019 14:40:53 +0800</pubDate>
      
      <guid>https://realjf.io/posts/what-docker-is/</guid>
      <description>官方定义 Develop, Ship and Run Any Application, Anywhere Docker is a platform for developers and sysadmins to develop, ship, and run applications. Docker lets you quickly assemble applications from components and eliminates the friction that can come when shipping code. Docker lets you get your code tested and deployed into production as fast as possible.  Docker 是 PaaS 提供商 dotCloud 开源的一个基于 LXC 的高级容器引擎，源代码托管在 Github 上, 基于go语言并遵从Apache2.0协议开源。
 LXC linux container容器是一种内核虚拟化技术，可以提供轻量级的虚拟化，以便隔离进程和资源。与kvm之类最明显的区别在于启动快，资源占用小。</description>
    </item>
    
    <item>
      <title>Namespace 资源隔离</title>
      <link>https://realjf.io/posts/namespace/</link>
      <pubDate>Tue, 19 Mar 2019 14:38:54 +0800</pubDate>
      
      <guid>https://realjf.io/posts/namespace/</guid>
      <description>资源隔离 - linux有个chroot命令，可以实现资源隔离 主机隔离 网络隔离 进程间通信隔离 用户和用户组权限隔离 进程PID隔离  namespace 6项隔离    namespace 系统调用参数 隔离内容     UTS CLONE_NEWUTS 主机名与域名   IPC CLONE_NEWIPC 信号量、消息队列和共享内存   PID CLONE_NEWPID 进程编号   Network CLONE_NEWNET 网络设备、网络栈、端口等   Mount CLONE_NEWNS 挂载点（文件系统）   User CLONE_NEWUSER 用户和用户组     同一namespace下的进程可以感知彼此的变化，而对外界的进程一无所知。此处的namespace是指Linux内核3.8及以后版本。
 1. namespace api 4种操作方式 namespace的api包括clone()、setns()以及unshare()，还有/proc下的部分文件，
通过clone()在创建新进程的同时创建namespace 使用clone()来创建一个独立namespace的进程是常见方法，也是docker使用namespace最基本的方法：
int clone(int (*child_func)(void *), void *child_stack, int flags, void *arg);  查看/proc/[pid]/ns文件 用户就可以在/proc/[pid]/ns文件下看到指向不同namespace号的文件，形如[4034532445]者即为namespace号。</description>
    </item>
    
    <item>
      <title>Kubernetes集群下 Traefik安装和使用</title>
      <link>https://realjf.io/posts/k8s-plugins-traefik/</link>
      <pubDate>Tue, 19 Mar 2019 14:35:31 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-plugins-traefik/</guid>
      <description>前提：安装好kubernetes集群情况下
  run traefik and let it do the work for you!
 traefik官方地址：http://traefik.cn/
方法一：使用k8s安装 准备 # 创建目录 mkdir traefik cd traefik # 拉取traefik官方docker镜像 docker pull docker.io/traefik # docker hub地址：https://store.docker.com/images/traefik # 拉取traefik相关配置 git clone https://github.com/containous/traefik.git # 检查traefik配置 ll traefik/example/k8s/ -rw-r--r-- 1 root root 140 Sep 11 16:53 cheese-default-ingress.yaml -rw-r--r-- 1 root root 1805 Sep 11 16:53 cheese-deployments.yaml -rw-r--r-- 1 root root 519 Sep 11 16:53 cheese-ingress.yaml -rw-r--r-- 1 root root 509 Sep 11 16:53 cheese-services.</description>
    </item>
    
    <item>
      <title>kubernetes 核心原理之 网络模型</title>
      <link>https://realjf.io/posts/k8s-core-principle-network-model/</link>
      <pubDate>Tue, 19 Mar 2019 14:30:13 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-core-principle-network-model/</guid>
      <description>主要解决以下问题： - 容器与容器之间的直接通信 - pod与pod之间的通信 - pod到service之间的通信 - 集群外部与集群内部组件之间的通信
容器与容器之间的通信 同一个Pod内的容器共享同一个linux协议栈，可以用localhost地址访问彼此的端口 kubernetes利用docker的网桥与容器内的映射eth0设备进行通信
pod之间的通信 每个pod都拥有一个真实的全局ip地址 - 同一个node内的不同pod之间 可以直接采用对方的pod的ip地址通信（因为他们都在同一个docker0网桥上，属于同一地址段） - 不同node上的pod之间</description>
    </item>
    
    <item>
      <title>kubernetes 核心原理之 集群安全机制</title>
      <link>https://realjf.io/posts/k8s-core-principle-security/</link>
      <pubDate>Tue, 19 Mar 2019 14:29:44 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-core-principle-security/</guid>
      <description> 安全性考虑目标  保证容器与其所在的宿主机的隔离 限制容器给基础设施及其他容器带来消极影响的能力 最小权限原则 明确组件间边界的划分 划分普通用户和管理员的角色 在必要时允许将管理员权限赋给普通用户 允许拥有secret数据（Keys、Certs、Passwords）的应用在集群中运行  1. API Server认证管理（Authentication） 集群安全的关键就在于如何识别并认证客户端身份，以及随后访问权限的授权这两个关键问题
k8s提供3种级别的客户端身份认证方式： - 最严格的https证书认证：基于ca根证书签名的双向数字证书认证 - http token认证：通过一个token来识别合法用户
 http token用一个很长的特殊编码方式并且难以被模仿的字符串——token来表明客户端身份，每个token对应一个用户名，存储在api server能访问的一个文件中，当客户端发起api调用请求时，需要在http header里放入token，这样一来，api server就能识别合法用户和非法用户了。
  http base认证：通过用户名+密码的方式   http base是指把“用户名+冒号+密码”用base64算法进行编码后的字符串放在http request中的header authorization域里发送到服务端，服务端接受后进行解码，获取用户名及密码，然后进行用户身份鉴权过程
 2. API Server授权管理（Authorization） 通过授权策略来决定一个api调用是否合法。对合法用户进行授权并且随后在用户访问时进行鉴权，是权限与安全系统的重要一环。
目前支持的授权策略： - AlwaysDeny：表示拒绝所有的请求，一般用于测试 - AlwaysAllow：允许接受所有请求，如果集群不需要授权，则可以采用这个策略，这也是默认配置 - ABAC：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制。 - Webhook：通过调用外部rest服务对用户进行授权 - RBAC：基于角色的访问控制
ABAC授权模式 Webhook授权模式 RBAC授权模式详解 基于角色的访问控制： - 对集群中的资源和非资源权限均有完整的覆盖 - 整个RBAC完全由几个api对象完成，同其他api对象一样，可以用kubectl或api进行操作 - 可以在运行时进行调整，无需重新启动api server
 要使用RBAC授权模式，需要在api server的启动参数中加上 &amp;ndash;authorization-mode=RBAC
 3. Admission Control（准入控制） </description>
    </item>
    
    <item>
      <title>kubernetes 核心原理之 Kube-Proxy</title>
      <link>https://realjf.io/posts/k8s-core-principle-kube-proxy/</link>
      <pubDate>Tue, 19 Mar 2019 14:26:43 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-core-principle-kube-proxy/</guid>
      <description>service是一个抽象的概念，类似一个反向代理，将请求转发到后端的pod上。真正实现service作用的是kube-proxy服务进程。
在每个node上都会运行一个kube-proxy的服务进程，这个进程可以看做service的透明代理兼负载均衡器，其核心功能是将到某个service的访问请求转发到后端的多个pod实例上。
kube-proxy会在本地node上简历一个socketserver来负责接收请求，然后均匀发送到后端某个pod端口上，这个过程默认采用round robin负载均衡算法。
k8s也提供了通过修改service的service.spec.sessionAffinity参数的值来实现会话保持特性的定向转发，如果设置的值为“clientIp”，则将来自同一个clientip的请求都转发到同一个后端pod上。
 service的clusterIP与nodeport等概念是kube-proxy服务通过iptables的NAT转换实现的，kube-proxy在运行过程中动态创建与service相关的iptables规则
 访问service的请求，不论是用cluster ip+target port的方式，还是用节点机ip+node port的方式，都被节点机的iptables规则重定向到kube-proxy监听的service服务代理端口。
 kube-proxy的负载均衡器只支持round robin算法。同时在此基础上还支持session保持。
 kube-proxy内部创建了一个负载均衡器——loadbalancer，loadbalancer上保存了service到对应的后端endpoint列表的动态转发路由表，而具体的路由选择取决于round robin负载均衡算法及service的session会话保持（SessionAffinity）这两个特性
kube-porxy针对变化的service列表，处理流程  如果service没有设置集群ip（ClusterIP），则不做处理，否则，获取该service的所有端口定义列表（spec.ports域） 逐个读取服务端口定义列表中的端口信息，根据端口名称，service名称和namespace判断本地是否已经存在对应的服务代理对象，如不存在则新建，如存在且service端口被修改过，则先删除iptables中和srevice端口相关的规则，关闭服务代理对象，然后走新建流程。 更新负载均衡器组件中对应service的转发地址列表，对于新建的service，确定转发时的会话保持策略。 对于已经删除的service则进行清理   针对Endpoint的变化，kube-proxy会自动更新负载均衡器中对应service的转发地址列表。
 针对iptables所做的一些细节操作  KUBE-PORTALS-CONTAINER：从容器中通过service cluster ip和端口号访问service的请求。（容器） KUBE-PORTALS-HOST：从主机中通过service cluster ip和端口号访问service的请求（主机） KUBE-NODEPORT-CONTAINER：从容器中通过service的nodeport端口号访问service的请求。（容器） KUBE-NODEPORT-HOST：从主机中通过service的nodeport端口号访问service请求（主机）  此外，kube-proxy在iptables中为每个service创建由cluster ip+service端口号到kube-proxy所在主机ip+service代理服务所监听的端口的转发规则。
service类型为NodePort kube-proxy在iptables中除了添加上面提及的规则，还会为每个service创建由nodeport端口到kube-proxy所在主机ip+service代理服务所监听的端口的转发规则。</description>
    </item>
    
    <item>
      <title>kubernetes 核心原理之 Kubelet</title>
      <link>https://realjf.io/posts/k8s-core-principle-kubelet/</link>
      <pubDate>Tue, 19 Mar 2019 14:26:28 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-core-principle-kubelet/</guid>
      <description>在每个Node节点上都会启动一个kubelet服务进程，该进程负责处理master节点下发到本节点的任务，管理Pod和pod中的容器。
每个kubelet进程会在api server上注册节点自身信息，定期向master节点汇报节点资源的使用情况，并通过cAdvisor监控容器和节点资源。
节点管理 节点通过设置kubelet的启动参数“&amp;ndash;register-node”，来决定是否向api server注册自己，如果该参数为true，则会向api server注册自己。
其他参数包括： - &amp;ndash;api-servers：api server的位置 - &amp;ndash;kubeconfig：kubeconfig文件，用于访问api server的安全配置文件 - &amp;ndash;cloud-provider：云服务商地址，仅用于公有云环境
通过kubelet的启动参数“&amp;ndash;node-status-update-frequency”设置kubelet每隔多长时间想api server报告节点状态，默认是10s。
Pod管理 kubelet通过以下几种方式获取自身node上所要运行的pod清单： - 文件：同过启动参数“&amp;ndash;config”指定的配置文件目录下的文件（默认/etc/kubernetes/manifests/） - http断电：通过“&amp;ndash;manifest-url”参数设置 - api server：通过api server监听etcd目录，同步pod列表
kubelet去读监听到的信息，如果是创建和修改pod任务，则  为该pod创建一个数据目录 从api server读取该pod清单 为该pod挂载外部卷 下载pod用到的secret 检查已经运行在节点中的pod，如果该pod没有容器或pause容器（kubernetes/pause镜像创建的容器）没有启动，则先停止pod里所有容器的进程。如果在pod中有需要删除的容器，则删除这些容器。 用&amp;rdquo;kubernetes/pause&amp;rdquo;镜像为每个pod创建一个容器，该pause容器用于接管pod中所有其他容器的网络。每创建一个新的pod，kubelet都会先创建一个pause容器，然后创建其他容器。 为pod中的每个容器做如下处理： 为容器计算一个hash值，然后用容器的名字去查询对应docker容器的hash值。若找到容器，且两者的hash值不同，则停止docker中容器的进程，并停止与之关联的pause容器的进程，若两者相同，则不做任何处理。 如果容器被终止了，且容器没有指定的restartPolicy（重启策略），则不做任何处理。 调用docker client下载容器镜像，调用docker client运行容器。  容器健康检查 检查容器健康状态的两种探针 - LivenessProbe探针：判断容器是否健康，如果不健康，则删除Pod，根据其重启策略做相应处理。 - ReadinessProbe探针：判断容器是否完成启动，且准备接受请求。如果失败，pod的状态将被修改，Endpoint Controller将从Service的Endpoint中删除包含该容器所在pod的ip地址的endpoint条目。
LivenessProbe实现方式  ExecAction：在容器内部执行一个命令，如果该命令的退出状态码为0，则表明容器健康 TCPSocketAction：通过容器的ip地址和端口号执行TCP检查，如果端口能被访问，则表明容器健康 HTTPGetAction：通过容器的ip地址和端口号即路径调用http get方法，如果响应的状态码大于等于200且小于400，则认为容器状态健康  LivenessProbe探针包含在pod定义的spec.containers.{某个容器}中
# 容器命令检查 livenessProbe: exec: command: - cat - /tmp/health initialDelaySeconds: 15 timeoutSeconds: 1  # http检查 livenessProbe: httpGet: path: /healthz port: 8080 initialDelaySeconds: 15 timeoutSeconds: 1  cAdvisor资源监控 监控级别包括：容器、pod、service和整个集群</description>
    </item>
    
    <item>
      <title>kubernetes 核心原理之 Sheduler</title>
      <link>https://realjf.io/posts/k8s-core-principle-sheduler/</link>
      <pubDate>Tue, 19 Mar 2019 14:26:15 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-core-principle-sheduler/</guid>
      <description>作用是将待调度的pod按照特定的调度算法和调度策略绑定到集群中的某个合适的Node上，并将绑定信息写入etcd中。
目标节点上的kubelet通过api server监听到schduler产生的pod绑定事件，然后获取对应的pod清单，下载image镜像，并启动容器。
Scheduler默认调度流程分为以下两步  预调度过程，即遍历所有目标node，筛选出符合要求的候选节点 确定最优节点，在上一步基础上，采用优选策略计算出每个候选节点的积分，积分高者胜出。  Scheduler调度流程是通过插件方式加载的“调度算法提供者”（AlgorithmProvider）具体实现的。一个AlgorithmProvider其实是一组预选策略与一组优先选择策略的结构体。
Scheduler中可选的预选策略  NoDiskConflict PodFitsResources PodSelectorMatches PodFitsHost CheckNodeLabelPresence CheckServiceAffinity PodFitsPorts  Scheduler优选策略  LeastRequestedPriority（资源消耗最小） CalculateNodeLabelPriority BalancedResourceAllocation（各项资源使用率最均衡的节点）  每个节点通过优选策略算出一个得分，最终选出分值最大的节点作为优选的结果。</description>
    </item>
    
    <item>
      <title>kubernetes 核心原理之 Controller Manager</title>
      <link>https://realjf.io/posts/k8s-core-principle-controller-manager/</link>
      <pubDate>Tue, 19 Mar 2019 14:26:00 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-core-principle-controller-manager/</guid>
      <description>controller manager作为集群内部的管理控制中心，负责集群内的Node、pod副本、服务端（Endpoint）、命名空间（Namespace）、服务账号（ServiceAccount）、资源定额（ResourceQuota）等的管理。
controller manager组件  replication controller node controller resourceQuota controller namespace controller serviceAccount controller token controller service controller endpoint controller  1. Replication Controller（副本控制器） 核心作用是确保在任何时候集群中一个RC所关联的pod副本数量保持预设值。 &amp;gt; 只有当pod的重启策略是always时（RestartPolicy=Always），Replication Controller才会管理该Pod的操作（创建、销毁、重启等）。
RC中的Pod模板就像一个模具，一旦pod被创建完毕，它们之间就没有关系了。
此外，可以通过修改Pod的标签来实现脱离RC的管控。该方法可以用于将pod从集群中迁移、数据修复等调试。
Replication Controller职责  确保当前集群中有且仅有N个pod实例，N是RC中定义的pod副本数量 通过调整RC的spec.replicas属性值来实现系统扩容或者缩容 通过改变RC中的pod模板（主要是镜像版本）来实现系统的滚动升级  Replication Controller典型使用场景  重新调度（Rescheduling） 弹性伸缩（Scaling） 滚动更新（Rolling Updates）  2. Node Controller Node Controller通过API Server实时获取Node的相关信息：节点健康状况、节点资源、节点名称、节点地址信息、操作系统版本、Docker版本、kubelet版本等。
node controller节点信息更新机制 比较节点信息和node controller的nodeStatusMap中保存的节点信息 - 如果没有收到kubelet发送的节点信息、第一次收到节点kubelet发送的节点信息，或处理过程中节点状态变成非健康状态，则在nodeStatusMap中保存改节点的状态信息，并用node controller所在节点的系统时间作为探测时间和节点状态变化时间。 - 如果指定时间内收到新的节点信息，且节点状态发生变化，则在nodeStatusMap保存改节点的状态信息，并用node controller所在节点的系统时间作为探测时间，用上次节点信息中的节点状态变化时间作为该节点的状态变化时间 - 如果某一段时间内没有收到该节点状态信息，则设置节点状态为未知，并通过api server保存节点状态
3. ResourceQuota Controller（资源配额管理） 资源配额管理确保了指定的资源对象在任何时候都不会超量占用系统物理资源，避免由于某些业务进程的设计或实现的缺陷导致整个系统运行紊乱甚至意外宕机</description>
    </item>
    
    <item>
      <title>kubernetes 核心原理之 Apiserver</title>
      <link>https://realjf.io/posts/k8s-core-principle-apiserver/</link>
      <pubDate>Tue, 19 Mar 2019 14:25:43 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-core-principle-apiserver/</guid>
      <description>API Server的核心功能提供了kubernetes各类资源对象（如pod、rc、service等）的增删改查以及watch等http rest接口，是集群内各个功能模块之间数据交互和通信的中心枢纽，是整个系统的数据总线和数据中心。
 是集群管理的api入口 是资源配额控制的入口 提供了完备的集群安全机制  </description>
    </item>
    
    <item>
      <title>kubernetes 基本概念和术语</title>
      <link>https://realjf.io/posts/k8s-basic-concepts-and-terminology/</link>
      <pubDate>Tue, 19 Mar 2019 14:21:00 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-basic-concepts-and-terminology/</guid>
      <description>kubernetes中大部分概念，如node、pod、replication、controller、service等都可以看作是一种“资源对象”，几乎所有的资源对象都可以通过kubernetes提供的kubectl工具执行增、删、改、查等操作并保存在etcd中持久化存储。
k8s里所有资源对象都可以采用yaml或者json格式的文件来定义或描述
 1. Master（主节点、集群控制节点）  每个kubernets集群里需要有一个master节点来负责整个集群管理和控制 所有控制命令都发给它 占据一个独立的服务器 如果宕机或不可用，整个集群内容器应用的管理都将失效  master节点运行一组以下关键进程  kubernetes api server(kube-apiserver)：提供http rest接口，是k8s所有资源增删改查等操作的唯一入口，也是集群控制入口进程 kubernetes controller manager(kube-controller-manager)：k8s所有资源对象的自动化控制中心 kubernetes scheduler(kube-scheduler)：负责资源调度（pod调度）的进程 etcd服务：保存k8s所有资源对象的数据  相关命令  kubectl get nodes：查看集群有多少个node kubectl describe node ：查看某个node详细信息  2. Node（较早版本也叫minion）  节点既可以是物理机，也可以是私有云或者公有云中的一个虚拟机，通常在一个节点上运行几百个pod kubernetes集群中的工作负载节点，当某个node宕机，其上的工作负载会被master自动转移到其他节点上  每个node节点运行一组以下关键进程  kubelet：负责pod对应的容器的创建、启停等，同时与master节点密切协作，实现集群管理的基本功能 kube-proxy：实现kubernetes service的通信与负载均衡机制 docker engine：docker引擎，负责本机的容器创建和管理工作  3. Pod 是k8s最重要也是最基本概念 - 每个Pod都有一个特殊的被称为“根容器”的Pause容器，Pause容器对应的镜像属于k8s平台的一部分（gcr.io/google_containers/pause-amd64） - pod对象将每个服务进程包装到相应的pod中，使其成为pod中运行的一个容器 - 根容器不易死亡 - pod里的多个业务容器共享pause容器的ip，共享pause容器挂接的volume（解决Pod直接拿文件共享问题） - k8s为每个pod都分配唯一的ip地址，称之为pod ip，一个Pod里的多个容器共享pod ip地址 - 集群内任意两个pod之间的tcp/ip可以直接通信，通常采用虚拟二层网络技术实现，如：flannel、open vSwitch等。
pod的两种类型  普通的pod（存放在k8s的etcd中） 静态pod（存放在某个具体的node上的一个具体文件中，且只在此Node上启动运行）   默认情况下：当pod里的某个容器停止时，k8s会自动检测到这个问题并重新启动这个pod（重启pod里的所有容器），如果pod所在node宕机，则会将这个Node上的所有pod重新调度到其他节点上。</description>
    </item>
    
    <item>
      <title>Kubernetes集群搭建三 之 docker镜像配置</title>
      <link>https://realjf.io/posts/k8s-cluster-set-up-3/</link>
      <pubDate>Tue, 19 Mar 2019 14:13:57 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-cluster-set-up-3/</guid>
      <description> 1. 使用docker提供的registry镜像创建一个私有镜像仓库 具体可以参考 https://docs.docker.com/registry/deploying
运行以下命令，启动一个本地镜像仓库 docker 1.6以上版本可以直接运行以下命令
docker run -d -p 5000:5000 --restart=always --name registry registry:2  停止本地仓库
docker container stop registry &amp;amp;&amp;amp; docker container rm -v registry  镜像仓库操作
docker pull ubuntu docker image tag ubuntu localhost:5000/myfirstimage docker push localhost:5000/myfirstimage docker pull localhost:5000/myfirstimage  2. kubelet配置 k8s中docker以pod启动，在kubelet创建pod时，还通过启动一个名为gcr.io/google_containers/pause的镜像来实现pod的概念。
需要从gcr.io中将该镜像下载，导出文件，再push到私有docker registry中。之后，可以给每台node的kubelet服务加上启动参数&amp;ndash;pod-infra-container-image，指定为私有仓库中pause镜像的地址。
--pod-infra-container-image=gcr.io/google_containers/pause-amd64:3.0  如果镜像无法下载，可以从docker hub上进行下载：
docker pull kubeguide/pause-amd64:3.0  然后在kubelet启动参数加上该配置，重启kubelet服务即可
systemctl restart kubelet  </description>
    </item>
    
    <item>
      <title>Kubernetes集群搭建二 之 k8s集群</title>
      <link>https://realjf.io/posts/k8s-cluster-set-up-2/</link>
      <pubDate>Tue, 19 Mar 2019 14:13:53 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-cluster-set-up-2/</guid>
      <description>方式1：基于CA签名的双向数字证书认证方式 过程如下： - 为kube-apiserver生成一个数字证书，并用CA证书进行签名 - 为kube-apiserver进程配置证书相关的启动参数，包括CA证书（用于验证客户端证书的签名真伪）、自己的经过CA签名后的证书及私钥 - 为每个访问K8S API server的客户端进程生成自己的数字证书，也都用CA证书进行签名，在相关程序的启动参数里增加CA证书、自己的证书等相关参数
1). 设置kube-apiserver的CA证书相关的文件和启动参数 使用openssl工具在master服务器上创建CA证书和私钥相关的文件：
openssl genrsa -out ca.key 2048 openssl req -x509 -new -nodes -key ca.key -subj &amp;quot;/CN=k8s-master&amp;quot; -days 5000 -out ca.crt openssl genrsa -out server.key 2048  注：生成ca.crt时，-subj参数中“/CN”的值为Master主机名
 509是一种通用的证书格式
 准备master_ssl.cnf文件，用于x509 v3版本的证书，示例如下：
[ req ] req_extensions = v3_req distinguished_name = req_distinguished_name [ req_distinguished_name ] [ v3_req ] basicConstraints = CA:FALSE keyUsage = nonRepudiation, digitalSignature, keyEncipherment subjectAltName = @alt_names [alt_names] DNS.</description>
    </item>
    
    <item>
      <title>Kubernetes集群搭建一 之 etcd集群</title>
      <link>https://realjf.io/posts/k8s-cluster-set-up-1/</link>
      <pubDate>Tue, 19 Mar 2019 14:13:46 +0800</pubDate>
      
      <guid>https://realjf.io/posts/k8s-cluster-set-up-1/</guid>
      <description>系统要求    软硬件 最低配置 推荐配置     cpu和内存 master:至少2core和4GB内存 Node：至少4core和16GB Master:4core和16GB Node: 应根据需要运行的容器数量进行配置   linux操作系统 基于x86_64架构的各种linux发行版本 Red Hat Linux 7 CentOS 7   Docker 1.9版本以上 1.12版本   etcd 2.0版本及以上 3.0版本    本次实验选用的是centos7 1804版本
 需要注意，kubernetes的master和node节点之间会有大量的网络通信，安全的做法是在防火墙上配置各组件需要相互通信的端口号。在一个安全的内网环境中，可以关闭防火墙服务
#关闭防火墙 systemctl disable firewalld systemctl stop firewalld # 禁用SELinux setenforce 0 # 也可以修改/etc/sysconfig/selinux，将SELINUX=enforcing修改成SELINUX=disabled   这里将搭建一个master节点和一个node节点的k8s集群  由于 raft 算法的特性，集群的节点数必须是奇数
    - ip etcd节点名称     master节点 192.</description>
    </item>
    
    <item>
      <title>How to Set Up Blog Using Hugo</title>
      <link>https://realjf.io/posts/how-to-set-up-blog-using-hugo/</link>
      <pubDate>Tue, 19 Mar 2019 09:43:09 +0800</pubDate>
      
      <guid>https://realjf.io/posts/how-to-set-up-blog-using-hugo/</guid>
      <description>github pages有两种方式：  一种是{USERNAME}.github.io/ 另一种是{USERNAME}.github.io/{PROJECT}  我们这里使用第二种方法创建
前期准备  有一个github账号  创建一个公开的repo 例如：blog
开通github pages 找到新创建的repo中的settings，往下找到github pages， 如果首次开通，则需要授权一下，授权后，github pages下的source可以选择对应的发布分支。默认为master分支。
注意 如果一切正常，github pages选项下有个蓝色提示，显示的是您的博客地址，可以先访问看看是否正常。我这里是：https://realjf.github.io/blog/
配置好后，开始使用hugo构建博客 首先，clone下刚才创建的repo
git clone git@github.com:{USERNAME}/blog  安装hugo，确保repo目录下可以使用hugo命令 请参考官网https://gohugo.io/
# 检查安装是否成功 hugo version  利用hugo构建博客目录结构 cd blog &amp;amp;&amp;amp; hugo new site . --force  这里使用了&amp;ndash;force是因为当前目录已存在，只是需要初始化而已
添加自己需要的主题 cd blog git submodule add https://github.com/realjf/hugo-theme-m10c.git themes/m10c  上述的m10c可以换成你想要的主题名字即可
更多的主题请参考：https://themes.gohugo.io/
# 修改根目录下的 .toml文件 theme = &amp;quot;{THEME}&amp;quot; baseUrl = &amp;quot;https://realjf.github.io/blog/&amp;quot;  {THEME}请修改为你的主题名即可
本地测试博客 hugo server -t {THEME}  到这里，基本的博客搭建完成，先保存到github git add -A &amp;amp;&amp;amp; git commit -m &amp;quot;Initializing&amp;quot; git push origin master  本地测试成功后，我们利用gh-pages分支作为新的发布分支 gh-pages分支保存的是hugo生成的html静态文件</description>
    </item>
    
  </channel>
</rss>