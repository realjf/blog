<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Realjf&#39;s blog</title>
    <link>https://realjf.io/series/</link>
    <description>Recent content on Realjf&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Apr 2020 15:37:44 +0800</lastBuildDate>
    
	<atom:link href="https://realjf.io/series/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kafka Go Client</title>
      <link>https://realjf.io/kafka/go-client/</link>
      <pubDate>Wed, 29 Apr 2020 15:37:44 +0800</pubDate>
      
      <guid>https://realjf.io/kafka/go-client/</guid>
      <description>本次实验假定您已经安装好了kafka（单机或者集群），且配置好了远程访问地址，详见配置文件config/server.properties
首先需要下载安装librdkafka wget https://github.com/edenhill/librdkafka/archive/v1.4.0.tar.gz tar zxvf librdkafka-1.4.0.tar.gz cd librdkafka-1.4.0 ./configure make make install  安装完毕，可以开始写go client
在go项目下安装客户端 go get -u gopkg.in/confluentinc/confluent-kafka-go.v1/kafka  consumer示例 import ( &amp;quot;fmt&amp;quot; &amp;quot;gopkg.in/confluentinc/confluent-kafka-go.v1/kafka&amp;quot; ) func main() { c, err := kafka.NewConsumer(&amp;amp;kafka.ConfigMap{ &amp;quot;bootstrap.servers&amp;quot;: &amp;quot;192.168.37.133:9092&amp;quot;, &amp;quot;group.id&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;auto.offset.reset&amp;quot;: &amp;quot;earliest&amp;quot;, }) if err != nil { panic(err) } c.SubscribeTopics([]string{&amp;quot;test&amp;quot;, &amp;quot;^aRegex.*[Tt]est&amp;quot;}, nil) for { msg, err := c.ReadMessage(-1) if err == nil { fmt.Printf(&amp;quot;Message on %s: %s\n&amp;quot;, msg.TopicPartition, string(msg.Value)) } else { fmt.</description>
    </item>
    
    <item>
      <title>Kafka快速开始</title>
      <link>https://realjf.io/kafka/set-up/</link>
      <pubDate>Tue, 28 Apr 2020 17:13:30 +0800</pubDate>
      
      <guid>https://realjf.io/kafka/set-up/</guid>
      <description>下载地址：https://www.apache.org/dyn/closer.cgi?path=/kafka/2.5.0/kafka_2.12-2.5.0.tgz
下载 wget https://www.apache.org/dyn/closer.cgi?path=/kafka/2.5.0/kafka_2.12-2.5.0.tgz tar zxvf kafka_2.12-2.5.0.tgz cd kafka_2.12-2.5.0  开启服务器 # 开启zookeeper bin/zookeeper-server-start.sh config/zookeeper.properties # 开启kafka bin/kafka-server-start.sh config/server.properties  创建一个topic bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test  上面创建了一个叫test的topic
我们现在可以运行list topic命令查看刚才创建的topic
bin/kafka-topics.sh --list --bootstrap-server localhost:9092  发送消息 bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test 这是一条信息 这是另外一条消息  开启一个消费者consumer 接收消息
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 这是一条信息 这是另一条信息  安装一个多broker集群，即kafka集群 # 首先为每个broker创建一个配置 cp config/server.properties config/server-1.properties cp config/server.properties config/server-2.properties # 然后为每个配置文件设置 config/server-1.</description>
    </item>
    
    <item>
      <title>storm安装</title>
      <link>https://realjf.io/storm/set-up/</link>
      <pubDate>Tue, 28 Apr 2020 15:31:08 +0800</pubDate>
      
      <guid>https://realjf.io/storm/set-up/</guid>
      <description>一、需要安装的工具  python、zookeeper、storm（如果是storm0.9以前的版本，则需要安装zeromq、jzmq）  二、开始安装 第一步：安装Python2.7.2 wget http://www.python.org/ftp/python/2.7.2/Python-2.7.2.tgz tar zxvf Python-2.7.2.tgz cd Python-2.7.2 ./configure --prefix=/usr/local/python2.7 make make install vi /etc/ld.so.conf 追加/usr/local/lib/ sudo ldconfig  第二步：安装zookeeper wget http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz tar -zxvf zookeeper-3.3.5.tar.gz cp -R zookeeper-3.3.5 /usr/local/zookeeper vim /etc/profile (设置ZOOKEEPER_HOME和ZOOKEEPER_HOME/bin) export ZOOKEEPER_HOME=&amp;quot;/usr/local/zookeeper&amp;quot; export PATH=$PATH:$ZOOKEEPER_HOME/bin cp /usr/local/zookeeper/conf/zoo_sample.cfg /usr/local/zookeeper/conf/zoo.cfg (用zoo_sample.cfg制作$ZOOKEEPER_HOME/conf/zoo.cfg) mkdir /tmp/zookeeper mkdir /var/log/zookeeper  zookeeper的单机安装已经完成了。
第三步：安装zeromq wget http://download.zeromq.org/zeromq-4.1.0-rc1.tar.gz tar zxf zeromq-2.2.0.tar.gz cd zeromq-2.2.0 ./configure //因为jzmq的安装时依赖于zeromq的，所以./configure的时候不能指定zeromq的安装目录，如果指定了，则jzmq的安装会出错（即不能指定--prefix=...）。 make make install sudo ldconfig (更新LD_LIBRARY_PATH)  zeromq安装完成。 注意：如有有依赖报错，需要安装： jzmq dependencies 依赖包 sudo yum install uuid* sudo yum install libtool sudo yum install libuuid sudo yum install libuuid-devel</description>
    </item>
    
    <item>
      <title>docker error creating overlay mount to invalid argument 解决方法</title>
      <link>https://realjf.io/docker/docker-create-layer-error/</link>
      <pubDate>Tue, 28 Apr 2020 15:29:31 +0800</pubDate>
      
      <guid>https://realjf.io/docker/docker-create-layer-error/</guid>
      <description> 原因 由于docker的不同版本在centos上产生的mount问题，1.2.x没有出现这个问题，当使用yum install时，安装的最新版本(1.3.x)，会导致overlay2的错误。
解决方法 修改docker启动参数storage-driver
vim /etc/sysconfig/docker-storage # 将文件中的DOCKER_STORAGE_OPTIONS=&amp;quot;-s overlay2&amp;quot;修改为DOCKER_STORAGE_OPTIONS=&amp;quot;-s overlay&amp;quot;  然后重新加载daemon
systemctl daemon-reload  重启docker
systemctl restart docker  </description>
    </item>
    
    <item>
      <title>Dockerfile实现修改容器hosts文件内容</title>
      <link>https://realjf.io/docker/docker-modify-hosts/</link>
      <pubDate>Tue, 28 Apr 2020 15:26:44 +0800</pubDate>
      
      <guid>https://realjf.io/docker/docker-modify-hosts/</guid>
      <description>场景 今天突然遇到一个问题，需要向容器的/etc/hosts文件追加自定义的内容，直接的做法的是，进入容器，直接修改/etc/hosts文件，但是，这种做法在容器重新启动后就失效，而且容器启动实例一多，就会带来繁琐的手动操作。
为了能让同一个镜像启动的容器每次启动的时候都能自动更新成我们需要的/etc/hosts文件，现有以下几种方法：
1. 在docker run的时候增加参数&amp;ndash;add-host进行添加（官方给的方法） # 添加单个hosts docker run -it nginx --add-host=localhost:127.0.0.1 # 添加多个hosts docker run -it nginx --add-host=localhost:127.0.0.1 --add-host=example.com:127.0.0.1 # 一个ip对应多个hosts docker run -it nginx --add-host=&amp;quot;localhost example.com&amp;quot;:127.0.0.1  2. 在dockerfile中，使用脚本作为镜像入口，再利用脚本运行修改hosts文件的命令以及真正的应用程序入口 文件说明 - myhosts：需要追加到/etc/hosts中的内容 - run.sh：容器的入口执行脚本 - dockerfile：构建镜像的dockerfile文件
dockerfile示例如下：
FROM centos:6 MAINTAINER chenjiefeng COPY run.sh ~/run.sh COPY myhosts ~/myhosts RUN chmod +x ~/run.sh ENTRYPOINT /bin/sh -c ~/run.sh  run.sh示例如下：
#!/bin/bash # 向hosts文件追加内容 cat ~/myhosts &amp;gt;&amp;gt; /etc/hosts # 其他命令 # 保留终端，防止容器自动退出 /bin/bash  myhosts示例如下：</description>
    </item>
    
    <item>
      <title>Docker容器和宿主机时间不一致问题解决</title>
      <link>https://realjf.io/docker/docker-time-sync/</link>
      <pubDate>Tue, 28 Apr 2020 15:26:29 +0800</pubDate>
      
      <guid>https://realjf.io/docker/docker-time-sync/</guid>
      <description> 1. 在Dockerfile中解决（永久性，推荐） 在Dockerfile文件中加上如下：
ENV TZ=Asia/Shanghai # 添加你需要的时区 RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;amp;&amp;amp; echo $TZ &amp;gt; /etc/timezone  2. 临时性设置 在container的shell交互里输入
TZ=Asia/Shanghai ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;amp;&amp;amp; echo $TZ &amp;gt; /etc/timezone ## 检查时间 date  </description>
    </item>
    
    <item>
      <title>golang Slice类型扩容机制</title>
      <link>https://realjf.io/golang/slice/</link>
      <pubDate>Tue, 28 Apr 2020 15:10:49 +0800</pubDate>
      
      <guid>https://realjf.io/golang/slice/</guid>
      <description> 一个slice是一个数组某个部分的引用。在内存中，他是一个包含3个域的结构体：指向slice中第一个元素的指针，slice的长度，以及slice的容量。长度是下标操作的上界，容量是分割操作的上界
数组的slice并不会实际复制一份数据，他只是创建一个新的数据结构，包含了另外的一个指针，一个长度和一个容量数据。如同分割字符串，分割数组也不涉及复制操作：它只是新建了一个结构来放置一个不同的指针，长度和容量。
由于slice是不同于指针的多字长结构，分割操作并不需要分配内存，甚至没有通常被保存在堆中的slice头部，这种表示方法使slice操作和在c中传递指针、长度对一样廉价。移除间接引用及分配操作可以让slice足够廉价，以避免传递显式索引。
slice的扩容 在对slice进行append等操作时，可能会造成slice的自动扩容。其扩容时的大小增长规则是： - 如果新的大小是当前大小2倍以上，则大小增长为新大小 - 否则循环以下操作：如果当前大小小于1024，按每次2倍增长，否则每次按当前大小1/4增长。直到增长的大小超过或等于新大小。
make和new 有两个数据结构创建函数：new和make，基本区别是new（T）返回一个*T，返回的这个指针可以被隐式地消除索引，而make(T, args)返回一个 普通的T，通常情况下，T内部有一些隐式的指针，一句话，new返回一个指向已清零内存的指针，而make返回一个复杂的结构。
slice与unsafe.Pointer相互转换 有时候可能需要使用一些比较tricky的技巧，比如利用make弄一块内存自己管理，或者用cgo之类的方式得到的内存，转换为Go类型使用。 从slice中得到一块内存地址是很容易的：
s := make([]byte, 200) ptr := unsafe.Pointer(&amp;amp;s[0])  从一个内存指针构造出go语言的slice结构相对麻烦些，比如：
var ptr unsafe.Pointer s := ((*[1&amp;lt;&amp;lt;10]byte)(ptr))[:200]  先将ptr强制类型转换为另外一种指针，一个指向[1&amp;lt;&amp;lt;10]byte数组的指针，这里数组大小其实是假的，然后用slice操作取出这个数组的前200个，于是s就是一个200个元素的slice
或者：
var ptr unsafe.Pointer var s1 = struct { addr uintptr len int cap int }{ptr, length, length} s := *(*[]byte)(unsafe.Pointer(&amp;amp;s1))  或者使用reflect.SliceHeader的方式构造slice，比较推荐这种：
var o []byte sliceHeader := (*reflect.SliceHeader)((unsafe.Pointer(&amp;amp;o))) sliceHeader.Cap = length sliceHeader.Len = length sliceHeader.Data = uintptr(ptr)  </description>
    </item>
    
    <item>
      <title>排序算法之选择排序 Select Sort</title>
      <link>https://realjf.io/algorithm/sort/select-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:03:27 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/select-sort/</guid>
      <description>选择排序算法是每次循环遍历出未排除中最小值的位置，然后与将其与未排序部分第一个元素进行交换
#include &amp;lt;stdio.h&amp;gt; void swap(int* a, int* b) { if(*a &amp;gt; *b){ *a = *a + *b; *b = *a - *b; *a = *a - *b; } } int main(){ int a[10],i,j; for(i=0;i&amp;lt;10;i++){ scanf(&amp;quot;%d&amp;quot;, &amp;amp;a[i]); } for(i=0;i&amp;lt;9;i++){ int min = i; for(j=i+1;j&amp;lt;10;j++){ if(a[j] &amp;lt; a[min]){ min = j; } } swap(&amp;amp;a[min], &amp;amp;a[i]); } return 0; }  </description>
    </item>
    
    <item>
      <title>排序算法之归并排序 Merge Sort</title>
      <link>https://realjf.io/algorithm/sort/merge-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:03:19 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/merge-sort/</guid>
      <description>归并排序的基本思想是： - 将给定的包含n个元素的局部数组“分割”成两个局部数组，每个数组各包含n/2各元素。 - 对两个局部数组分别执行mergeSort排序。 - 通过merge将两个已排序完毕的局部数组整合成一个数组。
#inlcude &amp;lt;iostream&amp;gt; using namespace std; #define MAX 500000 #define SENTINEL 2000000000 int L[MAX/2+2], R[MAX/2+2]; int cnt; void merge(int A[], int n, int left, int mid, int right){ int n1 = mid - left; int n2 = right - mid; for(int i=0; i&amp;lt; n1; i++)L[i] = A[left+i]; for(int i = 0; i&amp;lt; n2;i++) R[i] = A[mid+i]; L[n1] = R[n2] = SENTINEL; int i = 0; j = 0; for(int k = left; k&amp;lt;right;k++){ cnt++; if(L[i]&amp;lt;=R[j]){ A[k] = L[i++]; }else{ A[k] = R[j++]; } } } void mergeSort(int A[], int n, int left, int right){ if(left+1 &amp;lt; right){ int mid = (left + right) / 2; mergeSort(A, n, left, mid); mergeSort(A, n, mid, right); merge(A, n, left, mid, right); } } int main(){ int A[MAX], n, i; cnt = 0; cin &amp;gt;&amp;gt; n; for(i = 0; i&amp;lt;n; i++) cin&amp;gt;&amp;gt;A[i]; mergeSort(A, n, 0, n); for(i=0; i&amp;lt;n; i++){ if(i) cout &amp;lt;&amp;lt; &amp;quot; &amp;quot;; cout &amp;lt;&amp;lt; A[i]; } cout &amp;lt;&amp;lt; endl; cout &amp;lt;&amp;lt; cnt &amp;lt;&amp;lt; endl; return 0; }  </description>
    </item>
    
    <item>
      <title>排序算法之插入排序 Insert Sort</title>
      <link>https://realjf.io/algorithm/sort/insert-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:03:02 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/insert-sort/</guid>
      <description>插入排序是简单的说，就是遍历整个数组，每次将一个元素插入到已排序的数组中，直到插入最后一个元素即完成整个排序过程。
基本思想  将开头第一个元素视作已排序部分，后续元素视作未排序部分 对未排序部分执行一下操作，直到未排序部分被消除  取出未排序部分开头第一个元素作为待排序元素t 将t与已排序部分进行对比，将比t顺序大的元素往后移动一个，即确定排序位置 将待排序元素t插入空出的排序位置中    #include &amp;lt;stdio.h&amp;gt; int main(){ int a[10],i,j; for(i=0;i&amp;lt;10;i++){scanf(&amp;quot;%d&amp;quot;, &amp;amp;a[i]);} for (i=1;i&amp;lt;10;i++){ int t = a[i]; // 待排序元素 j = i-1; while(j&amp;gt;=0 &amp;amp;&amp;amp; a[j] &amp;gt; t){ a[j+1] = a[j]; // 往后移动一个 j--; } a[j+1] = t; // 插入 } for(i=0; i&amp;lt;10;i++){ printf(&amp;quot;%d &amp;quot;, a[i]); } }  插入排序算法最坏的情况时间复杂度也是O(n^2)</description>
    </item>
    
    <item>
      <title>排序算法之冒泡排序 Bubble Sort</title>
      <link>https://realjf.io/algorithm/sort/bubble-sort/</link>
      <pubDate>Tue, 28 Apr 2020 15:00:51 +0800</pubDate>
      
      <guid>https://realjf.io/algorithm/sort/bubble-sort/</guid>
      <description>冒泡排序算法很简单，对相邻的元素进行两两比较，顺序相反则进行交换，这样，每一趟会将最小或最大的元素“浮”到顶端，最终达到完全有序。
基本思想： 1.
#include &amp;lt;stdio.h&amp;gt; void swap(int* a, int* b){ if(*a &amp;gt; &amp;amp;b){ *a = *a+*b; *b = *a-*b; *a = *a-*b; } return; } int main(){ int a[10],i,j; for(i=0;i&amp;lt;10;i++){scanf(&amp;quot;%d&amp;quot;, &amp;amp;a[i]);} for (i=0;i&amp;lt;10;i++){ for(j=0; j&amp;lt;i; j++){ swap(&amp;amp;a[i], &amp;amp;a[j]); } } for(i=0; i&amp;lt;10;i++){ printf(&amp;quot;%d&amp;quot;, a[i]); } }  由以上程序可以看出，程序的时间复杂度是O(n^2)</description>
    </item>
    
    <item>
      <title>分布式锁的实现方式和原理</title>
      <link>https://realjf.io/distributed/lock-implement/</link>
      <pubDate>Tue, 28 Apr 2020 14:53:32 +0800</pubDate>
      
      <guid>https://realjf.io/distributed/lock-implement/</guid>
      <description>我们需要的分布式锁应该是怎么样的？  可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。 这把锁要是一把可重入锁（避免死锁） 这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条） 有高可用的获取锁和释放锁功能 获取锁和释放锁的性能要好  实现分布式锁的几种方法 分布式锁是控制分布式系统之间同步访问共享 资源的一种方式。在分布式系统中，常常需要协调他们的动作，如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性，这种情况下，便需要使用到分布式锁。
 基于缓存实现，如Redis实现——使用redis的setnx()、get()、getset()方法，用于分布式锁，解决死锁问题 基于数据库乐观锁实现 基于zookeeper实现   乐观锁通常实现基于数据版本(version)的记录机制实现的，比如有一张红包表（t_bonus），有一个字段(left_count)记录礼物的剩余个数，用户每领取一个奖品，对应的left_count减1，在并发的情况下如何要保证left_count不为负数，乐观锁的实现方式为在红包表上添加一个版本号字段（version），默认为0。
 SETNX key val # 原子性操作，当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。 expire key timeout # 为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。 delete key # 删除key GETSET key value # 将给定 key 的值设为 value ，并返回 key 的旧值 (old value)，当 key 存在但不是字符串类型时，返回一个错误，当key不存在时，返回nil  基于数据库实现 使用数据库乐观锁，包括主键防重，版本号控制。但是这两种方法各有利弊。
 使用主键冲突的策略进行防重，在并发量非常高的情况下对数据库性能会有影响，尤其是应用数据表和主键冲突表在一个库的时候，表现更加明显。其实针对是否会对数据库性能产生影响这个话题，我也和一些专业的DBA同学讨论过，普遍认可的是在MySQL数据库中采用主键冲突防重，在大并发情况下有可能会造成锁表现象，比较好的办法是在程序中生产主键进行防重。
 使用版本号策略 这个策略源于mysql的mvcc机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断sql每次进行判断。
  基于数据库表实现 要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。
当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。
上面这种简单的实现有以下几个问题： - 1、这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。
 2、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。
 3、这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。
 4、这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</description>
    </item>
    
    <item>
      <title>rabbitmq go客户端库实现</title>
      <link>https://realjf.io/rabbitmq/client/</link>
      <pubDate>Tue, 28 Apr 2020 14:49:47 +0800</pubDate>
      
      <guid>https://realjf.io/rabbitmq/client/</guid>
      <description>go rabbitmq client library
go get github.com/streadway/amqp   send.go（消息发送者） package main import ( &amp;quot;log&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;github.com/streadway/amqp&amp;quot; ) func failOnError(err error, msg string){ if err != nil { log.Fatalf(&amp;quot;%s: %s&amp;quot;, msg, err) panic(fmt.Sprintf(&amp;quot;%s: %s&amp;quot;, msg, err)) } } func main(){ conn, err := amqp.Dial(&amp;quot;amqp://guest:guest@localhost:5672/&amp;quot;) failOnError(err, &amp;quot;Failed to connect to RabbitMQ&amp;quot;) defer conn.Close() ch, err := conn.Channel() failOnError(err, &amp;quot;Failed to open a channel&amp;quot;) defer ch.Close() q, err := ch.QueueDeclare( &amp;quot;hello&amp;quot;, false, false, false, false, nil, ) failOnError(err, &amp;quot;Failed to declare a queue&amp;quot;) body := &amp;quot;hello&amp;quot; // 发布消息 err = ch.</description>
    </item>
    
    <item>
      <title>安装rabbitmq</title>
      <link>https://realjf.io/rabbitmq/set-up/</link>
      <pubDate>Tue, 28 Apr 2020 14:49:04 +0800</pubDate>
      
      <guid>https://realjf.io/rabbitmq/set-up/</guid>
      <description>Erlang下载地址：http://www.erlang.org/downloads
 rabbitmq官网下载地址：http://www.rabbitmq.com/download.html
  CentOS7.x安装  下载rabbitmq
wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.4/rabbitmq-server-3.7.4-1.el7.noarch.rpm  安装erlang
yum install erlang   需要先安装yum EPEL源
yum install epel-release -y # 或 rpm -vih http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm # 或 wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-2.noarch.rpm rpm -vih epel-release-7-2.noarch.rpm # 更新数据 yum clean all &amp;amp;&amp;amp; yum makecache     erlang下载地址http://erlang.org/download/ 源码安装：
wget http://erlang.org/download/otp_src_20.2.tar.gz # 解压 tar -xzvf otp_src_20.2.tar.gz # 安装依赖包 yum install -y gcc gcc-c++ unixODBC-devel openssl-devel ncurses-devel # 设定安装位置 .</description>
    </item>
    
    <item>
      <title>mysql 事务 Transaction</title>
      <link>https://realjf.io/mysql/transaction/</link>
      <pubDate>Tue, 28 Apr 2020 14:42:50 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/transaction/</guid>
      <description>mysql存储引擎与事务：  1.myisam：不支持事务，用于只读程序提高性能 2. innodb：支持acid事务、行级锁、并发 3. berkeley db：支持事务。  一个事务是一个连续的一组数据库操作，就好像一个单一的工作单元进行。 如果在事务的任何操作失败，则整个事务将失败。
事务的特性： 事务有以下四个标准属性的缩写acid，通常被称为：
 原子性：确保工作单元内的所有操作都完成，否则事务将被终止在故障点，和以前的操作将回滚到以前的状态。 一致性：确保数据库正确地改变状态后，成功提交的事务。 隔离性：使事务操作彼此独立的和透明的。 持久性：确保提交的事务的结果或效果的系统出现故障的情况下仍然存在。  在MySQL中，事务开始使用COMMIT或ROLLBACK语句开始工作和结束。开始和结束语句的SQL命令之间形成了大量的事务。
COMMIT &amp;amp; ROLLBACK: 这两个关键字提交和回滚主要用于MySQL的事务。
当一个成功的事务完成后，发出COMMIT命令应使所有参与表的更改才会生效。
如果发生故障时，应发出一个ROLLBACK命令返回的事务中引用的每一个表到以前的状态。
可以控制的事务行为称为AUTOCOMMIT设置会话变量。如果AUTOCOMMIT设置为1（默认值），然后每一个SQL语句（在事务与否）被认为是一个完整的事务，并承诺在默认情况下，当它完成。 AUTOCOMMIT设置为0时，发出SET AUTOCOMMIT =0命令，在随后的一系列语句的作用就像一个事务，直到一个明确的COMMIT语句时，没有活动的提交。
可以通过使用mysql_query()函数在PHP中执行这些SQL命令。
事务 ACID Atomicity（原子性）、Consistency（稳定性）、Isolation（隔离性）、Durability（可靠性） 1、事务的原子性 一组事务，要么成功；要么撤回。
2、稳定性 有非法数据（外键约束之类），事务撤回。
3、隔离性 事务独立运行。 一个事务处理后的结果，影响了其他事务，那么其他事务会撤回。 事务的100%隔离，需要牺牲速度。
4、可靠性 软、硬件崩溃后，InnoDB数据表驱动会利用日志文件重构修改。 可靠性和高速度不可兼得， innodb_flush_log_at_trx_commit选项 决定什么时候吧事务保存到日志里。
开启事务 START TRANSACTION 或 BEGIN
提交事务（关闭事务） COMMIT
放弃事务（关闭事务） ROLLBACK
折返点 SAVEPOINT adqoo_1 ROLLBACK TO SAVEPOINT adqoo_1 发生在折返点 adqoo_1 之前的事务被提交，之后的被忽略
事务的终止
设置“自动提交”模式 SET AUTOCOMMIT = 0 每条SQL都是同一个事务的不同命令，之间由 COMMIT 或 ROLLBACK隔开 掉线后，没有 COMMIT 的事务都被放弃 事务锁定模式</description>
    </item>
    
    <item>
      <title>数据库范式 Database Normal Form</title>
      <link>https://realjf.io/mysql/database-normal-form/</link>
      <pubDate>Tue, 28 Apr 2020 14:39:03 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/database-normal-form/</guid>
      <description>第一范式：关系模式中，每个属性不可再分。属性原子性 第二范式：非主属性完全依赖于主属性，即消除非主属性对主属性的部分函数依赖关系。 第三范式：非主属性对主属性不存在传递函数依赖关系。 BNCF范式：在第三范式的基础上，消除主属性之间的部分函数依赖  第一范式（1NF）：在关系模式R中的每一个具体关系r中，如果每个属性值都是不可再分的最小数据单位，则称R是第一范式的关系。 例：如职工号，姓名，电话号码组成一个表（一个人可能有多个电话号码） 规范成为1NF有三种方法： 一是重复存储职工号和姓名。这样，关键字只能是电话号码。 二是职工号为关键字，电话号码分为单位电话和住宅电话两个属性 三是职工号为关键字，但强制每条记录只能有一个电话号码。
以上三个方法，第一种方法最不可取，按实际情况选取后两种情况。
第二范式（2NF）：如果关系模式R（U，F）中的所有非主属性都完全依赖于任意候选关键字，则称关系R 是属于第二范式的。 例：选课关系 sc（sid，cid，grade，credit）其中sid为学号， cid为课程号，grade为成绩，credit为学分。 由以上条件，关键字为组合关键字（sid，cid） 在应用中使用以上关系模式有以下问题： a.数据冗余，假设同一门课由40个学生选修，学分就重复40次。 b.更新异常，若调整了某课程的学分，相应的元组credit值都要更新，有可能会出现同一门课学分不同。 c.插入异常，如计划开新课，由于没人选修，没有学号关键字，只能等有人选修才能把课程和学分存入。 d.删除异常，若学生已经结业，从当前数据库删除选修记录。某些门课程新生尚未选修，则此门课程及学分记录无法保存。 原因：非关键字属性credit仅函数依赖于cid，也就是credit部分依赖组合关键字（sid，cid）而不是完全依赖。 解决方法：分成两个关系模式sc（sid，cid，grade），c（cid，credit）。新关系包括两个关系模式，它们之间通过sc中的外关键字cid相联系，需要时再进行自然联接，恢复了原来的关系
第三范式（3NF）：如果关系模式R（U，F）中的所有非主属性对任何候选关键字都不存在传递依赖，则称关系R是属于第三范式的。 例：如s（sid，sname，did，dname，location） 各属性分别代表学号，姓名，所在系，系名称，系地址。 关键字sid决定各个属性。由于是单个关键字，没有部分依赖的问题，肯定是2NF。但这关系肯定有大量的冗余，有关学生所在的几个属性did，dname，location将重复存储，插入，删除和修改时也将产生类似以上例的情况。 原因：关系中存在传递依赖造成的。即sid -&amp;gt; did。 而did -&amp;gt;sid却不存在，did -&amp;gt; location, 因此关键字sid对location函数决定是通过传递依赖did-&amp;gt;location 实现的。也就是说，sid不直接决定非主属性location。 解决目地：每个关系模式中不能留有传递依赖。 解决方法：分为两个关系 s（sid，sname，did），d（dno，dname，location） 注意：关系s中必须有外关键字did。否则两个关系之间失去联系。
BCNF：如果关系模式R（U，F）的所有属性（包括主属性和非主属性）都不传递依赖于R的任何候选关键字，那么称关系R是属于BCNF的。或是关系模式R中，每个决定因素都包含关键字（而不是被关键字所包含）。 例：配件管理关系模式 wpe（wid，pid，eid，qnt）分别表仓库号，配件号，职工号，数量。有以下条件: a.一个仓库有多个职工。 b.一个职工仅在一个仓库工作。 c.每个仓库里一种型号的配件由专人负责，但一个人可以管理几种配件。 d.同一种型号的配件可以分放在几个仓库中。 分析： 1. pid不能确定qnt，由组合属性（wid，pid）来决定，存在函数依赖（wid，pid）-&amp;gt; qnt。 2. 每个仓库里的一种配件由专人负责，而一个人可以管理几种配件，所以有（wid，pid）-&amp;gt; eid。 3. 一个职工仅在一个仓库工作，有eid -&amp;gt; wid。 4. 每个仓库里的一种配件由专人负责，而一个职工仅在一个仓库工作，有（eid，pid）-&amp;gt; qnt。 找一下候选关键字。因为（wid，pid）-&amp;gt; qnt，（wid，pid）-&amp;gt; eid，因此（wid，pid）可以决定整个元组，是一个候选关键字。根据eid -&amp;gt; wid，（eid，pid）-&amp;gt; qnt，故（eid，pid）也能决定整个元组，为另一个候选关键字。属性eid，eid，pid 均为主属性，只有一个非主属性qnt。它对任何一个候选关键字都是完全函数依赖的，并且是直接依赖，所以该关系模式是3NF。</description>
    </item>
    
    <item>
      <title>Mysql优化技巧</title>
      <link>https://realjf.io/mysql/optimize-mysql/</link>
      <pubDate>Tue, 28 Apr 2020 14:35:15 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/optimize-mysql/</guid>
      <description>索引失效情况：  1. 如果条件中有or，即使其中有条件带有索引也不会使用，换言之，要想使用or，又想让索引生效，只能将or条件中的每个列都必须使用索引。 2. 对于多列索引，不是使用的第一部分，则不会使用索引 3. like查询是以%开头的情况 4. 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不使用索引。 5. 如果mysql估计使用全表扫描要比使用索引快，则不使用索引。 6. 在列上进行运算 7. 使用NOT IN 和 &amp;lt;&amp;gt;操作 8. 只要列中包含有NULL值将不会 被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的，所以我们在数据库设计时不要让字段的默认值为NULL 9. mysql查询只使用一个索引，因此如果where子句已经使用了索引，那么order by中的列不会使用索引的。因此数据库默认排序可以复合要求的情况下不要使用排序操作，尽量不要包含多列排序，如果需要最好给这些列创建复合索引。  sql语句小技巧 1. 在使用group by 分组查询时，默认分组后，还会进行排序，可能会降低速度 在group by后面加上order by null 就可以防止排序
2. 有些情况下，可以使用连接来替代子查询，因为使用join，mysql不需要在内存中创建临时表。 select * from dept,emp where dept.deptno=emp.deptno select * from dept left join emp on dept.deptno=emp.deptno[左外连接]
3. 避免使用 select * 从数据库中读取越多数据，查询就越慢
4. 当只要一行数据时使用limit 1 使用limit 1数据库引擎会在找到一条数据后停止搜索，而不是继续往后查寻下一条符合记录的数据。
5. 使用explain你的select查询 使用explain关键字可以让你直到mysql是如何处理你的sql语句的，这可以帮你分析你的查询语句或表结构的性能瓶颈。
6. 永远为每张表设置一个id字段为主键 7. 使用enum而不是varchar类型 enum类型非常快和紧凑，实际上，其保存的是tinyint类型，但其外表上显示为字符串。</description>
    </item>
    
    <item>
      <title>远程登录Mysql配置</title>
      <link>https://realjf.io/mysql/remote-login-mysql/</link>
      <pubDate>Tue, 28 Apr 2020 14:33:41 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/remote-login-mysql/</guid>
      <description>原文地址:http://blog.chinaunix.net/uid-25806228-id-371815.html
Mysql默认关闭远程登录权限，如下操作允许用户在任意地点登录：  进入mysql，
GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;&#39; WITH GRANT OPTION;  IDENTIFIED BY后跟的是密码，可设为空。
 FLUSH privileges;
  更新Mysql为了安全性，在默认情况下用户只允许在本地登录，可是在有此情况下，还是需要使用用户进行远程连接，因此为了使其可以远程需要进行如下操作：
一、允许root用户在任何地方进行远程登录，并具有所有库任何操作权限，具体操作如下： 在本机先使用root用户登录mysql： mysql -u root -p&amp;rdquo;youpassword&amp;rdquo; 进行授权操作：
mysql&amp;gt;GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;youpassword&#39; WITH GRANT OPTION;  重载授权表：
FLUSH PRIVILEGES;  退出mysql数据库： exit
二、允许root用户在一个特定的IP进行远程登录，并具有所有库任何操作权限，具体操作如下： 在本机先使用root用户登录mysql：
mysql -u root -p&amp;quot;youpassword&amp;quot;  进行授权操作：
GRANT ALL PRIVILEGES ON *.* TO root@&amp;quot;172.16.16.152&amp;quot; IDENTIFIED BY &amp;quot;youpassword&amp;quot; WITH GRANT OPTION;  重载授权表：</description>
    </item>
    
    <item>
      <title>MySQL 5.7 源码安装</title>
      <link>https://realjf.io/mysql/set-up-mysql-57/</link>
      <pubDate>Tue, 28 Apr 2020 14:31:48 +0800</pubDate>
      
      <guid>https://realjf.io/mysql/set-up-mysql-57/</guid>
      <description>源码安装 源码下载地址:http://cdn.mysql.com/Downloads/MySQL-5.7/mysql-5.7.15.tar.gz
先检查已有的mysql
rpm -qa | grep mysql rpm -e mysql-libs-5.1.73-3.el6_5.x86_64 --nodeps  1. 安装依赖的包 由于从mysql5.5开始弃用了常规的configure编译方法，所以需要下载cmake编译器、boost库、ncurses库和gnu分析器生成器bison这4种工具。
yum -y install make gcc-c++ ncurses-devel  安装cmake
wget https://cmake.org/files/v3.6/cmake-3.6.2.tar.gz tar zxvf cmake-3.6.2.tar.gz cd cmake-3.6.2 ./configure make &amp;amp;&amp;amp; make install  安装bison
wget -c http://git.typecodes.com/libs/ccpp/bison-3.0.tar.gz tar zxvf bison-3.0.tar.gz &amp;amp;&amp;amp; cd bison-3.0/ &amp;amp;&amp;amp; ./configure make &amp;amp;&amp;amp; make install  安装boost
wget http://nchc.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz tar zxvf boost_1_59_0.tar.gz cd boost_1_59_0 ./bootstrap.sh ./b2 stage threading=multi link=shared ./b2 install threading=multi link=shared  或者</description>
    </item>
    
    <item>
      <title>安装 Sphinx</title>
      <link>https://realjf.io/sphinx/set-up-sphinx/</link>
      <pubDate>Tue, 28 Apr 2020 14:26:34 +0800</pubDate>
      
      <guid>https://realjf.io/sphinx/set-up-sphinx/</guid>
      <description>简介 sphinx是由俄罗斯人开发的一个全文检索引擎。旨在为其他应用提供高速、低空间占用、告诫过相关度的全文搜索功能。
特性: - 高速的建立索引（在现代cpu上，峰值性能可达到10MB/秒）; - 高性能的搜索（在2~4GB的文本数据上，平均每次检索响应时间小于0.1秒） - 可处理海量数据（目前已知可以处理超过100GB的文本数据，在单一CPU系统上可处理100M文档） - 提供了优秀的相关度算法，基于短语相似度和统计的复合Ranking方法。 - 支持分布式搜索 - 支持短语搜索 - 提供文档摘要生成 - 可作为mysql的存储引擎提供搜索服务 - 支持布尔、短语、词语相似度等多种检索模式 - 文档支持多个全文检索字段（最大不超过32个） - 文档支持多个额外的属性信息 - 支持断词
官网地址：http://sphinxsearch.com/
下载地址：http://sphinxsearch.com/downloads/current/
二进制地址：http://sphinxsearch.com/files/sphinx-3.0.2-2592786-linux-amd64.tar.gz
源码包地址：http://sphinxsearch.com/files/sphinx-2.2.11-release.tar.gz
中文文档地址：http://www.sphinxsearch.org/archives/category/php
sphinx在mysql上的应用有两种方式：  采用api调用，如php、java等的api函数或方法查询。优点是可不必对mysql重新编译，服务端进程“低耦合”，且程序灵活度高、方便调用。 使用插件方式 sphinxSE把sphinx编译成一个mysql插件并使用特定的sql语句进行检索。 通过安装相关编程语言的扩展插件  准备  mysql mysql-devel 编译软件gcc gcc-c++ autoconf automake sphinx
# 安装工具 yum install -y make gcc libtool gcc-c++ g++ autoconf imake automake mysql-devel libxml2-devel expat-devel   sphinx安装 # 下载 wget http://sphinxsearch.</description>
    </item>
    
    <item>
      <title>sphinx的 total 和 total_found的区别</title>
      <link>https://realjf.io/sphinx/total_found/</link>
      <pubDate>Tue, 28 Apr 2020 14:26:04 +0800</pubDate>
      
      <guid>https://realjf.io/sphinx/total_found/</guid>
      <description>sphinx.conf文件里面有一个配制最大匹配数的参数max_matches ,默认值是1000假如一次搜索里应该查询到2000个匹配,但是在sphinx结果集中只会返回1000个匹配，因为受到max_matches=1000的限制,这时候,结果集里, total=1000,total_found=2000,假设一页显示20条,那么如果用total_found做为分页的总数来设定,在第51页之后的数据都将显示为空白,因为操过了1000条记录.
于是,我修改了sphinx.conf里的max_matches=2000,结果发现,改成2000之后还是没有取到2000条记录,在第51页之后都是空白数据,为什么?
这时候我又去网上查了资料,发现,$s-&amp;gt;SetLimits($start, $limit)的第三个参数,默认为1000,这个参数也是用来设定返回的最大匹配数的,所以这就是这为什么配制文件里改成2000后还是只取到1000条记录的原因&amp;hellip;
还有一点,就是setLimits的第三个参数的值不能超过max_matches的值,否则将取不到记录
所以,total_found返回的是所有的匹配数,不受max_matches和setLimits的第三个参数的限制,而total返回的匹配数最大不超过max_matches和setLimits里的最小值
比如我们经常看到的,淘宝搜索返回的页面最多只返回100页的数据,这时候,total和total_found就能很好的起到作用</description>
    </item>
    
    <item>
      <title>C&#43;&#43;之内存模型 Memory Model</title>
      <link>https://realjf.io/cpp/memory-model/</link>
      <pubDate>Mon, 27 Apr 2020 16:44:23 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/memory-model/</guid>
      <description>C++使用三种不同方案（C++11是四种）来存储数据：
 自动存储持续性 在函数定义中声明的变量（包括函数参数）的持续性为自动的。他们在程序开始执行其所属的函数或代码块时被创建，在执行完函数或代码块时，他们使用的内存将被释放。 静态存储持续性 在函数定义外定义的变量和使用关键字static定义的变量存储的持续性都为静态，他们在程序整个运行过程中都存在。 线程储存持续性（C++11）多核处理器很常见，如果变量是使用关键字thread_local声明的，则其生命周期与所属的线程一样长。 动态存储持续性 用new运算符分配的内存将一直存在，知道使用delete运算符将其释放或程序结束位置。这种内存的存储持续性为动态，有时被称为自由存储或堆   作用域描述了名称在文件的多大范围可见 链接性描述了名称如何在不同单元间共享。链接性为外部的名称可在文件间共享，链接性为内存的名称只能由一个文件中的函数共享。自动变量的名称没有链接性，因为它们不能共享。
 自动存储持续性 在默认情况下，在函数中声明的函数参数和变量的存储持续性为自动，作用域为局部，没有链接性。
自动变量和栈 由于自动变量的数目随函数的开始和结束而增减，因此程序常留出一段内存对自动变量进行管理，通常将其视为栈。
栈是后进先出的，这种设计简化了参数传递。函数调用将其参数的值放在栈顶，然后重新设置栈顶指针，被调用的函数根据其形参描述来确定每个参数的地址。
静态持续变量 c++为静态存储持续性变量提供了3种链接性： - 外部链接性（可在其他文件中访问）、 - 内部链接性（只能在当前文件中访问） - 无连接性（只能在当前函数或代码中访问）
这三种链接性都在整个程序执行期间存在。
编译器将分配固定的内存块来存储所有的静态变量。主要是.data段里
 如果没有显示地初始化静态变量，编译器将把它设置为0.
    存储描述 持续性 作用域 链接性 如何声明     自动 自动 代码块 无 在代码块中   寄存器 自动 代码块 无 在代码块中，使用关键字register   静态，无链接性 静态 代码块 无 在代码块中，使用关键字static   静态，外部链接性 静态 文件 外部 不在任何函数内   静态，内部链接性 静态 文件 内部 不在任何函数内，使用关键字static    静态持续性、外部链接性 外部变量的存储持续性为静态，作用域为整个文件。外部变量也称全局变量。</description>
    </item>
    
    <item>
      <title>TCP协议流量控制与拥塞控制详解</title>
      <link>https://realjf.io/network/tcp-protocol/</link>
      <pubDate>Thu, 23 Apr 2020 17:31:45 +0800</pubDate>
      
      <guid>https://realjf.io/network/tcp-protocol/</guid>
      <description>TCP的主要特点  面向连接的运输层协议 可靠交付服务 提供全双工通信 面向字节流  连续ARQ协议  连续ARQ协议规定：发送方维持一个发送窗口，每收到一个确认，就把发送窗口向前滑动一个分组的位置。 接收方采用累积确认的方式，在收到几个分组后，对按序到达的最后一个分组发送确认。   MSS最大报文段长度
 滑动窗口协议 以字节为单位的滑动窗口。每个tcp活动连接的两端都维护一个发送窗口结构和接收窗口结构。tcp以字节为单位维护其窗口结构。 随着时间推移，当接收到返回的数据ack，滑动窗口也随之右移。
每个tcp报文段都包含ack号和窗口通告信息，tcp发送端可以据此调节窗口结构。
流量控制 所谓流量控制，就是让发送方的发送速率不要太快，要让接收方来得及接收，利用滑动窗口机制可以很方便在tcp连接上实现对发送方的流量控制。
图例说明下 TCP报文段发送机制  第一种机制是TCP维持一个tcp报文段发送出去 第二种机制是由发送方的应用进程指明要求发送报文段 第三种机制是发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段发送出去。  拥塞控制 拥塞控制原理 所谓拥塞控制就是防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制索要做的都有一个前提， 就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。
流量控制往往是指点对点通信量的控制。
拥塞控制方法 拥塞控制是一个动态的问题，从大的方面看，可以分为开环控制和闭环控制两种方法。
开环控制 就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。
闭环控制 闭环控制基于反馈环路，主要有以下几种措施：
 监测网络系统以便检测到拥塞在何时、何处发生。 把拥塞发生的信息传送到可采取行动的地方 调整网络系统的运行以解决出现的问题  拥塞控制的算法 tcp进行拥塞控制的算法有四种，即慢开始(slow-start)、拥塞避免(congestion avoidance)、快重传(fast retransmit)和快恢复(fast recovery)
慢开始和拥塞避免  发送方让自己的发送窗口等于拥塞窗口 判断网络出现拥塞的依据就是出现了超时
 慢开始算法思路：当主机开始发送数据时，由于并不清楚网络的负荷情况，所以如果立即把大量数据字节注入到网络，那么就有可能引起网络发生拥塞。 经验证明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。
RFC5681规定初始拥塞窗口cwnd设置为不超过2至4个SMSS（最大报文段）的数值，具体如下：
 若SMSS&amp;gt;2190字节，则设置初始拥塞窗口cwnd=2xSMSS字节，且不得超过2个报文段。 若SMSS&amp;gt;1095且SMSS&amp;lt;=2190字节，则设置初始拥塞窗口cwnd=3xSMSS字节，且不得超过3个报文段。 若SMSS&amp;lt;=1095字节，则设置初始拥塞窗口cwnd=4xSMSS字节，且不得超过4个报文段。  慢开始规定：在每收到一个对新的报文段的确认后，可以把拥塞窗口增加最多一个SMSS的数值。即
拥塞窗口cwnd每次的增加量 = min(N,SMSS)
这里使用报文段的个数作为窗口大小的单位，来阐述拥塞控制原理
 因此，使用慢开始算法后，每经过一个传输轮次，拥塞窗口cwnd就加倍。</description>
    </item>
    
    <item>
      <title>Tcp 连接的建立与终止</title>
      <link>https://realjf.io/network/tcp/</link>
      <pubDate>Thu, 23 Apr 2020 16:10:57 +0800</pubDate>
      
      <guid>https://realjf.io/network/tcp/</guid>
      <description>tcp连接的建立和终止依赖于connect、accept、close等函数。同时tcp也可以说是全双工的方式进行通信。
TCP连接的建立：三次握手 准备条件 服务器通过调用socket、bind和listen三个函数完成准备监听工作，称为被动打开。
第一次 客户端通过调用connect发起连接建立请求，客户端通过tcp发送一个SYN（同步）数据包， 数据包中携带的是建立连接发送数据的初始序列号。通常SYN数据包不携带数据
第二次 服务器收到客户端的SYN数据包后，需要对这个数据包回应一个ACK数据包（其确认序列号=初始序列号+1），且自己也需要发送建立连接的 同步SYN数据包，服务器在一个数据包中发送SYN和ACK信息，并携带自己的初始序列号
第三次 客户端确认收到服务端发送的ACK后，需要回应服务端发送的SYN并发送一个ACK数据包（其确认序列号=初始序列号+1）给服务端。 服务端收到后，连接建立。
TCP连接的终止： 四次挥手 第一次 某个进程首先调用close，称为主动关闭，主动端发送一个FIN数据包，同样携带一个初始序列号，表示数据发送完毕。
第二次 接收这个FIN数据包的称为被动端，它的接收也作为一个文件结束符传递给接收端应用程序，并发送一个ACK数据包给主动端，且携带一个确认序列号
第三次 过了某个时间，被动端的应用程序处理了这个文件结束符，调用了close关闭这端的套接字，所以也发送一个FIN数据包并携带一个初始序列号过去。
第四次 主动端收到关闭请求，也需要回应一个ACK数据包并携带一个确认序列号过去，表示结束。
TCP 状态转换图 TIME_WAIT状态 TIME_WAIT状态，在主动关闭端最后发送确认关闭ACK数据包后，需要等待一段时间才能关闭。这个停留时间是最长数据包生命周期（maximum segment lifetime）的两倍，称为2MSL。
任何TCP实现都必须为MSL选择一个值，RFC1122建议是2分钟。不过伯克利套接字实现改用30秒，这意味着持续时间可能在一分钟到4分钟之间。
TIME_WAIT存在的理由：
 可靠实现tcp全双工连接的终止 允许老的重复数据包在网络中消失（每个数据包都有一个跳数ttl限制，通常是255）  第一个理由 因为假设最后一个ACK数据包可能丢失，这样被动端在没有收到FIN的ACK确认关闭数据包时，会启用超时重传，重新发送FIN数据包， 因此，主动端必须维持状态以等待重传的那个FIN数据包，并允许它重新发送确认ACK数据包。
第二个理由 假设某个套接字（这里指ip和端口的组合）刚关闭，过一段时间这个套接字上又建立了另一个连接，如果这个时候那个丢失的数据包出现， 则可能被这个新连接误认为是发给它的数据，造成错误。tcp为了防止这种问题出现，就必须让这个套接字上之前关闭的连接等待一段时间， 以等待这个丢失的数据包消失，而这个时间就是2MSL，这个时间足以让这个丢失的数据包在网络中消失。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;常用关键字用法解析 const static volatile extern mutable</title>
      <link>https://realjf.io/cpp/keyword/</link>
      <pubDate>Wed, 22 Apr 2020 18:09:41 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/keyword/</guid>
      <description>static 修饰局部变量  静态局部变量只作用于其定义的函数期间，函数结束，其所占用的内存空间也被回收。 在静态存储区分配空间，只初始化一次  修饰全局变量  也称静态全局变量，其作用域在定义它的文件里，不能作用于其他文件。 静态全局变量在静态存储区分配空间，在程序开始运行时完成初始化，也是唯一的一次初始化  修饰函数  静态函数只在声明它的文件中可见，不能被其他文件使用。  修饰类成员  对于静态类成员，它属于类，而不属于某个对象实例，多个对象之间共享静态类成员 静态类成员存储于静态存储区，生命周期为整个程序执行期 静态类成员需要初始化，且在类外初始化，默认初始化为0  初始化方法：&amp;lt;数据类型&amp;gt; &amp;lt;类名&amp;gt;::&amp;lt;静态类成员&amp;gt;=&amp;lt;值&amp;gt;
修饰类成员函数  同样静态类成员函数属于整个类，而非某个实例对象，也没有this指针，需要通过类名进行访问。 不能将静态类成员函数定义为虚函数 &amp;gt; 虚函数依赖vptr和vtable，vptr通过类的构造函数生成，且只能用this指针访问，这也就是为什么静态成员函数不能是虚函数的原因 由于静态成员函数没有this指针，所以就差不多等同于nonmember函数，结果就产生了一个意想不到的好处：成为一个callback函数，使得我们得以将C++和C-based X Window系统结合，同时也成功的应用于线程函数身上 为了防止父类的影响，可以在子类定义一个与父类相同的静态变量，以屏蔽父类的影响。  const 规则：const离谁近，谁就不能被修改，只读的意思，且需要初始化。
修饰基本数据类型  修饰一般常量时，可以在类型说明符前也可以在其后，只要在使用时不改变常量即可。 const修饰指针变量*及引用变量&amp;amp; &amp;gt; 如果const位于星号*的左侧，则const就是用来修饰指针所指向的变量，即指针指向为常量 &amp;gt; 如果const位于星号的右侧，const就是修饰指针本身，即指针本身是常量  作为函数参数的修饰符 用相应的变量初始化const常量，则在函数体中，按照const所修饰的部分进行常量化，保护了原对象的属性不被修改
void say(const char* str){...}  作为函数返回值的修饰符 声明了返回值后，对返回值起到保护作用，即使得其返回值不为“左值”，只能作为右值使用。
const int add(int a, int b){...}  const修饰类成员 修饰的类成员的初始化只能在类的构造函数的初始化表中进行
const修饰类成员函数 作用是修饰的成员函数不能修改类的任何成员变量
int funcA() const {}  const修饰类对象，定义常量对象 常量对象只能调用常量函数，别的成员函数都不能调用。</description>
    </item>
    
    <item>
      <title>zab协议 （Zookeeper Zab Protocol）</title>
      <link>https://realjf.io/distributed/zookeeper-zab-protocol/</link>
      <pubDate>Wed, 22 Apr 2020 09:18:44 +0800</pubDate>
      
      <guid>https://realjf.io/distributed/zookeeper-zab-protocol/</guid>
      <description>ZAB协议，（ZooKeeper Atomic Broadcast, ZooKeeper原子消息广播协议） ZAB协议不像Paxos算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播协议
ZAB协议的核心 所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为Leader服务器，而余下的其他服务器则成为follower服务器， leader服务器负责将一个客户端事务请求转换成一个事务Proposal，并将该Proposal分发给集群中所有的follower服务器，之后leader服务器需要 等待所有follower服务器的反馈，一旦超过半数的follower服务器进行了正确的反馈后，那么leader就会再次向所有的follower服务器分发commit消息， 要求其将前一个Proposal进行提交。
ZAB协议内容 ZAB协议包括两种基本模式：崩溃恢复和消息广播。
当整个服务框架在启动过程中，或是当leader服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB协议就会进入恢复模式并选举产生新的leader服务器。 当选举产生新的leader服务器后，同时集群中已经有过半机器与该leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式，其中，所谓的状态同步是指数据同步， 用来保证集群中存在过半的机器能够和leader服务器的数据状态保持一致。
当集群中已经有过半的follower服务器完成了和leader服务器的状态同步，那么整个服务器框架就可以进入消息广播模式了。当一台同样遵循ZAB协议的服务器启动后加入到集群中， 如果此时集群中已经存在一个leader服务器在负责进行消息广播，那么新加入的服务器就会自觉的进入数据恢复模式：找到leader所在的服务器，并与其进行数据同步， 然后一起参与到消息广播流程中。
ZooKeeper设计成只允许唯一的一个leader服务器来进行事务请求的处理。leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议， 而如果集群中的其他机器接收到客户端的事务请求，那么这些非leader服务器会首先将这个事务请求转发给leader服务器。
当leader服务器出现崩溃退出或机器重启，亦或集群中已经不存在过半的服务器与该leader服务器保持正常通信时，那么在重新开始新一轮的原子广播事务操作之前， 所有进程首先会使用崩溃恢复协议来使彼此达到一个一致的状态，于是整个ZAB流程就会从消息广播模式进入到崩溃恢复模式。
数据同步 在ZAB协议的事务编号ZXID设计中，ZXID是一个64位的数字，其中低32位可以看作是一个简单的单调递增的计数器，针对客户端的每一个事务请求，leader服务器在产生 一个新的事务Proposal的时候，都会对该计数器进行加1操作，而高32位则代表了leader周期epoch的编号，每当选举产生一个新的leader服务器，就会从这个leader 服务器上取出其本地日志中最大事务Proposal的ZXID，并从该ZXID中解析出对应的epoch值，然后再对其进行加1操作，之后就会以此编号作为新的epoch，并 将低32位置0来开始生成新的ZXID。ZAB协议中的这一通过epoch编号来区分leader周期变化的策略，能够有效避免不同的leader服务器错误地使用相同的ZXID编号 提出不一样的事务Proposal的异常情况，这对于识别在leader崩溃恢复前后生成的Proposal非常有帮助。
基于这样的策略，当一个包含了上一个leader周期中尚未提交过的事务Proposal的服务器启动时，其肯定无法成为leader，因为当前集群中一定包含一个Quorum集合， 该集合中的机器一定包含了更高epoch的事务Proposal，因此这台机器的事务Proposal肯定不是最高，也就无法成为leader了。
ZAB与Paxos算法的联系与区别 联系  两者都存在一个类似leader进程的角色，由其负责协调多个follower进程的运行 leader进程都会等待超过半数的follower做出正确的反馈后，才会将一个提案进行提交 在ZAB协议中，每个Proposal中都包含了一个epoch值，用来代表当前leader周期，在Paxos算法中，同样存在这样一个标识，只是名字是Ballot。
区别 Paxos算法一个新选举产生的主进程会进行两个阶段的工作，第一阶段称为读阶段，与所有其他进程通信收集上一个主进程提出的提案，并将它们提交。 第二个阶段称为写阶段，主进程开始提出自己的提案。
  ZAB协议在Paxos算法上额外添加了一个同步阶段。在同步阶段之前，ZAB有个类似Paxos算法的读阶段，称为发现阶段。同步阶段之后，也有一个类似的写阶段。</description>
    </item>
    
    <item>
      <title>分布式一致性协议 2PC和3PC Paxos（Distributed Consistency Protocol）</title>
      <link>https://realjf.io/distributed/distributed-consistency-protocol/</link>
      <pubDate>Tue, 21 Apr 2020 10:05:32 +0800</pubDate>
      
      <guid>https://realjf.io/distributed/distributed-consistency-protocol/</guid>
      <description>分布式一致性协议在实践过程中产生了许多优秀的协议和算法，其中就包括两阶段提交、三阶段提交协议和Paxos算法。
2PC：两阶段提交 两阶段提交，主要由协调者和参与者组成，协调者负责协调所有参与者是否提交最后结果，并保证各参与者之间的结果一致（提交或者回滚）。
阶段一：提交事务请求阶段  协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并等待各参与者的回应 各参与者节点执行事务操作，并将undo和redo信息记录事务日志中 如果参与者执行了事务操作，那么就反馈给协调者yes响应，表示事务可以执行，否则返回no，表示事务不可以执行。  阶段二：执行事务提交阶段 阶段二主要是对各参与者反馈的情况决定是否继续进行事务提交操作，或者回滚。 主要包括两种情况：
第一种：执行事务提交 假如协调者从所有的参与者获得的反馈都是yes，那么就执行事务提交。
 发送提交请求，协调者向所有参与者节点发送commit请求 事务提交，参与者接收到commit请求后，会正式执行事务提交，并在完成后释放整个事务执行期间占用的资源 反馈事务提交结果，提交完成后，向协调者发送ack信息 完成事务，协调者接收到所有参与者的ack信息后，完成事务。  第二种：中断事务 假如任何一个参与者向协调者反馈了no，或者在等待超时之后，协调者仍然没有接收到所有参与者的反馈，那么就中断事务。
 发送回滚请求，协调者向所有参与者节点发送rollback请求 事务回滚，参与者接收到rollback请求后，利用第一阶段中记录的undo信息来执行事务回滚，并在完成回滚后释放在整个事务期间占用的资源 反馈事务回滚结果，参与者在完成事务回滚之后，向协调者发送ack信息 中断事务，协调者接收到所有的参与者反馈的ack信息后，完成事务中断  两阶段提交优缺点  优点：原理简单，实现方便 缺点：同步阻塞，单点问题、脑裂、容错机制简单  3PC：三阶段提交 三阶段提交可说是2PC的改进版，其将二阶段提交协议的提交事务请求过程一分为二，形成了CanCommit、PreCommit和do Commit三个阶段组成的事务处理协议。
阶段一：CanCommit  事务询问，协调者向所有的参与者发送一个包含事务内容的canCommit请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。 各参与者向协调者反馈事务询问的响应，参与者在接收到来自协调者的canCommit请求后，正常情况是，如果其自身认为可以顺利执行事务，那么会反馈yes，并进入预备状态，否则反馈no  阶段二：PreCommit 阶段二，协调者会根据各参与者的反馈情况来决定是否可以进行事务的PreCommit操作，正常情况，包括两种：
第一种：执行事务预提交 假如协调者从所有的参与者获得的反馈都是yes，那么就会执行事务预提交。
 发送预提交请求，协调者向所有参与者节点发送preCommit请求，并进入prepared阶段。 事务预提交，参与者接收到preCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。 各参与者向协调者反馈事务执行的响应，如果参与者成功执行了事务操作，那么就反馈给协调者ack响应，同时等待最终指令：提交（commit）或终止（abort）  第二种：中断事务 如果协调者收到任何一个参与者反馈了no，或者等待超时之后，仍然无法接收到所有参与者的反馈，那么就中断事务。
 发送中断请求，协调者向所有参与者节点发送abort请求 中断事务，无论是收到来自协调者的abort，或者是等待协调者请求过程中出现超时，参与者都会中断事务。  阶段三：doCommit 这个阶段是真正执行事务提交，存在两种可能
第一种：执行提交  发送提交请求，假设协调者处于正常状态，并且收到了所有参与者的ack信息，那么它就从预提交状态转换到提交状态，并向所有参与者发送doCommit请求 事务提交，参与者接收到doCommit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的资源。 反馈事务提交结果，参与者在完成事务提交之后，向协调者发送ack信息 完成事务，协调者接收到所有参与者的反馈ack信息后，完成事务。  第二种：中断事务 在这个阶段，假设协调者正常，并且有任意一个参与者反馈了no，或者等待超时之后，协调者无法接收到所有参与者的响应，那么就中断事务。
 发送中断请求，协调者向所有参与者节点发送abort请求 事务回滚，参与者接收到abort请求后，会利用其在阶段二中记录的undo信息来执行回滚，并在完成回滚之后释放事务执行期间占用的资源。 反馈事务回滚结果，事务完成回滚之后，向协调者发送ack信息 中断事务，协调者接收到所有参与者反馈的的ack信息后，中断事务  注意：一旦进入阶段三，可能有两种故障</description>
    </item>
    
    <item>
      <title>五种I/O模式 （Io Pattern）</title>
      <link>https://realjf.io/cpp/io-pattern/</link>
      <pubDate>Fri, 17 Apr 2020 15:22:29 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/io-pattern/</guid>
      <description>常见的五种I/O模式 I/O模式有这五种，分别是：
 阻塞I/O （linux下默认都采用阻塞I/O） 非阻塞I/O （可以通过fcntl或者open设置使用O_NONBLOCK参数，将文件描述符设置为非阻塞） I/O多路复用 信号驱动I/O 异步I/O  其中前面四种被称为同步IO
用户空间与内核空间 首先理解，当进程运行在内核空间时就处于内核态，而进程运行在用户空间时则处于用户态。 在内核态下，进程运行在内核地址空间中，此时的 CPU 可以执行任何指令。运行的代码也不受任何的限制，可以自由地访问任何有效地址，也可以直接进行端口的访问。 在用户态下，进程运行在用户地址空间中，被执行的代码要受到 CPU 的诸多检查，它们只能访问映射其地址空间的页表项中规定的在用户态下可访问页面的虚拟地址，且只能对任务状态段(TSS)中 I/O 许可位图(I/O Permission Bitmap)中规定的可访问端口进行直接访问。
所以，区分内核空间和用户空间本质上是要提高操作系统的稳定性及可用性
进程切换过程 从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： - 保存上下文，包括程序计数器和其他寄存器 - 更新PCB信息(进程管理与控制信息) - 把进程pcb加入等待挂起等队列 - 选择另一个进程执行，并更新其pcb - 更新内存管理的数据结构 - 恢复上下文
阻塞IO 同步阻塞IO，用户进程发起一个IO请求，内核查看数据是否就绪，如果没有，就等待数据就绪，而用户进程处于阻塞状态， 且交出cpu控制权，但数据就绪后，内核将数据拷贝到用户进程空间，并通知用户进程，用户进程解除阻塞状态，进入就绪状态，等待下一次运行。
非阻塞I/O 非阻塞IO，用户进程发起IO请求后，内核检查相应状态，无论就绪与否都返回结果给用户进程，用户进程无需等待就可以根据相应结果进行处理， 当然用户进程可以循环发起IO请求操作，这相当于一直占用CPU。
I/O多路复用 多路IO复用是目前比较多的用于环节C10K问题的方案，采用select、poll、epoll等方式，其中epoll是linux特有的。 相比较非阻塞IO，多路复用的效率明显要高，且是在内核中进行的。
下面分别简要说下select、poll和epoll的区别
select select 函数监听的文件描述符有三类，writefds、readfds和exceptfds，调用后select会阻塞进程，直到有描述符就绪，或者超时， 函数返回后，通过遍历fdset，查找相应就绪的描述符进行处理。
select目前支持几乎所有的平台，在linux上一般限制最大监视文件描述符大小为1024。
 select最大限制是单进程fd最大支持1024个，64为系统默认为2048 对文件描述符采用轮询，效率低 需要维护一个用于存放大量fd的数据结构  poll poll本质上与select类似，管理多个文件描述符，也是进行轮询，根据描述符的状态进行处理。 但它没有最大数限制，poll也有个致命缺陷，包含大量文件描述符的数组被整个在内核与用户空间之间多次复制， 开销随着文件描述符数量激增
epoll epoll是linux2.6开始提供的功能，是对poll的改进，epoll没有文件描述符限制，使用一个文件描述符管理多个描述符， 将用户关心的事件描述符映射到内核中，期间只复制一次。
epoll使用epoll_ctl注册文件描述符，并监听自己感兴趣的事件，使用epoll_wait可以收到事件通知。
epoll的两种触发模式  EPOLLLT （水平触发）当epoll_wait监听的事件发生时，将此事件通知用户进程，用户进程可以不立即处理该事件。下次调用epoll_wait时，会再次响应并通知此事件 EPOLLET （边缘触发）当epoll_wait监听的事件发生时，将此事件通知用户进程，用户进程必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应通知此事件。  epoll的优点  没有最大并发数限制 效率提升，内核态监听事件，只复制一次事件映射集，不是轮询机制，而是使用事件通知机制，只有活跃的文件描述符才占用开销。  epoll的工作流程 信号驱动I/O 信号驱动IO,用户进程首先需要安装SIGIO信号处理函数，然后内核等待IO请求，用户进程继续执行， 直到内核发出SIGIO信号，表示数据准备好，并拷贝到用户进程空间，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;多态与虚函数 （Polymorphism）</title>
      <link>https://realjf.io/cpp/polymorphism/</link>
      <pubDate>Fri, 17 Apr 2020 14:04:30 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/polymorphism/</guid>
      <description>什么是多态？ C++的多态即针对同一事物对不同场景表现多种形态，称为c++的多态性
多态分为静态多态和动态多态 - 静态多态又分为函数重载和泛型编程 - 动态多态则通过虚函数实现
多态的作用  提供了接口与具体实现之间的另一层隔离， 改善了代码的组织结构和可读性以及可扩展性  静态多态 直接上代码
int Add(int a, int b) { return a + b; } double Add(float a, float b) { return a + b; } // 调用的时候 int main() { Add(1, 2); // 调用的是第一个Add Add(1.5, 2.5); // 调用的是第二个Add return 0; }  可以看到，静态多态是在编译期间可以确定的，根据具体的了类型调用不同的函数
动态多态 首先要理解，这里的动态是指在程序运行期间，所以动态多态只能在程序运行的时候确定。
而要实现动态多态，这里需要用到关键字virtual，声明一个函数为虚函数
具体代码：
class Animal { public: virtual void Say() = 0; } class Cow : public Animal { public: void Say() { cout &amp;lt;&amp;lt; &amp;quot;哞哞&amp;quot; &amp;lt;&amp;lt; endl; } } class Sheep : public Animal { public: void Say() { cout &amp;lt;&amp;lt; &amp;quot;咩咩&amp;quot; &amp;lt;&amp;lt; endl; } } // 开始使用 int main() { Animal* cow = (Animal*)new Cow(); Animal* sheep = (Animal*)new Sheep(); cow-&amp;gt;Say(); sheep-&amp;gt;Say(); }  有上述代码可以看出，多态是基类中包含虚函数，而子类对其进行重写的，并且通过基类对象的指针或引用调用虚函数形成多态。</description>
    </item>
    
    <item>
      <title>C&#43;&#43;智能指针详解（Smart Pointer）</title>
      <link>https://realjf.io/cpp/smart-pointer/</link>
      <pubDate>Fri, 17 Apr 2020 11:21:57 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/smart-pointer/</guid>
      <description> 智能指针 智能指针在C++11版本之后提供，包含在头文件中，包括三种： - shared_ptr - unique_ptr - weak_ptr
智能指针的作用 由于C++没有垃圾回收机制，一切内存堆操作都是程序员自己管理，但对于程序员来说管理堆不胜麻烦，稍有不慎忘记释放就会造成内存泄露最终导致内存溢出等问题。 而智能指针则能有效避免此类问题发生。
智能指针通过对普通指针进行类封装，使其表现的跟普通指针类似的行为。
shared_ptr指针 shared_ptr 使用引用计数，每一个shared_ptr的拷贝都指向相同的内存地址，每使用一次，内部的引用计数加1， 每析构一次，内部的引用计数减1，减到0时，自动删除所指向的堆内存。shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。
 初始化。std::shared_ptr n，也可以make_shared函数初始化。不能直接赋值一个指针，因为它是类。 拷贝和赋值，拷贝引用计数加1，赋值引用计数减1，当计数为0时，自动释放内存。 get函数获取原始指针 不要用一个原始指针初始化多个shared_ptr，否则会造成二次释放同一内存。 避免循环引用，循环引用会导致内存泄漏。  unique_ptr指针 unique_ptr 唯一拥有其所指对象，统一时刻只能有一个unique_ptr指向给定对象（通过禁止拷贝语义，只有移动语义实现）。 相比原始指针，unique_ptr的RAII特性，使得其在出现异常时，能自动释放指向对象占用资源。unique_ptr生命周期从创建到作用域结束， 离开作用域时，若其指向对象，则将其所指向对象销毁。
unique_ptr在生命周期内，可以改变智能指针所指对象，通过release释放所有权，通过reset函数指定新对象，通过移动语义转移所有权。
weak_ptr指针  weak_ptr作为一个辅助智能指针，配合shared_ptr可以对资源使用情况进行观测。 weak_ptr可以从一个shared_ptr或另一个weak_ptr对象中构造，以获得资源观测权，它不会使原对象引用计数增加，  智能指针的原理 智能指针：实际指行为类似于指针的类对象，是利用了一种叫做RAII（资源获取即初始化）的技术对普通的指针进行封装, 它的一种通用实现方法是采用引用计数的方法。
 1.智能指针将一个计数器与类指向的对象相关联，引用计数跟踪共有多少个类对象共享同一指针。 2.每次创建类的新对象时，初始化指针并将引用计数置为1； 3.当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数； 4.对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数；这是因为左侧的指针指向了右侧指针所指向的对象，因此右指针所指向的对象的引用计数+1； 5.调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）。 6.实现智能指针有两种经典策略：一是引入辅助类，二是使用句柄类。这里主要讲一下引入辅助类的方法  </description>
    </item>
    
    <item>
      <title>死锁 Deadlock</title>
      <link>https://realjf.io/posts/deadlock/</link>
      <pubDate>Thu, 16 Apr 2020 15:28:20 +0800</pubDate>
      
      <guid>https://realjf.io/posts/deadlock/</guid>
      <description> 什么是死锁？ 简单说，是指两个或两个以上的线程在执行过程中，彼此持有对方需要的资源和处于等待对方释放资源的现象， 如果没有外力作用，这种状态将一直持续下去。
如何避免？ 避免死锁的一般建议是：对竞争资源按顺序采用互斥加锁
当然，如果能在编程时就注意这方便的问题，将可以用更好的方式，比如：
 避免嵌套锁 避免在持有锁时调用用户提供的代码 使用固定顺序获取锁 使用锁的层次结构  </description>
    </item>
    
    <item>
      <title>memcache数据提前过期（丢失）Memcache Data Lost</title>
      <link>https://realjf.io/mc/memcache-data-lost/</link>
      <pubDate>Wed, 15 Apr 2020 10:51:20 +0800</pubDate>
      
      <guid>https://realjf.io/mc/memcache-data-lost/</guid>
      <description>背景 今天遇到一个比较奇葩的问题，使用脚本测试接口防洪攻击时，mc的封禁数据还未到过期时间就出现数据“丢失”的情况， 一直以为是代码问题，后来偶然想到memcache在达到内存超过50%以上时，就可能采用LRU算法回收部分内存，考虑到防洪封禁数据 比较多，所以做了本地测试
了解下memcache的一些状态信息 php通过getStat函数获取memcache状态信息。
 pid mc进程号 uptime 服务器已运行秒数 version 版本 time 当前时间 libevent libevent版本 pointer_size 当前os的指针大小(64位系统一般为64) rusage_user 进程的累计用户时间 rusage_system 进程的累计系统时间 curr_connections 服务器当前打开的连接数 total_connections 从服务器启动后累计打开的总连接数 connection_structures 服务器分配的连接结构数 reserved_fds cmd_get get命令总请求次数 cmd_set set命令总请求次数 cmd_flush flush命令请求次数 cmd_touch touch命令请求次数 get_hits get命令总命中次数 get_misses get命令总未命中次数 delete_misses delete_hits incr_misses incr_hits decr_misses decr_hits cas_misses cas_hits cas_badval 使用擦拭次数 touch_hits touch_misses auth_cmds 认证命令处理次数 auth_errors 认证失败次数 bytes_read 总读取字节数（请求字节数） byte_written 总发送字节数（结果字节数） limit_maxbytes 分配给memcache的内存大小（字节） accepting_conns 服务器是否大打过最大连接数 listen_disabled_num 失效的监听数 threads 当前线程数 conn_yields 连接操作主动放弃数目 hash_power_level hash_bytes hash_is_expanding malloc_fails bytes 当前存储内容所占总字节数 curr_items 当前存储的items数量 total_items 从启动后存储的items总数量 expired_unfetched evicted_unfetched evictions 为获取空闲内存而删除的items数，LRU算法释放（分配给memcache的空间用满后需要删除旧的items来得到空间分配给新的items） reclaimed 已过期的数据条目来存储新数据的数目 crawler_reclaimed lrutail_reflocked  解决方法是，增大MC使用内存</description>
    </item>
    
    <item>
      <title>C&#43;&#43; 的Struct和Class 的区别</title>
      <link>https://realjf.io/cpp/struct-and-class-inherit/</link>
      <pubDate>Sat, 22 Feb 2020 22:14:22 +0800</pubDate>
      
      <guid>https://realjf.io/cpp/struct-and-class-inherit/</guid>
      <description> 关于c++的class和struct的不同可以简单归纳为以下几点： 内部成员变量及成员函数的默认防控属性不同 struct默认防控属性是public，而class默认的防控属性是Private
继承关系中的默认防控属性的区别 在继承关系中，struct默认是public，而class是private
在继承中的基类和子类之间的继承方式
   继承方式 基类的public成员 基类的protected成员 基类中的private成员     public继承 仍为public成员 仍为protected成员 不可见   protected继承 变为protected成员 变为protected成员 不可见   private继承 变为private成员 变为private成员 不可见    模板中使用 class关键字可以用于定义模板参数，但是struct不行
template&amp;lt;template T, class Y&amp;gt; int Func(const T&amp;amp; t, const Y&amp;amp; y) { ... }  使用花括号{}赋值问题  struct如果没有定义构造函数，可以使用花括号对struct成员进行赋值。 struct中如果定义了一个构造函数，则不能使用花括号进行赋值  </description>
    </item>
    
    <item>
      <title>debian 系统启动进入Busybox Initramfs界面</title>
      <link>https://realjf.io/linux/error/boot-into-busybox-initramfs/</link>
      <pubDate>Thu, 20 Feb 2020 22:07:19 +0800</pubDate>
      
      <guid>https://realjf.io/linux/error/boot-into-busybox-initramfs/</guid>
      <description>首先说下背景  系统环境： debian 9  问题描述 今天使用vmware workstation的时候，提示操作失败，且提示为文件系统只读。 奇怪？怎么突然进入可读了，猜想可能文件系统哪里损坏导致进入只读保护模式。
所以重新启动，之后进入了busybox界面的Initramfs界面，输入help可以查看相应命令。 我使用exit直接退出看能否重新进入，发现还是提示错误，无法进入
 busybox可以提供一个比较完善的shell工具集以及运行环境，同时可以引导程序进入系统。
 解决 在多次尝试重启无果后，重新查看错误提示，提到了/dev/mapper/realjf&amp;ndash;vg-root的文件系统， 可能是文件系统损坏了，所以开始检查修复文件系统：fsck /dev/mapper/realjf&amp;ndash;vg-root， 然后系统开始检查文件系统损坏情况，并尝试进行修复，多次输入&amp;rsquo;y&amp;rsquo;后，提示文件系统修复完成， 然后重新输入exit看是否能重新进入系统，发现已经可以进入系统了。</description>
    </item>
    
    <item>
      <title>Channel 底层实现原理</title>
      <link>https://realjf.io/golang/channel-implement/</link>
      <pubDate>Mon, 20 Jan 2020 09:08:15 +0800</pubDate>
      
      <guid>https://realjf.io/golang/channel-implement/</guid>
      <description>channel是golang的一大特色，golang的goroutine之间的通信也建议通过channel机制实现。 那么我们有必要探讨下，channel的底层实现机制，以便我们更好的应用channel。
 本次探讨版本为go v1.13
 channel的实现原理 go中实现channel的文件包含在/runtime/chan.go中
type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel.</description>
    </item>
    
    <item>
      <title>linux系统资源设置 之 Ulimit 命令</title>
      <link>https://realjf.io/linux/command/ulimit/</link>
      <pubDate>Tue, 10 Dec 2019 14:14:25 +0800</pubDate>
      
      <guid>https://realjf.io/linux/command/ulimit/</guid>
      <description>根据linux 开发手册， ulimit 设置和获取用户的资源限制
ulimit 参数说明
   选项 说明     -t 最大 cpu 占用时间 (单位是秒)   -f 进程创建文件大小的最大值 (单位是blocks)   -d 进程最大的数据段的大小，以kbytes为单位   -s 线程栈的大小，以kbytes为单位   -c 最大的core文件的大小，以blocks为单位   -m 最大内存大小，以kbytes为单位   -u 用户最大的可用的进程数   -n 可以打开的最大文件描述符数量   -l 最大可加锁内存大小，以kbytes为单位   -v 进程最大可用的虚拟内存，以kbytes为单位   -x    -i    -q    -e    -r    -N    -p 管道缓冲区的大小，以kbytes为单位   -a 显示所有资源限制的设定   -S 设定资源的弹性限制    </description>
    </item>
    
    <item>
      <title>如何写go语言的基准测试？</title>
      <link>https://realjf.io/golang/how-to-write-benchmarks-in-go/</link>
      <pubDate>Mon, 25 Nov 2019 15:08:36 +0800</pubDate>
      
      <guid>https://realjf.io/golang/how-to-write-benchmarks-in-go/</guid>
      <description>简介 Go标准库中test包包含一个基准测试工具，可用于检查Go代码的性能。 接下来将介绍如何使用测试包编写一个简单的基准测试。
一个基准测试示例 我们以斐波那契数列计算来做测试
func Fib(n int) int { if n &amp;lt; 2 { return n } return Fib(n-1) + Fib(n-2) }  创建一个名为*_test.go的测试文件，我们将对计算第20个斐波那契数列值进行性能测试。
func BenchmarkFib20(b *testing.B) { for n := 0; n &amp;lt; b.N; n++ { Fib(20) } }  编写基准测试与编写测试非常相似，因为它们共享测试包中的基础结构。一些关键区别是
 基准测试功能以Benchmark而不是Test开头 基准功能由测试包运行多次。 b.N的值每次都会增加，直到基准运行者对基准的稳定性感到满意为止。 每个基准测试必须执行b.N次测试代码。 BenchmarkFib20中的for循环将出现在每个基准测试函数中。  运行基准测试 我们可以使用go test -bench=. 调用基准测试
go test -bench=. # 运行结果如下 goos: linux goarch: amd64 pkg: test/benchmark BenchmarkFib-4 30000 44684 ns/op PASS ok test/benchmark 1.</description>
    </item>
    
  </channel>
</rss>